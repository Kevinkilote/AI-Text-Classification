category,title,abstract
math,Generalized spaces for constructive algebra,"The purpose of this contribution is to give a coherent account of a
particular narrative which links locales, geometric theories, sheaf semantics
and constructive commutative algebra. We are hoping to convey a firm grasp of
three ideas: (1) Locales are a kind of space in which opens instead of points
are fundamental. (2) Sheaf semantics allows us to explore mathematical objects
from custom-tailored mathematical universes. (3) Without loss of generality,
any reduced ring is a field."
math,Quantalic spectra of semirings,"Spectrum constructions appear throughout mathematics as a way of constructing
topological spaces from algebraic data. Given a commutative localic semiring R
(the pointfree analogue of a topological semiring), we define a spectrum of R
which generalises the Stone spectrum of a distributive lattice, the Zariski
spectrum of a commutative ring, the Gelfand spectrum of a commutative unital
C*-algebra and the Hofmann-Lawson spectrum of a continuous frame. We then
provide an explicit construction of this spectrum under conditions on R which
are satisfied by our main examples.
  Our results are constructively valid and hence admit interpretation in any
elementary topos with natural number object. For this reason the spectrum we
construct should actually be a locale instead of a topological space.
  A simple modification to our construction gives rise to a quantic spectrum in
the form of a commutative quantale. Such a quantale contains `differential'
information in addition to the purely topological information of the localic
spectrum. In the case of a discrete ring, our construction produces the
quantale of ideals.
  This prompts us to study the quantale of ideals in more detail. We discuss
some results from abstract ideal theory in the setting of quantales and provide
a tentative definition for what it might mean for a quantale to be nonsingular
by analogy to commutative ring theory."
math,Von Neumann coordinatization is not first-order,"A lattice L is coordinatizable, if it is isomorphic to the lattice L(R) of
principal right ideals of some von Neumann regular ring R. This forces L to be
complemented modular. All known sufficient conditions for coordinatizability,
due first to J. von Neumann, then to B. Jonsson, are first-order. Nevertheless,
we prove that coordinatizability of lattices is not first-order, by finding a
non-coordinatizable lattice K with a coordinatizable countable elementary
extension L. This solves a 1960 problem of B. Jonsson. We also prove that there
is no L\_{infinity, infinity} statement equivalent to coordinatizability.
Furthermore, the class of coordinatizable lattices is not closed under
countable directed unions; this solves another problem of B. Jonsson from 1962."
math,Analysis in J_2,"This is an expository paper in which I explain how core mathematics,
particularly abstract analysis, can be developed within a concrete countable
set J_2 (the second set in Jensen's constructible hierarchy). The implication,
well-known to proof theorists but probably not to most mainstream
mathematicians, is that ordinary mathematical practice does not require an
enigmatic metaphysical universe of sets. I go further and argue that J_2 is a
superior setting for normal mathematics because it is free of irrelevant
set-theoretic pathologies and permits stronger formulations of existence
results."
math,The twisting procedure,"This paper provides a conceptual study of the twisting procedure, which
amounts to create functorially new differential graded Lie algebras,
associative algebras or operads (as well as their homotopy versions) from a
Maurer--Cartan element. On the way, we settle the integration theory of
complete pre-Lie algebras in order to describe this twisting procedure in terms
of gauge group action. We give a criterion on quadratic operads for the
existence of a meaningful twisting procedure of their associated categories of
(homotopy) algebras. We also give a new presentation of the twisting procedure
for operads \`a la Willwacher and we perform new homology computations of graph
complexes."
math,Brackets and products from centres in extension categories,"Building on Retakh's approach to Ext groups through categories of extensions,
Schwede reobtained the well-known Gerstenhaber algebra structure on Ext groups
over bimodules of associative algebras both from splicing extensions (leading
to the cup product) and from a suitable loop in the categories of extensions
(leading to the Lie bracket). We show how Schwede's construction admits a vast
generalisation to general monoidal categories with coefficients of the Ext
groups taken in (weak) left and right monoidal (or Drinfel'd) centres. In case
of the category of left modules over bialgebroids and coefficients given by
commuting pairs of braided (co)commutative (co)monoids in these categorical
centres, we provide an explicit description of the algebraic structure obtained
this way, and a complete proof that this leads to a Gerstenhaber algebra is
then obtained from an operadic approach. This, in particular, considerably
generalises the classical construction given by Gerstenhaber himself.
Conjecturally, the algebraic structure we describe should produce a
Gerstenhaber algebra for an arbitrary monoidal category enriched over abelian
groups, but even the bilinearity of the cup product and of the Lie-type bracket
defined by the abstract construction in terms of extension categories remain
elusive in this general setting."
math,Maurer-Cartan methods in deformation theory: the twisting procedure,"This monograph provides an overview on the Maurer-Cartan methods in algebra,
geometry, topology, and mathematical physics. It offers a conceptual,
exhaustive and gentle treatment of the twisting procedure, which functorially
creates new differential graded Lie algebras, associative algebras or operads
(as well as their homotopy versions) from a Maurer-Cartan element. The twisting
procedure for (homotopy) associative algebras or (homotopy) Lie algebras is
described by means of the action of the biggest deformation gauge group ever
considered. We give a criterion on quadratic operads for the existence of a
meaningful twisting procedure of their associated categories of algebras. And,
we introduce the twisting procedure for operads \`a la Willwacher using a new
and simpler presentation, which provides us with a wide source of motivating
examples related to graph homology, both recovering known graph complexes (due
to Kontsevich) and introducing some new ones. This book starts with elementary
surveys on gauge theory and deformation theory using differential graded Lie
algebras in order to ease the way to the theory. It finishes with concise
surveys on the fundamental theorem of deformation theory, higher Lie theory,
rational homotopy theory, simplicial theory of homotopy algebras, and the Floer
cohomology of Lagrangian submanifolds, to illustrate deep examples of
applications."
math,"Notes on A-infinity algebras, A-infinity categories and non-commutative
  geometry. I","We develop geometric approach to A-infinity algebras and A-infinity
categories based on the notion of formal scheme in the category of graded
vector spaces. Geometric approach clarifies several questions, e.g. the notion
of homological unit or A-infinity structure on A-infinity functors. We discuss
Hochschild complexes of A-infinity algebras from geometric point of view. The
paper contains homological versions of the notions of properness and smoothness
of projective varieties as well as the non-commutative version of Hodge-to-de
Rham degeneration conjecture. We also discuss a generalization of Deligne's
conjecture which includes both Hochschild chains and cochains. We conclude the
paper with the description of an action of the PROP of singular chains of the
topological PROP of 2-dimensional surfaces on the Hochschild chain complex of
an A-infinity algebra with the scalar product (this action is more or less
equivalent to the structure of 2-dimensional Topological Field Theory
associated with an ""abstract"" Calabi-Yau manifold)."
math,Gelfand spectra and Wallman compactifications,"We carry out a systematic, topos-theoretically inspired, investigation of
Wallman compactifications with a particular emphasis on their relations with
Gelfand spectra and Stone-Cech compactifications. In addition to proving
several specific results about Wallman bases and maximal spectra of
distributive lattices, we establish a general framework for functorializing the
representation of a topological space as the maximal spectrum of a Wallman base
for it, which allows to generate different dualities between categories of
topological spaces and subcategories of the category of distributive lattices;
in particular, this leads to a categorical equivalence between the category of
commutative C*-algebras and a natural category of distributive lattices. We
also establish a general theorem concerning the representation of the
Stone-Cech compactification of a locale as a Wallman compactification, which
subsumes all the previous results obtained on this problem."
math,Derived categories and syzygies,"We introduce syzygies for derived categories and study their properties.
Using these, we prove the derived invariance of the following classes of artin
algebras: (1) syzygy-finite algebras, (2) Igusa-Todorov algebras, (3) AC
algebras, (4) algebras satisfying the finitistic Auslander conjecture, and (5)
algebras satisfying the generalized Auslander-Reiten conjecture. In particular,
Gorenstein CM-finite algebras are derived invariants."
math,From objects to diagrams for ranges of functors,"Let A, B, S be categories, let F:A-->S and G:B-->S be functors. We assume
that for ""many"" objects a in A, there exists an object b in B such that F(a) is
isomorphic to G(b). We establish a general framework under which it is possible
to transfer this statement to diagrams of A. These diagrams are all indexed by
posets in which every principal ideal is a join-semilattice and the set of all
upper bounds of any finite subset is a finitely generated upper subset. Various
consequences follow, in particular: (1) The Gr\""atzer-Schmidt Theorem, which
states that every algebraic lattice is isomorphic to the congruence lattice of
some algebra, can be extended to finite poset-indexed diagrams of algebraic
lattices and compactness-preserving complete join-homomorphisms (and no
finiteness restriction if there are large enough cardinals). (2) In a host of
situations, the relative critical point between two locally finite
quasivarieties is either less than aleph omega or equal to infinity. (3) A
lattice of cardinality aleph 1 may not have any congruence-permutable,
congruence-preserving extension."
math,"A non-coordinatizable sectionally complemented modular lattice with a
  large Jónsson four-frame","A sectionally complemented modular lattice L is coordinatizable if it is
isomorphic to the lattice L(R) of all principal right ideals of some von
Neumann regular (not necessarily unital) ring R. We say that L has a large
4-frame if it has a homogeneous sequence (a_0,a_1,a_2,a_3) such that the
neutral ideal generated by a_0 is L. J\'onsson proved in 1962 that if L has a
countable cofinal sequence and a large 4-frame, then it is coordinatizable;
whether the cofinal sequence assumption could be dispensed with was left open.
We solve this problem by finding a non-coordinatizable sectionally complemented
modular lattice L with a large 4-frame; it has cardinality aleph one.
Furthermore, L is an ideal in a (necessarily coordinatizable) complemented
modular lattice with a spanning 5-frame. Our proof uses Banaschewski functions.
A Banaschewski function on a bounded lattice L is an antitone self-map of L
that picks a complement for each element of L. In an earlier paper, we proved
that every countable complemented modular lattice has a Banaschewski function.
We prove that there exists a unit-regular ring R of cardinality aleph one and
index of nilpotence 3 such that L(R) has no Banaschewski function."
math,A^1-homotopy theory and contractible varieties: a survey,"We survey some topics in ${\mathbb A}^1$-homotopy theory. Our main goal is to
highlight the interplay between ${\mathbb A}^1$-homotopy theory and affine
algebraic geometry, focusing on the varieties that are ""contractible"" from
various standpoints."
math,Strong algebraization of fixed point properties,"The following natural question arises from Shalom's innovational work (1999,
Publ. IHES): ""Can we establish an intrinsic criterion to synthesize relative
fixed point properties into the whole fixed point property without assuming
Bounded Generation?"" This paper resolves this question in the affirmative. Our
criterion works for ones with respect to certain classes of Busemann NPC
spaces. It, moreover, suggests a further step toward constructing
super-expanders from finite simple groups of Lie type."
math,The mathematical work of K.S.S. Nambooripad,"We provide an overview of the mathematical work of K.S.S. Nambooripad, with a
focus on his contributions to the theory of regular semigroups. In particular,
we outline Nambooripad's seminal contributions to the structure theory of
regular semigroups via his theory of {\em inductive groupoids}, and also via
his theory of {\em cross connections}. We also provide information about
outgrowths of his work in the algebraic theory of semigroups and its
connections with several other fields of mathematics, in particular with the
theory of operator algebras."
math,"Characterizing group $C^\ast$-algebras through their unitary groups: the
  Abelian case","We study to what extent group $C^\ast$-algebras are characterized by their
unitary groups. A complete characterization of which Abelian group
$C^\ast$-algebras have isomorphic unitary groups is obtained. We compare these
results with other unitary-related invariants of $C^\ast(\Gamma)$, such as the
$K$-theoretic $K_1(C^\ast(\Gamma))$ and find that $C^\ast$-algebras of
nonisomorphic torsion-free Abelian groups may have isomorphic $K_1$-groups, in
sharp contrast with the well-known fact that $C^\ast(\Gamma)$ (even $\Gamma$)
is characterized by the topological group structure of its unitary group when
$\Gamma $ is torsion-free and Abelian."
math,Surprising occurrences of order structures in mathematics,"Order and symmetry are main structural principles in mathematics. We give
five examples where on the face of it order is not apparent, but deeper
investigations reveal that they are governed by order structures. These
examples are finite topologies, associative algebras, subgroups of matrix
groups, ideals in polynomial rings, and classes of bipartite graphs."
math,Right Bousfield Localization and Operadic Algebras,"It is well known that under some general conditions right Bousfield
localization exists. We provide general conditions under which right Bousfield
localization yields a monoidal model category. Then we address the questions of
when this monoidal model structure on a right Bousfield localization induces a
model structure on the category of algebras over a colored operad and when a
right Bousfield localization preserves colored operadic algebras. We give
numerous applications, to topological spaces, equivariant spaces, chain
complexes, stable module categories, and to the category of small categories.
We recover a wide range of classical results as special cases of our theory,
and prove several new preservation results."
math,Symmetric homotopy theory for operads,"The purpose of this foundational paper is to introduce various notions and
constructions in order to develop the homotopy theory for differential graded
operads over any ring. The main new idea is to consider the action of the
symmetric groups as part of the defining structure of an operad and not as the
underlying category. We introduce a new dual category of higher cooperads, a
new higher bar-cobar adjunction with the category of operads, and a new higher
notion of homotopy operads, for which we establish the relevant homotopy
properties. For instance, the higher bar-cobar construction provides us with a
cofibrant replacement functor for operads over any ring. All these
constructions are produced conceptually by applying the curved Koszul duality
for colored operads. This paper is a first step toward a new Koszul duality
theory for operads, where the action of the symmetric groups is properly taken
into account."
math,On the axiomatisability of the dual of compact ordered spaces,"We provide a direct and elementary proof of the fact that the category of
Nachbin's compact ordered spaces is dually equivalent to an Aleph_1-ary variety
of algebras. Further, we show that Aleph_1 is a sharp bound: compact ordered
spaces are not dually equivalent to any SP-class of finitary algebras."
math,Grätzer-Hofmann-Lawson-Jung-Sünderhauf Duality,"We unify several extensions of the classic Stone duality due to Gr\""atzer,
Hoffman-Lawson and Jung-S\""underhauf. Specifically we show that U-bases of
locally compact sober spaces are dual to <-distributive v-predomains, where <
is a transitive relation representing compact containment."
math,Generalized Frobenius Algebras and the Theory of Hopf Algebras,"""Co-Frobenius"" coalgebras were introduced as dualizations of Frobenius
algebras. Recently, it was shown in \cite{I} that they admit left-right
symmetric characterizations analogue to those of Frobenius algebras: a
coalgebra $C$ is co-Frobenius if and only if it is isomorphic to its rational
dual. We consider the more general quasi-co-Frobenius (QcF) coalgebras; in the
first main result we show that these also admit symmetric characterizations: a
coalgebra is QcF if it is weakly isomorphic to its (left, or equivalently
right) rational dual $Rat(C^*)$, in the sense that certain coproduct or product
powers of these objects are isomorphic. These show that QcF coalgebras can be
viewed as generalizations of both co-Frobenius coalgebras and Frobenius
algebras. Surprisingly, these turn out to have many applications to fundamental
results of Hopf algebras. The equivalent characterizations of Hopf algebras
with left (or right) nonzero integrals as left (or right) co-Frobenius, or QcF,
or semiperfect or with nonzero rational dual all follow immediately from these
results. Also, the celebrated uniqueness of integrals follows at the same time
as just another equivalent statement. Moreover, as a by-product of our methods,
we observe a short proof for the bijectivity of the antipode of a Hopf algebra
with nonzero integral. This gives a purely representation theoretic approach to
many of the basic fundamental results in the theory of Hopf algebras."
math,Simplicial Structure on Complexes,"While chain complexes are equipped with a differential $d$ satisfying $d^2 =
0$, their generalizations called $N$-complexes have a differential $d$
satisfying $d^N = 0$. In this paper we show that the lax nerve of the category
of chain complexes is pointwise adjoint equivalent to the d\'ecalage of the
simplicial category of $N$-complexes. This reveals additional simplicial
structure on the lax nerve of the category of chain complexes which provides a
categorfication of the triangulated homotopy category of chain complexes. We
study this phenomena in general and present evidence that the axioms of
triangulated categories have simplicial origin."
math,Localization of Cofibration Categories and Groupoid $C^*$-algebras,"We prove that relative functors out of a cofibration category are essentially
the same as relative functors which are only defined on the subcategory of
cofibrations. As an application we give a new construction of the functor that
assigns to a groupoid its groupoid $C^*$-algebra and thereby its topological
$K$-theory spectrum."
math,Updates on Hirzebruch's 1954 Problem List,"We present updates to the problems on Hirzebruch's 1954 problem list
focussing on open problems, and on those where substantial progress has been
made in recent years. We discuss some purely topological problems, as well as
geometric problems about (almost) complex structures, both algebraic and
non-algebraic, about contact structures, and about (complementary pairs of)
foliations."
math,The magnitude of metric spaces,"Magnitude is a real-valued invariant of metric spaces, analogous to the Euler
characteristic of topological spaces and the cardinality of sets. The
definition of magnitude is a special case of a general categorical definition
that clarifies the analogies between various cardinality-like invariants in
mathematics. Although this motivation is a world away from geometric measure,
magnitude, when applied to subsets of R^n, turns out to be intimately related
to invariants such as volume, surface area, perimeter and dimension. We
describe several aspects of this relationship, providing evidence for a
conjecture (first stated in arXiv:0908.1582) that magnitude subsumes all the
most important invariants of classical integral geometry."
math,Monotone-light factorizations in coarse geometry,"We introduce large scale analogues of topological monotone and light maps,
which we call coarsely monotone and coarsely light maps respectively. We show
that these two classes of maps constitute a factorization system on the coarse
category. We also show how coarsely monotone maps arise from a reflection in a
similar way to classically monotone maps, and prove that coarsely monotone maps
are stable under those pullbacks which exist in the coarse category. For the
case of maps between proper metric spaces, we exhibit some connections between
the coarse and classical notions of monotone and light using the Higson corona.
Finally, we look at some coarse properties which are preserved by coarsely
light maps such as finite asymptotic dimension and exactness, and make some
remarks on the situation for groups and group homomorphisms."
math,Ends of spaces via linear algebra,"We develop a theory that may be considered as a prequel to the coarse theory.
We are viewing ends of spaces as extra points at infinity. In order to discuss
behaviour of spaces at infinity one needs a concept (a measure) of approaching
infinity. The simplest way to do so is to list subsets of $X$ that are bounded
(i.e. far from infinity) and that list should satisfy certain basic properties.
Such a list $S_X$ we call a \textbf{scale} on a set $X$ (see Section 3). In
order to use ideas from the Stone Duality Theorem we consider sub-Boolean
algebras $BA_X$ of the power set $2^X$ of $X$ that contain $S_X$ and that leads
naturally to the concept of ends of a \textbf{scaled Boolean algebra}
$(X,S_X,BA_X)$ which can be attached to $X$ and form a new scaled Boolean
algebra $(\bar X,S_X,\overline{BA_X})$ that is \textbf{compact at infinity}.
  Given a scaled space $(X,S_X)$ the most natural scaled Boolean algebra is
$(X,S_X,2^X)$ which can be too far removed from the geometry of $X$. Therefore
we need to figure out how to trim $2^X$ to a smaller sub-Boolean algebra
$BA_X$. More generally, how to trim a sub-Boolean algebra $BA_X$ to a smaller
one. That is done using ideas from linear algebra. Namely, we consider a family
$\mathcal{F}$ of naturally arising $S_X$-linear operators on $BA_X$ and the
smaller sub-Boolean algebra $BA_{\mathcal{F}}$ consists of eigensets of
$\mathcal{F}$, an analog of eigenvectors from linear algebra. We show that all
ends defined in literature so far (Freundenthal ends, ends of finitely
generated groups, Specker ends, Cornulier ends, ends of coarse spaces) are
special cases of such a process."
math,Homotopy invariance of higher K-theory for abelian categories,"The main theorem in this paper is that the base change functor from a
noetherian abelian category to its noetherian polynomial category induces an
isomorphism on K-theory. The main theorem implies the well-known fact that
A^1-homotopy invariance of K'-theory for noetherian schemes."
math,Graded Brauer groups of a groupoid with involution,"We define a group $RBr(\mathcal{G})$ containing, in a sense, the graded
complex and orthogonal Brauer groups of a locally compact groupoid
$\mathcal{G}$ equipped with an involution. When the involution is trivial, we
show that the new group naturally provides a generalization of
Donovan-Karoubi's graded orthogonal Brauer group $GBrO$. More generally, it is
shown to be a direct summand of the well-known graded complex Brauer goup. In
addition, we prove that $RBr(\mathcal{G})$ identifies with a direct sum of a
Real cohomology group and the abelian group $RExt(\mathcal{G},U(1))$ of Real
graded $U(1)$-central extensions. A cohomological picture is then given."
math,"Expanders, exact crossed products, and the Baum-Connes conjecture","We reformulate the Baum-Connes conjecture with coefficients by introducing a
new crossed product functor for C*-algebras. All confirming examples for the
original Baum-Connes conjecture remain confirming examples for the reformulated
conjecture, and at present there are no known counterexamples to the
reformulated conjecture. Moreover, some of the known expander-based
counterexamples to the original Baum-Connes conjecture become confirming
examples for our reformulated conjecture."
math,The negative side of cohomology for Calabi-Yau categories,"We study integer-graded cohomology rings defined over Calabi-Yau categories.
We show that the cohomology in negative degree is a trivial extension of the
cohomology ring in non-negative degree, provided the latter admits a regular
sequence of central elements of length two. In particular, the product of
elements of negative degrees are zero. As corollaries we apply this to
Tate-Hochschild cohomology rings of symmetric algebras, and to Tate cohomology
rings over group algebras. We also prove similar results for Tate cohomology
rings over commutative local Gorenstein rings."
math,Cokernels in the stable category of a left hereditary ring,"It is proved that if a ring is left hereditary, left perfect and right
coherent, then the stable category has cokernels. Moreover, we show that the
condition for a ring to be left perfect and right coherent is also necessary
for the stable category to have cokernels, provided that the ring is left
hereditary and satisfies the additional condition that there are no non-trivial
projective injective left modules over it (satisfied, for instance, by integral
domains). This, in particular, implies that, for a Dedekind domain, the stable
category has cokernels if and only if the domain is left perfect. Several new
necessary and sufficient conditions for a left hereditary ring to be left
perfect and right coherent are found. One of them requires that the full
subcategory of projective modules be reflective in the category of modules.
Another one requires that any module be isomorphic to a stable module in the
stable category. Yet another equivalent condition found in the paper requires
that, for any module $M$, among all representations $M=K\oplus P$ with a
projective $P$, there should be the one with the smallest $K$. To accomplish
the goals, a version of the well-known Freyd's adjoint functor theorem, where
the solution set condition is removed under some additional conditions on the
categories, is given."
math,"The spectral measure of certain elements of the complex group ring of a
  wreath product","We use elementary methods to compute the L2-dimension of the eigenspaces of
the Markov operator on the lamplighter group and of generalizations of this
operator on other groups. In particular, we give a transparent explanation of
the spectral measure of the Markov operator on the lamplighter group found by
Grigorchuk-Zuk. The latter result was used by Grigorchuk-Linnell-Schick-Zuk to
produce a counterexample to a strong version of the Atiyah conjecture about the
range of L2-Betti numbers. We use our results to construct manifolds with
certain L2-Betti numbers (given as convergent infinite sums of rational
numbers) which are not obviously rational, but we have been unable to determine
whether any of them are irrational."
math,"Spaces with vanishing $l\sp 2$-homology and their fundamental groups
  (after Farber and Weinberger)","The ""zero in the spectrum conjecture"" asserted (in its strongest form) that
for any manifold M zero should be in the l2-spectrum of the Laplacian (on
forms) of the universal covering of M, i.e. that at least one (unreduced)
L2-cohomology group of (the universal covering of) M is non-zero.
  Farber and Weinberger gave the first counterexamples to this conjecture. In
this paper, using their fundamental idea to show the following stronger version
of this result:
  Let G be a finitely presented group and suppose that the homology groups
H_k(G,\ell^2(G)) are zero for k=0,1,2. For every dimension n\ge 6 there is a
closed manifold M of dimension n and with fundamental group G such that the
L2-cohomology of (the universal covering of) M vanishes in all degrees."
math,"Analytic Topology of Groups, Actions, Strings and Varietes",This is a paper in Analytic Topology.
math,Semiprojectivity and semiinjectivity in different categories,"Projectivity and injectivity are fundamental notions in category theory. We
consider natural weakenings termed semiprojectivity and semiinjectivity, and
study these concepts in different categories.
  For example, in the category of metric spaces, (semi)injective objects are
precisely the absolute (neighborhood) retracts. We show that the trivial group
is the only semiinjective group, while every free product of a finitely
presented group and a free group is semiprojective.
  To a compact, metric space $X$ we associate the commutative C*-algebra
$C(X)$. This association is contravariant, whence semiinjectivity of $X$ is
related to semiprojectivity of $C(X)$. Together with Adam S{\o}rensen, we
showed that $C(X)$ is semiprojective in the category of all C*-algebras if and
only if $X$ is an absolute neighborhood retract with dimension at most one."
math,Quantum direct products and the Künneth class,"We introduce a K\""unneth class in the quantum equivariant setting inspired by
the pioneer work by J. Chabert, H. Oyono-Oyono and S. Echterhoff, which allows
to relate the quantum Baum-Connes property with the K\""unneth formula by
generalising some key results of Chabert-Oyono-Oyono-Echterhoff to discrete
quantum groups. Finally, we make the observation that the C$^*$-algebra
defining a compact quantum group with dual satisfying the strong quantum
Baum-Connes property belongs to the K\""unneth class. This allows to obtain some
K-theory computations for quantum direct products based on earlier work by
Voigt and Vergnioux-Voigt."
math,"$K$-theory of two-dimensional substitution tiling spaces from
  $AF$-algebras","Given a two-dimensional substitution tiling space, we show that, under some
reasonable assumptions, the $K$-theory of the groupoid $C^\ast$-algebra of its
unstable groupoid can be explicitly reconstructed from the $K$-theory of the
$AF$-algebras of the substitution rule and its analogue on the $1$-skeleton. We
prove this by generalizing the calculations done for the chair tiling in [JS16]
using relative $K$-theory and excision, and packaging the result into an exact
sequence purely in topology. From this exact sequence, it appears that one
cannot use only ordinary $K$-theory to compute using the dimension-filtration
on the unstable groupoid. Several examples are computed using Sage and the
results are compiled in a table."
math,Etale groupoids as germ groupoids and their base extensions,"We introduce the notion of wide representation of an inverse semigroup and
prove that with a suitably defined topology there is a space of germs of such a
representation which has the structure of an etale groupoid. This gives an
elegant description of Paterson's universal groupoid and of the translation
groupoid of Skandalis, Tu, and Yu. In addition we characterize the inverse
semigroups that arise from groupoids, leading to a precise bijection between
the class of etale groupoids and the class of complete and infinitely
distributive inverse monoids equipped with suitable representations, and we
explain the sense in which quantales and localic groupoids carry a
generalization of this correspondence."
math,A Note on Surjective Inverse Systems,"Given an upward directed set $I$ we consider surjective $I$-inverse systems
$\{X_\al,f_{\al\be}:X_\be\lra X_\al| \al\leq\be\in I\}$, namely those inverse
systems that have all $f_{\al\be}$ surjective. A number of properties of
$I$-inverse systems have been investigated; such are the Mittag-Leffler
condition, investigated by Grothendieck and flabby and semi-flabby $I$-inverse
systems studied by Jensen. We note that flabby implies semi-flabby implies
surjective implies Mittag-Leffler. Some of the results about surjective inverse
systems have been known for some time. The aim of this note is to give a series
of equivalent statements and implications involving surjective inverse systems
and the systems satisfying the Mittag-Leffler condition, together with
improvements of established results, as well as their relationships with the
already known, but scattered facts. The most prominent results relate
cardinalities of the index sets with right exactness of the inverse limit
functor and the non-vanishing of the inverse limit -- connections related to
cohomological dimensions."
math,"On the abelianization of derived categories and a negative solution to
  Rosicky's problem","We prove for a large family of rings R that their lambda-pure global
dimension is greater than one for each infinite regular cardinal lambda. This
answers in negative a problem posed by Rosicky. The derived categories of such
rings then do not satisfy the Adams lambda-representability for morphisms for
any lambda. Equivalently, they are examples of well generated triangulated
categories whose lambda-abelianization in the sense of Neeman is not a full
functor for any lambda. In particular we show that given a compactly generated
triangulated category, one may not be able to find a Rosicky functor among the
lambda-abelianization functors."
math,Cohomologie des foncteurs polynomiaux sur les groupes libres,"We show that extension groups between two polynomial functors on free groups
are the same in the category of all functors and in a subcategory of polynomial
functors of bounded degree. We give some applications. ---- On montre que les
groupes d'extensions entre foncteurs polynomiaux sur les groupes libres sont
les m\^emes dans la cat\'egorie de tous les foncteurs et dans une
sous-cat\'egorie de foncteurs polynomiaux de degr\'e born\'e. On donne quelques
applications."
math,"Koszulity of cohomology = $K(π,1)$-ness + quasi-formality","This paper is a greatly expanded version of Section 9.11 in arXiv:1006.4343.
A series of definitions and results illustrating the thesis in the title (where
quasi-formality means vanishing of a certain kind of Massey multiplications in
the cohomology) is presented. In particular, we include a categorical
interpretation of the ""Koszulity implies $K(\pi,1)$"" claim, discuss the
differences between two versions of Massey operations, and apply the derived
nonhomogeneous Koszul duality theory in order to deduce the main theorem. In
the end we demonstrate a counterexample providing a negative answer to a
question of Hopkins and Wickelgren about formality of the cochain DG-algebras
of absolute Galois groups, thus showing that quasi-formality cannot be
strengthened to formality in the title assertion."
math,Galois theory and the categorical Peiffer commutator,"We show that the Peiffer commutator previously defined by Cigoli, Mantovani
and Metere can be used to characterize central extensions of precrossed modules
with respect to the subcategory of crossed modules in any semi-abelian category
satisfying an additional property. We prove that this commutator also
characterizes double central extensions, obtaining then some Hopf formulas for
the second and third homology objects of internal precrossed modules."
math,Torsion aspects of varieties of simplicial groups,"There is a lattice of torsion theories in simplicial groups such that the
torsion/torsion-free categories are given by simplicial groups with truncated
Moore complex below/above a certain degree. We study the restriction of these
torsion theories to certain subcategories of simplicial groups. In particular,
we prove that the categories of D.Conduch\'{e}'s 2-crossed modules and Ashley's
crossed complexes in groups are semi-abelian and we give some descriptions of
their torsion theories. These examples of torsion theories also give rise to
new examples of pretorsion theories in the sense of A. Facchini and C.
Finocchiaro, as well as examples of torsion torsion-free theories (TTF
theories)."
math,Integral Excision for K-Theory,"If A is a homotopy cartesian square of ring spectra satisfying connectivity
hypotheses, then the cube induced by Goodwillie's integral cyclotomic trace
from K(A) to TC(A) is homotopy cartesian. In other words, the homotopy fiber of
the cyclotomic trace satisfies excision. The method of proof gives as a
spin-off new proofs of some old results, as well as some new results, about
periodic cyclic homology, and - more relevantly for our current application -
the T-Tate spectrum of topological Hochschild homology, where T is the circle
group"
math,Exel-Pardo algebras with a twist,"Katsura associated a $C^*$-algebra $C^*_{A,B}$ to integral matrices $A\ge 0$
and $B$ of the same size, gave sufficient conditions on $(A,B)$ making it
simple purely infinite (SPI), and proved that any separable $C^*$-algebra
$KK$-isomorphic to a cone of an element $\xi\in KK(C(S^1)^n,C(S^1)^n)$ in
Kasparov's $KK$ is $KK$-isomorphic to an SPI $C^*_{A,B}$. Here we introduce,
for the data of a commutative ring $\ell$, matrices $A,B$ as above and $C$ of
the same size with coefficients in the group $\mathcal{U}(\ell)$ of invertible
elements, an $\ell$-algebra $\mathcal{O}_{A,B}^C$, the twisted Katsura algebra
of the triple $(A,B,C)$, show it is SPI whenever $\ell\supset\mathbb{Q}$ is a
field and $(A,B)$ satisfy Katsura conditions, and that any $\ell$-algebra which
is a cone of a map $\xi\in kk(\ell[t,t^{-1}]^n,\ell[t,t^{-1}]^n)$ in the
bivariant algebraic $K$-theory category $kk$ is $kk$-isomorphic to an SPI
$\mathcal{O}_{A,B}^C$. Twisted Katsura $\ell$-algebras are twisted Exel-Pardo
algebras $L(G,E,\phi_c)$ associated to a group $G$ acting on a graph $E$, and
$1$-cocycles $\phi:G\times E^1\to G$ and $c:G\times E^1\to \mathcal{U}(\ell)$.
We describe $L(G,E,\phi_c)$ by generators and relations, as a quotient of a
twisted semigroup algebra, as a twisted Steinberg algebra, as a corner skew
Laurent polynomial algebra, and as a universal localization of a tensor
algebra. We use each of these guises of $L(G,E,\phi_c)$ to study its
$K$-theoretic, regularity and simplicity properties. For example we show that
if $\ell\supset \mathbb{Q}$ is a field, $G$ and $E$ are countable and $E$ is
regular, then $L(G,E,\phi_c)$ is simple whenever the Exel-Pardo $C^*$-algebra
$C^*(G,E,\phi)$ is, and is SPI if in addition the Leavitt path algebra $L(E)$
is SPI."
math,Semisimplicity manifesting as categorical smallness,"For a compact group $\mathbb{G}$, the functor from unital Banach algebras
with contractive morphisms to metric spaces with 1-Lipschitz maps sending a
Banach algebra $A$ to the space of $\mathbb{G}$-representations in $A$
preserves filtered colimits. Along with this, we prove a number of analogues:
one can substitute unitary representations in $C^*$-algebras, as well as
semisimple finite-dimensional Banach algebras (or finite-dimensional
$C^*$-algebras) for $\mathbb{G}$.
  These all mimic results on the metric-enriched finite
generation/presentability of finite-dimensional Banach spaces due to Ad{\'a}mek
and Rosick{\'y}. We also give an alternative proof of that finite
presentability result, along with parallel results on functors represented by
compact metric, metric convex, or metric absolutely convex spaces."
math,The Tambara Structure of the Trace Ideal for Cyclic Extensions,"This paper explores the Tambara functor structure of the trace ideal of a
Galois extension. In the case of a (pro-)cyclic extension, we are able to
explicitly determine the generators of the ideal. Furthermore, we show that the
absolute trace ideal of a cyclic group is strongly principal when viewed as an
ideal of the Burnside Tambara Functor. Applying our results, we calculate the
trace ideal for extensions of finite fields. The appendix determines a formula
for the norm of a quadratic form over an arbitrary finite extension of a finite
field."
math,Computer theorem proving in math,"We give an overview of issues surrounding computer-verified theorem proving
in the standard pure-mathematical context. This is based on my talk at the PQR
conference (Brussels, June 2003)."
math,Co-induced actions for topological and filtered groups,"In this note, we show that the category of strongly central series admits
co-induced actions, which means that it is Locally Algebraically Cartesian
Closed. We also show that some co-induction functors exist in the category of
topological groups, and that a convenient category of topological groups is
LACC."
math,Algebraic Geometry of Topological Spaces I,"We use techniques from both real and complex algebraic geometry to study
K-theoretic and related invariants of the algebra C(X) of continuous
complex-valued functions on a compact Hausdorff topological space X. For
example, we prove a parametrized version of a theorem of Joseph Gubeladze; we
show that if M is a countable, abelian, cancellative, torsion-free, seminormal
monoid, and X is contractible, then every finitely generated projective module
over C(X)[M] is free. The particular case when M=N^n gives a parametrized
version of the celebrated theorem proved independently by Daniel Quillen and
Andrei Suslin that finitely generated projective modules over a polynomial ring
over a field are free. The conjecture of Jonathan Rosenberg which predicts the
homotopy invariance of the negative algebraic K-theory of C(X) follows from the
particular case when M=Z^n. We also give algebraic conditions for a functor
from commutative algebras to abelian groups to be homotopy invariant on
C*-algebras, and for a homology theory of commutative algebras to vanish on
C*-algebras. These criteria have numerous applications. For example, the
vanishing criterion applied to nil-K-theory implies that commutative
C*-algebras are K-regular. As another application, we show that the familiar
formulas of Hochschild-Kostant-Rosenberg and Loday-Quillen for the algebraic
Hochschild and cyclic homology of the coordinate ring of a smooth algebraic
variety remain valid for the algebraic Hochschild and cyclic homology of C(X).
Applications to the conjectures of Beilinson-Soule and Farrell-Jones are also
given."
math,Salce's problem on cotorsion pairs is undecidable,"Salce \cite{MR565595} introduced the notion of a \emph{cotorsion pair} of
classes of abelian groups, and asked whether every such pair is \emph{complete}
(i.e., has enough injectives and projectives). We prove that it is consistent,
relative to the consistency of Vop\v{e}nka's Principle (VP), that the answer is
affirmative. Combined with a previous result of Eklof-Shelah \cite{MR2031314},
this shows that Salce's Problem is independent of the ZFC axioms (modulo the
consistency of VP)."
math,The homotopy theory of differentiable sheaves,"Many important theorems in differential topology relate properties of
manifolds to properties of their underlying homotopy types -- defined e.g.
using the total singular complex or the \v{C}ech nerve of a good open cover.
Upon embedding the category of manifolds into the $\infty$-topos
$\mathbf{Diff}^\infty$ of differentiable sheaves one gains a further notion of
underlying homotopy type: the shape of the corresponding differentiable sheaf.
  In a first series of results we prove using simple cofinality and descent
arguments that the shape of any manifold coincides with many other notions of
underlying homotopy types such as the ones mentioned above. Our techniques
moreover allow for computations, such as the homotopy type of the Haefliger
stack, following Carchedi.
  This leads to more refined questions, such as what it means for a mapping
differential sheaf to have the correct shape. To answer these we construct
model structures as well as more general homotopical calculi on the
$\infty$-category $\mathbf{Diff}^\infty$ (which restrict to its full
subcategory of $0$-truncated objects,$\mathbf{Diff}^\infty_{\leq 0}$) with
shape equivalences as the weak equivalences. These tools are moreover developed
in such a way so as to be highly customisable, with a view towards future
applications, e.g. in geometric topology.
  Finally, working with the $\infty$-topos $\mathbf{Diff}^0$ of sheaves on
topological manifolds, we give new and conceptual proofs of some classical
statements in algebraic topology. These include Dugger and Isaksen's
hypercovering theorem, and the fact that the Quillen adjunction between
simplicial sets and topological spaces is a Quillen equivalence."
math,Generalized cohomological field theories in the higher order formalism,"In the classical Batalin--Vilkovisky formalism, the BV operator $\Delta$ is a
differential operator of order two with respect to the commutative product. In
the differential graded setting, it is known that if the BV operator is
homotopically trivial, then there is a tree level cohomological field theory
induced on the homology; this is a manifestation of the fact that the homotopy
quotient of the operad of BV algebras by $\Delta$ is represented by the operad
of hypercommutative algebras. In this paper, we study generalized
Batalin--Vilkovisky algebras where the operator $\Delta$ is of the given finite
order. In that case, we unravel a new interesting algebraic structure on the
homology whenever $\Delta$ is homotopically trivial. We also suggest that the
sequence of algebraic structures arising in the higher order formalism is a
part of a ""trinity"" of remarkable mathematical objects, fitting the philosophy
proposed by Arnold in the 1990s."
math,From homotopy operads to infinity-operads,"The goal of the present paper is to compare, in a precise way, two notions of
operads up to homotopy which appear in the literature. Namely, we construct a
functor from the category of strict unital homotopy colored operads to the
category of infinity-operads. The former notion, that we make precise, is the
operadic generalization of the notion of A-infinity-categories and the latter
notion was defined by Moerdijk--Weiss in order to generalize the simplicial
notion of infinity-category of Joyal--Lurie. This functor extends in two
directions the simplicial nerve of Faonte--Lurie for A-infinity-categories and
the homotopy coherent nerve of Moerdijk--Weiss for differential graded operads;
it is also shown to be equivalent to a big nerve \`a la Lurie for differential
graded operads. We prove that it satisfies some homotopy properties with
respect to weak equivalences and fibrations; for instance, it is shown to be a
right Quillen functor."
math,Quandle cohomology is a Quillen cohomology,"We show that the cohomology groups usually associated with racks and quandles
agree with the Quillen cohomology groups for the algebraic theories of racks
and quandles, respectively. We also explain how this makes available the entire
range of tools that comes with a Quillen homology theory, such as long exact
sequences (transitivity) and excision isomorphisms (flat base change)."
math,Enhanced finite triangulated categories,"We give a necessary and sufficient condition for the existence of an
enhancement of a finite triangulated category. Moreover, we show that
enhancements are unique when they exist, up to Morita equivalence."
math,Traces for factorization homology in dimension 1,"We construct a circle-invariant trace from the factorization homology of the
circle $ {\sf trace} \colon \int^\alpha_{{\mathbb S}^1} \\underline{\sf End}(V)
\longrightarrow \uno $ associated to a dualizable object $V\in
{\boldsymbol{\mathfrak X}}$ in a symmetric monoidal $\infty$-category. This
proves a conjecture of To\""en--Vezzosi on existence of circle-invariant traces.
Underlying our construction is a calculation of the factorization homology over
the circle of the walking adjunction in terms of the paracyclic category of
Getzler--Jones: $ \int_{{\mathbb S}^1} {\sf Adj} ~\simeq~
{\bDelta_{\circlearrowleft}}^{\triangleleft\!\triangleright} ~. $ This
calculation exhibits a form of Poincar\'e duality for 1-dimensional
factorization homology."
math,"Bimonoidal Categories, $E_n$-Monoidal Categories, and Algebraic
  $K$-Theory","Bimonoidal categories are categorical analogues of rings without additive
inverses. They have been actively studied in category theory, homotopy theory,
and algebraic $K$-theory since around 1970. There is an abundance of new
applications and questions of bimonoidal categories in mathematics and other
sciences. This work provides a unified treatment of bimonoidal and higher
ring-like categories, their connection with algebraic $K$-theory and homotopy
theory, and applications to quantum groups and topological quantum computation.
With ample background material, extensive coverage, detailed presentation of
both well-known and new theorems, and a list of open questions, this work is a
user friendly resource for beginners and experts alike."
math,Enhancing the filtered derived category,"The filtered derived category of an abelian category has played a useful role
in subjects including geometric representation theory, mixed Hodge modules, and
the theory of motives. We develop a natural generalization using current
methods of homotopical algebra, in the formalisms of stable
infinity-categories, stable model categories, and pretriangulated,
idempotent-complete dg categories. We characterize the filtered stable
infinity-category Fil(C) of a stable infinity-category C as the left exact
localization of sequences in C along the infinity-categorical version of
completion (and prove analogous model and dg category statements). We also
spell out how these constructions interact with spectral sequences and monoidal
structures. As examples of this machinery, we construct a stable model category
of filtered D-modules and develop the rudiments of a theory of filtered operads
and filtered algebras over operads."
math,Arithmetic Aspects of Bianchi Groups,"We discuss several arithmetic aspects of Bianchi groups, especially from a
computational point of view. In particular, we consider computing the homology
of Bianchi groups together with the Hecke action, connections with automorphic
forms, abelian varieties, Galois representations and the torsion in the
homology of Bianchi groups. Along the way, we list several open problems and
conjectures, survey the related literature, presenting concrete examples and
numerical data."
math,Localized strict topologies on multiplier algebras of pro-$C^*$-algebras,"The bounded localization $\beta_b$ of a locally convex topology $\beta$ is
defined as the finest locally convex topology agreeing with $\beta$ on all
bounded sets. We show that the strict topology on the multiplier algebra of a
bornological pro-$C^*$-algebras equals its own localization, generalizing the
analogous result due to Taylor for multiplier algebras of plain $C^*$-algebras.
  We also (a) characterize the barreled commutative unital pro-$C^*$-algebras
as those of continuous functions on functionally Hausdorff spaces whose
relatively pseudocompact subsets are relatively compact, equipped with the
topology of uniform convergence on compact subsets, and (b) describe a
contravariant equivalence between the category of commutative unital
pro-$C^*$-algebras and a category of Tychonoff (rather than functionally
Hausdorff) topological spaces."
math,Gelfand-type duality for commutative von Neumann algebras,"We show that the following five categories are equivalent: (1) the opposite
category of commutative von Neumann algebras; (2) compact strictly localizable
enhanced measurable spaces; (3) measurable locales; (4) hyperstonean locales;
(5) hyperstonean spaces. This result can be seen as a measure-theoretic
counterpart of the Gelfand duality between commutative unital C*-algebras and
compact Hausdorff topological spaces."
math,(Co)module algebras and their generalizations,"This manuscript is an extended version of the author's habilitation thesis
defended on May 21, 2021 at M.V. Lomonosov Moscow State University. It is
devoted to the study of (co)stability of radicals, existence of (co)invariant
Levi and Wedderburn decompositions, structure of the corresponding simple
algebras and codimension growth of polynomial identities in (co)module algebras
over bi- and Hopf algebras and their generalizations. The main difference
between this manuscript and the ""official"" thesis are additional chapters
dealing with equivalences of gradings and Hopf algebra (co)actions, V-universal
(co)acting bi- and Hopf algebras and related categorical questions. (In
Russian.)"
math,"Support and vanishing for non-Noetherian rings and tensor triangulated
  categories","We define and characterise small support for complexes over non-Noetherian
rings and in this context prove a vanishing theorem for modules. Our definition
of support makes sense for any rigidly compactly generated tensor triangulated
category. Working in this generality, we establish basic properties of support
and investigate when it detects vanishing. We use pointless topology to relate
support, the topology of the Balmer spectrum, and the structure of the
idempotent Bousfield lattice."
math,Pre-Lie deformation theory,"In this paper, we develop the deformation theory controlled by pre-Lie
algebras; the main tool is a new integration theory for pre-Lie algebras. The
main field of application lies in homotopy algebra structures over a Koszul
operad; in this case, we provide a homotopical description of the associated
Deligne groupoid. This permits us to give a conceptual proof, with complete
formulae, of the Homotopy Transfer Theorem by means of gauge action. We provide
a clear explanation of this latter ubiquitous result: there are two gauge
elements whose action on the original structure restrict its inputs and
respectively its output to the homotopy equivalent space. This implies that a
homotopy algebra structure transfers uniformly to a trivial structure on its
underlying homology if and only if it is gauge trivial; this is the ultimate
generalization of the $dd^c$-lemma."
math,Connected gradings and fundamental group,"The main purpose of this paper is to provide explicit computations of the
fundamental group of several algebras. For this purpose, given a $k$-algebra
$A$, we consider the category of all connected gradings of $A$ by a group $G$
and we study the relation between gradings and Galois coverings. This
theoretical tool gives information about the fundamental group of $A$, which
allows its computation using complete lists of gradings."
math,"Lie, associative and commutative quasi-isomorphism","Over a field of characteristic zero, we show that two commutative
differential graded (dg) algebras are quasi-isomorphic if and only if they are
quasi-isomorphic as associative dg algebras. This answers a folklore problem in
rational homotopy theory, showing that the rational homotopy type of a space is
determined by its associative dg algebra of rational cochains. We also show a
Koszul dual statement, under an additional completeness hypothesis: two
homotopy complete dg Lie algebras whose universal enveloping algebras are
quasi-isomorphic as associative dg algebras must themselves be
quasi-isomorphic. The latter result applies in particular to nilpotent Lie
algebras (not differential graded), in which case it says that two nilpotent
Lie algebras whose universal enveloping algebras are isomorphic as associative
algebras must be isomorphic."
math,"Higher limits, homology theories and fr-codes","This text is based on lectures given by authors in summer 2015. It contains
an introduction to the theory of limits over the category of presentations,
with examples of different well-known functors like homology or derived
functors of non-additive functors in a form of derived limits. The theory of
so-called ${\bf fr}$-codes also is developed. This is a method how different
functors from the category of groups to the category of abelian groups, such as
group homology, tensor products of abelianization, can be coded as sentences in
the alphabet with two symbols ${\bf f}$ and ${\bf r}$."
math,The Whitehead group of (almost) extra-special p-groups with p odd,"Let p be an odd prime number. We describe the Whitehead group of all
extra-special and almost extra-special p-groups. For this we compute, for any
finite p-group P , the subgroup Cl\_1 (ZP) of SK\_1 (ZP), in terms of a genetic
basis of P. We also introduce a deflation map Cl\_1 (ZP) $\rightarrow$ Cl\_1
(Z(P/N)) , for a normal subgroup N of P , and show that it is always
surjective. Along the way, we give a new proof of the result describing the
structure of SK\_1 (ZP), when P is an elementary abelian p-group."
math,"K-theory, genotypes, and biset functors","Let p be an odd prime number. In this paper, we show that the genome
$\Gamma(P)$ of a finite $p$-group $P$, defined as the direct product of the
genotypes of all rational irreducible representations of $P$, can be recovered
from the first group of $K$-theory $K_1(\mathbb{Q}P)$. It follows that the
assignment $P \to \Gamma(P)$ is a $p$-biset functor. We give an explicit
formula for the action of bisets on $\Gamma$, in terms of generalized transfers
associated to left free bisets. Finally, we show that $\Gamma$ is a rational
$p$-biset functor, i.e. that $\Gamma$ factors through the Roquette category of
finite $p$-groups."
math,Non-Commutative Geometry Methods for Group C*-Algebras,"This research notes is intended to provide a quick introduction to the
subject. We expose a K-theoretic approach to study group C*-algebras: started
in the elementary part, with one example of description of the structure of
C*-algebras of the group of affine transformations of the real straight line,
continued then for special classes of solvable and nilpotent Lie groups. In the
second advanced part, we introduced the main tools of the theory. In
particular, the conception of multidimensional geometric quantization and the
index of group C*-algebras were created and developed."
math,On Amiot's conjecture,"In a survey paper in 2011, Amiot proposed a conjectural characterisation of
the cluster categories which were conceived in the mid 2000s to lift the
combinatorics of Fomin-Zelevinsky's cluster algebras to the categorical level.
This paper is devoted to a proof of (a variant of) her conjecture. More
generally, cluster categories admit higher dimensional and relative variants,
the so-called Higgs categories recently introduced by Wu. We also prove
higher-dimensional and relative variants of the conjecture."
math,Stereotype Dualities in Geometry,"This book contains the material of my research on stereotype duality theories
in geometry. It was intended as a continuation of my recently published
monograph in De Gruyter on stereotype spaces and algebras."
math,A general framework for homotopic descent and codescent,"In this paper we elaborate a general homotopy-theoretic framework in which to
study problems of descent and completion and of their duals, codescent and
cocompletion. Our approach to homotopic (co)descent and to derived
(co)completion can be viewed as $\infty$-category-theoretic, as our framework
is constructed in the universe of simplicially enriched categories, which are a
model for $(\infty, 1)$-categories.
  We provide general criteria, reminiscent of Mandell's theorem on
$E_{\infty}$-algebra models of $p$-complete spaces, under which homotopic
(co)descent is satisfied. Furthermore, we construct general descent and
codescent spectral sequences, which we interpret in terms of derived
(co)completion and homotopic (co)descent.
  We show that a number of very well-known spectral sequences, such as the
unstable and stable Adams spectral sequences, the Adams-Novikov spectral
sequence and the descent spectral sequence of a map, are examples of general
(co)descent spectral sequences. There is also a close relationship between the
Lichtenbaum-Quillen conjecture and homotopic descent along the
Dwyer-Friedlander map from algebraic K-theory to \'etale K-theory. Moreover,
there are intriguing analogies between derived cocompletion (respectively,
completion) and homotopy left (respectively, right) Kan extensions and their
associated assembly (respectively, coassembly) maps."
math,Chain duality for categories over complexes,"We show that the additive category of chain complexes parametrized by a
finite simplicial complex $K$ forms a category with chain duality. This fact,
never fully proven in the original reference, is fundamental for Ranicki's
algebraic formulation of the surgery exact sequence of Sullivan and Wall, and
his interpretation of the surgery obstruction map as the passage from local
Poincar\'e duality to global Poincar\'e duality. Our paper also gives a new,
conceptual, and geometric treatment of chain duality on $K$-based chain
complexes."
math,A K-theory spectrum for cobordism cut and paste groups,"Cobordism groups and cut-and-paste groups of manifolds arise from imposing
two different relations on the monoid of manifolds under disjoint union. By
imposing both relations simultaneously, a cobordism cut and paste group
$\overline{\mathrm{SK}}_n$ is defined. In this paper, we extend this definition
to manifolds with boundary obtaining $\overline{\mathrm{SK}}^{\partial}_n$ and
study the relationship of this group to an appropriately defined cobordism
group of manifolds with boundary. The main results are the construction of a
spectrum that recovers on $\pi_0$ the cobordism cut and paste groups of
manifolds with boundary, $\overline{\mathrm{SK}}^{\partial}_n$, and a map of
spectra that lifts the canonical quotient map $\mathrm{SK}^{\partial}_n
\rightarrow \overline{\mathrm{SK}}^{\partial}_n$."
math,Decomposition theorems for asymptotic property C and property A,"We combine aspects of the notions of finite decomposition complexity and
asymptotic property C into a notion that we call finite APC-decomposition
complexity. Any space with finite decomposition complexity has finite
APC-decomposition complexity and any space with asymptotic property C has
finite APC-decomposition complexity. Moreover, finite APC-decomposition
complexity implies property A for metric spaces. We also show that finite
APC-decomposition complexity is preserved by direct products of groups and
spaces, amalgamated products of groups, and group extensions, among other
constructions."
math,"Permanence properties of property A and coarse embeddability for locally
  compact groups","If $H$ is a lattice in a locally compact second countable group $G$, then we
show that $G$ has property A (respectively is coarsely embeddable into Hilbert
space) if and only if $H$ has property A (respectively is coarsely embeddable
into Hilbert space). Moreover, we show three interesting generalizations of
this result. If $H$ is a closed subgroup of $G$ that is co-amenable in $G$, and
if $H$ has property A (respectively, is coarsely embeddable into Hilbert
space), then we show that $G$ has property A (respectively, is coarsely
embeddable into Hilbert space). We also show that an extension of property A
groups still has property A. On the coarse embeddability side, we show that if
$\{e\}\rightarrow H\rightarrow G\rightarrow Q\rightarrow\{e\}$ is a short exact
sequence, and if either $H$ is coarsely embeddable into Hilbert space and $Q$
has property A, or $H$ is compact and $Q$ is coarsely embeddable into Hilbert
space, then $G$ is coarsely embeddable into Hilbert space. We extend the theory
of measure equivalence to locally compact non-unimodular groups. In a natural
way, we can also define measure equivalence subgroups. We show that property A
and uniform embeddability into Hilbert space pass to measure equivalence
subgroups. Using the same techniques, we show that also the Haagerup property,
weak amenability and the weak Haagerup property pass to measure equivalence
subgroups."
math,Intermediate rank and property RD,"We introduce concepts of intermediate rank for countable groups that
""interpolate"" between consecutive values of the classical (integer-valued)
rank. Various classes of groups are proved to have intermediate rank behaviors.
We are especially interested in interpolation between rank 1 and rank 2. For
instance, we construct groups ""of rank 7/4"". Our setting is essentially that of
non positively curved spaces, where concepts of intermediate rank include
polynomial rank, local rank, and mesoscopic rank. The resulting framework has
interesting connections to operator algebras. We prove property RD in many
cases where intermediate rank occurs. This gives a new family of groups
satisfying the Baum-Connes conjecture. We prove that the reduced $C^*$-algebras
of groups of rank 7/4 have stable rank 1."
math,"Topological Representation of Precontact Algebras and a Connected
  Version of the Stone Duality Theorem -- I","The notions of a {\em 2-precontact space}\/ and a {\em 2-contact space}\/ are
introduced. Using them, new representation theorems for precontact and contact
algebras are proved. It is shown that there are bijective correspondences
between such kinds of algebras and such kinds of spaces. As applications of the
obtained results, we get new connected versions of the Stone Duality Theorems
for Boolean algebras and for complete Boolean algebras, as well as a
Smirnov-type theorem for a kind of compact $T_0$-extensions of compact
Hausdorff extremally disconnected spaces. We also introduce the notion of a
{\em Stone adjacency space}\/ and using it, we prove another representation
theorem for precontact algebras. We even obtain a bijective correspondence
between the class of all, up to isomorphism, precontact algebras and the class
of all, up to isomorphism, Stone adjacency spaces."
math,"The local spectrum of the Dirac operator for the universal cover of
  $SL_2(\mathbb R)$","Using representation theory, we compute the spectrum of the Dirac operator on
the universal covering group of $SL_2(\mathbb R)$, exhibiting it as the
generator of $KK^1(\mathbb C, \mathfrak A)$, where $\mathfrak A$ is the reduced
$C^*$-algebra of the group. This yields a new and direct computation of the
$K$-theory of $\mathfrak A$. A fundamental role is played by the
limit-of-discrete-series representation, which is the frontier between the
discrete and the principal series of the group. We provide a detailed analysis
of the localised spectra of the Dirac operator and compute the Dirac
cohomology."
math,"Ample groupoids, topological full groups, algebraic K-theory spectra and
  infinite loop spaces","Inspired by work of Szymik and Wahl on the homology of Higman-Thompson
groups, we establish a general connection between ample groupoids, topological
full groups, algebraic K-theory spectra and infinite loop spaces, based on the
construction of small permutative categories of compact open bisections. This
allows us to analyse homological invariants of topological full groups in terms
of homology for ample groupoids.
  Applications include complete rational computations, general vanishing and
acyclicity results for group homology of topological full groups as well as a
proof of Matui's AH-conjecture for all minimal, ample groupoids with
comparison."
math,The slice Burnside ring and the section Burnside ring of a finite group,"This paper introduces two new Burnside rings for a finite group $G$, called
the slice Burnside ring and the section Burnside ring. They are built as
Grothendieck rings of the category of morphisms of $G$-sets, and of Galois
morphisms of $G$-sets, respectively. The well known results on the usual
Burnside ring, concerning ghost maps, primitive idempotents, and description of
the prime spectrum, are extended to these rings. It is also shown that these
two rings have a natural structure of Green biset functor. The functorial
structure of unit groups of these rings is also discussed."
math,"Inequality on the optimal constant of Young's convolution inequality for
  locally compact groups and their closed subgroups","We define the optimal constant $Y ( p_1 , p_2 ; G )$ of Young's convolution
inequality as \begin{align}
  Y ( p_1 , p_2 ; G ) := \sup \{ \| \phi_1 * ( \phi_2 \Delta^{1 / p_1'} ) \|_p
\mid \phi_1 , \phi_2 \colon G \to \mathbb{C} , \; \| \phi_1 \|_{p_1} = \|
\phi_2 \|_{p_2} = 1 \} \end{align} for a locally compact group $G$ and $1 \leq
p_1 , p_2 , p \leq \infty$ with $1 / p_1 + 1 / p_2 = 1 + 1 / p$. Here $p'$ is
the H\""{o}lder conjugate of $p$, $\| \cdot \|_{ p }$ is the $L^p$-norm on a
left Haar measure, and $\Delta \colon G \to \mathbb{R}_{> 0}$ is the modular
function. The main result of this paper is that $Y ( p_1 , p_2 ; G ) \leq Y (
p_1 , p_2 ; H )$ for any closed subgroup $H \subset G$. It follows from this
inequality that $Y ( p_1 , p_2 ; G ) \leq Y ( p_1 , p_2 ; \mathbb{R} )^{ \dim G
- r ( G ) }$ for any connected Lie group $G$ such that the center of the
semisimple part is a finite group such as connected linear Lie groups and
connected solvable Lie groups, where $r ( G )$ is the dimension of the maximal
compact subgroups of $G$."
math,"Constructing universally small subsets of a given packing index in
  Polish groups","A subset of a Polish space $X$ is called universally small if it belongs to
each ccc $\sigma$-ideal with Borel base on $X$. Under CH in each uncountable
Abelian Polish group $G$ we construct a universally small subset $A_0\subset G$
such that $|A_0\cap gA_0|=\mathfrak c$ for each $g\in G$. For each cardinal
number $\kappa\in[5,\mathfrak c^+]$ the set $A_0$ contains a universally small
subset $A$ of $G$ with sharp packing index
$\pack^\sharp(A_\kappa)=\sup\{|\mathcal D|^+:\mathcal D\subset \{gA\}_{g\in G}$
is disjoint$\}$ equal to $\kappa$."
math,The Eta-invariant and Pontryagin duality in K-theory,"The topological significance of the spectral Atiyah-Patodi-Singer
eta-invariant is investigated under the parity conditions of P. Gilkey. We show
that twice the fractional part of the invariant is computed by the linking
pairing in K-theory with the orientation bundle of the manifold. The Pontrjagin
duality implies the nondegeneracy of the linking form. An example of a
nontrivial fractional part for an even-order operator is presented. This result
answers the question of P. Gilkey (1989) concerning the existence of even-order
operators on odd-dimensional manifolds with nontrivial fractional part of
eta-invariant."
math,Pre-triangulated categories are triangulated,"We prove a stronger version of the octahedral axiom in a pre-triangulated
category. The proof uses a new lemma about exact sequences in pointed additive
categories which is based on a weak converse of the snake lemma."
math,Segal Enriched Categories I,"We develop a theory of enriched categories over a (higher) category M
equipped with a class W of morphisms called homotopy equivalences. We call them
Segal M_W -categories. Our motivation was to generalize the notion of
""up-to-homotopy monoids"" in a monoidal category M, introduced by Leinster. The
formalism adopted generalizes the classical Segal categories and extends the
theory of enriched category over a bicategory. In particular we have a linear
version of Segal categories which did not exist so far. Our goal in this paper
is to present the theory and provide some examples. Applications are reserved
for the future."
math,Grothendieck-Neeman duality and the Wirthmüller isomorphism,"We clarify the relationship between Grothendieck duality \`a la Neeman and
the Wirthm\""uller isomorphism \`a la Fausk-Hu-May. We exhibit an interesting
pattern of symmetry in the existence of adjoint functors between compactly
generated tensor-triangulated categories, which leads to a surprising
trichotomy: There exist either exactly three adjoints, exactly five, or
infinitely many. We highlight the importance of so-called relative dualizing
objects and explain how they give rise to dualities on canonical subcategories.
This yields a duality theory rich enough to capture the main features of
Grothendieck duality in algebraic geometry, of generalized Pontryagin-Matlis
duality \`a la Dwyer-Greenlees-Iyengar in the theory of ring spectra, and of
Brown-Comenetz duality \`a la Neeman in stable homotopy theory."
math,"Higher traces, noncommutative motives, and the categorified Chern
  character","We propose a categorification of the Chern character that refines earlier
work of To\""en and Vezzosi and of Ganter and Kapranov. If X is an algebraic
stack, our categorified Chern character is a symmetric monoidal functor from a
category of mixed noncommutative motives over X, which we introduce, to
S1-equivariant perfect complexes on the derived free loop stack LX. As an
application of the theory, we show that To\""en and Vezzosi's secondary Chern
character factors through secondary K-theory. Our techniques depend on a
careful investigation of the functoriality of traces in symmetric monoidal
(infinity,n)-categories, which is of independent interest."
math,"Picard groups, weight structures, and (noncommutative) mixed motives","We develop a general theory which enables the computation of the Picard group
of a symmetric monoidal triangulated category, equipped with a weight
structure, in terms of the Picard group of the associated heart. As an
application, we compute the Picard group of several categories of motivic
nature - mixed Artin motives, mixed Artin-Tate motives, motivic spectra,
noncommutative mixed Artin motives, noncommutative mixed motives of central
simple algebras, noncommutative mixed motives of separable algebras - as well
as the Picard group of the derived categories of symmetric ring spectra."
math,Universal cohomology theories,"We furnish any category of a universal (co)homology theory. Universal
(co)homologies and universal relative (co)homologies are obtained by showing
representability of certain functors and take values in $R$-linear abelian
categories of motivic nature, where $R$ is any commutative unitary ring.
Universal homology theory on the one point category yields ""hieratic""
$R$-modules, i.e. the indization of Freyd's free abelian category on $R$.
Grothendieck $\partial$-functors and satellite functors are recovered as
certain additive relative homologies on an abelian category for which we also
show the existence of universal ones."
math,On irreducible triangulations of punctured and pinched surfaces,"A triangulation of a punctured or pinched surface is irreducible if no edge
can be shrunk without producing multiple edges or changing the topological type
of the surface. The finiteness of the set of (non-isomorphic) irreducible
triangulations of any punctured surface is established. Complete lists of
irreducible triangulations are determined for the M\""obius band (6 in number)
and the pinched torus (2 in number). All the non-isomorphic combinatorial types
(20 in number) of triangulations of the projective plane with up to 8 vertices
are determined."
math,The pong algebra,"In an earlier paper, we described bordered algebras for knot Floer homology.
In this paper, we introduce a differential graded algebra, the pong algebra and
compute the A-infinity structure on its homology."
math,"Sur l'homologie des groupes orthogonaux et symplectiques à
  coefficients tordus","We compute the stable homology of orthogonal and symplectic groups over a
finite field k with coefficients coming from an usual endofunctor F of k-vector
spaces (exterior, symmetric, divided powers...), that is, for all natural
integer i, we compute the colimits of the vector spaces $H_i(O_{n,n}(k) ;
F(k^{2n}))$ and $H_i(Sp_{2n}(k) ; F(k^{2n}))$. In this situation, the
stabilization is a classical result of Charney. We give a formal framework to
connect stable homology of some families of groups and homology of suitable
small categories thanks to a spectral sequence which collapses in several
cases. By our purely algebraic methods (i.e. without stable K-theory) we obtain
again results of Betley for stable homology of linear groups and symmetric
groups. For orthogonal and symplectic groups over a field we prove a
categorical result for vector spaces equipped with quadratic or alternating
forms and use powerful cancellation results known in homology of functors
(Suslin, Scorichenko, Djament) to deduce a spectacular simplification of the
second sheet of our general spectral sequence. When we consider the orthogonal
and symplectic groups over a finite field and we take coefficients with values
in vector spaces over the same field, we can compute the second sheet of the
spectral sequence thanks to classical results: homological cancellation with
trivial coefficients (Quillen, Fiedorowicz-Priddy) and calculation of torsion
groups between usual functors (Franjou-Friedlander-Scorichenko-Suslin,
Chalupnik)."
math,Coherent presentations of Artin monoids,"We compute coherent presentations of Artin monoids, that is presentations by
generators, relations, and relations between the relations. For that, we use
methods of higher-dimensional rewriting that extend Squier's and Knuth-Bendix's
completions into a homotopical completion-reduction, applied to Artin's and
Garside's presentations. The main result of the paper states that the so-called
Tits-Zamolodchikov 3-cells extend Artin's presentation into a coherent
presentation. As a byproduct, we give a new constructive proof of a theorem of
Deligne on the actions of an Artin monoid on a category."
math,"2-Groups, 2-Characters, and Burnside Rings","We study 2-representations, i.e., actions of 2-groups on 2-vector spaces. Our
main focus is character theory for 2-representations. To this end we employ the
technique of extended Burnside rings. Our main theorem is that the
Ganter-Kapranov 2-character is a particular mark homomorphism of the Burnside
ring. As an application we give a new proof of Osorno formula for the
Ganter-Kapranov 2-character of a finite group."
math,Central stability homology,"We give a new categorical way to construct the central stability homology of
Putman and Sam and explain how it can be used in the context of representation
stability and homological stability. In contrast to them, we cover categories
with infinite automorphism groups. We also connect central stability homology
to Randal-Williams and Wahl's work on homological stability. We also develop a
criterion that implies that functors that are polynomial in the sense of
Randal-Williams and Wahl are centrally stable in the sense of Putman."
math,Model categories structures from rigid objects in exact categories,"Let $\mathcal{E}$ be a weakly idempotent complete exact category with enough
injective and projective objects. Assume that $\mathcal{M} \subseteq
\mathcal{E}$ is a rigid, contravariantly finite subcategory of $\mathcal{E}$
containing all the injective and projective objects, and stable under taking
direct sums and summands. In this paper, $\mathcal{E}$ is equipped with the
structure of a prefibration category with cofibrant replacements. As a
corollary, we show, using the results of Demonet and Liu in \cite{DL}, that the
category of finite presentation modules on the costable category
$\overline{\mathcal{M}}$ is a localization of $\mathcal{E}$. We also deduce
that $\mathcal{E} \to \mathrm{mod}\overline{\mathcal{M}}$ admits a calculus of
fractions up to homotopy. These two corollaries are analogues for exact
categories of results of Buan and Marsh in \cite{BM2}, \cite{BM1} (see also
\cite{Be}) that hold for triangulated categories.
  If $\mathcal{E}$ is a Frobenius exact category, we enhance its structure of
prefibration category to the structure of a model category (see the article of
Palu in \cite{Palu} for the case of triangulated categories). This last result
applies in particular when $\mathcal{E}$ is any of the Hom-finite Frobenius
categories appearing in relation to cluster algebras."
math,Mackey 2-functors and Mackey 2-motives,"We study collections of additive categories $\mathcal{M}(G)$, indexed by
finite groups $G$ and related by induction and restriction in a way that
categorifies usual Mackey functors. We call them `Mackey 2-functors'. We
provide a large collection of examples in particular thanks to additive
derivators. We prove the first properties of Mackey 2-functors, including
separable monadicity of restriction to subgroups. We then isolate the initial
such structure, leading to what we call `Mackey 2-motives'. We also exhibit a
convenient calculus of morphisms in Mackey 2-motives, by means of string
diagrams. Finally, we show that the 2-endomorphism ring of the identity of $G$
in this 2-category of Mackey 2-motives is isomorphic to the so-called crossed
Burnside ring of $G$."
math,On morphisms killing weights and Hurewicz-type theorems,"We study ""canonical weight decompositions"" slightly generalizing that defined
by J. Wildeshaus. For an triangulated category $C$, any integer $n$, and a
weight structure $w$ on $C$ a triangle $LM\to M\to RM\to LM[1]$, where $LM$ is
of weights at most $m-1$ and $RM$ is of weights at least $n+1$ for some $m\le
n$, is determined by $M$ if exists. This happens if and only if the weight
complex $t(M)\in Obj K(Hw)$ ($Hw$ is the heart of $w$) is homotopy equivalent
to a complex with zero terms in degrees $-n,\dots, -m$; hence this condition
can be ""detected"" via pure functors. One can also take $m=-\infty$ or
$n=+\infty$ to obtain that the weight complex functor is ""conservative and
detects weights up to objects of infinitely small and infinitely large
weights""; this is a significant improvement over previously known bounded
conservativity results. Applying this statement we ""calculate intersections of
purely generated subcategories"" and prove that certain weight-exact functors
are conservative up to weight-degenerate objects. The main tool is the new
interesting notion of morphisms killing weights $m,\dots, n$ that we study in
detail as well.
  We apply general results to equivariant stable homotopy categories and
spherical weight structures for them (as introduced in the previous paper) and
obtain a certain converse to the (equivariant) stable Hurewicz theorem. In
particular, the singular homology of a spectrum $E$ vanishes in negative
degrees if and only if $E$ is an extension of a connective spectrum by an
acyclic one."
math,The bivariant parasimplicial $\mathsf{S}_{\bullet}$-construction,"Coherent strings of composable morphisms play an important role in various
important constructions in abstract stable homotopy theory (for example
algebraic K-theory or higher Toda brackets) and in the representation theory of
finite dimensional algebras (as representations of Dynkin quivers of type A).
In a first step we will prove a strong comparison result relating composable
strings of morphisms and coherent diagrams on cubes with support on a path from
the initial to the final object.
  We observe that both structures are equivalent (by passing to higher
analogues of mesh categories) to distinguished coherent diagrams on special
classes of morphism objects in the 2-category of parasimplices. Furthermore, we
show that the notion of distinguished coherent diagrams generalizes well to
arbitrary morphism objects in this 2-category. The resulting categories of
coherent diagrams lead to higher versions of the
$\mathsf{S}_{\bullet}$-construction and are closely related to representations
of higher Auslander algebras of Dynkin quivers of type A.
  Understanding these categories and the functors relating them in general will
require a detailed analysis of the 2-category of parasimplices as well as basic
results from abstract cubical homotopy theory (since subcubes of distinguished
diagrams very often turn out to be bicartesian). Finally, we show that the
previous comparison result extends to a duality theorem on general categories
of distinguished coherent diagrams, as a special case leading to some new
derived equivalences between higher Auslander algebras."
math,Universal property of triangulated derivators via Keller's towers,"In his thesis B. Keller solved the universal problem of the extension of an
exact category to its (bounded) derived category by introducing the notions of
tower of exact and triangulated categories and proving the universal property
in this setting. In this note we show that his result extends to the
corresponding universal problem for Grothendieck's derivators."
math,Derived Character Maps of Groups Representations,"In this paper, we construct and study derived character maps of
finite-dimensional representations of $\infty$-groups. As models for
$\infty$-groups we take homotopy simplicial groups, i.e. homotopy simplicial
algebras over the algebraic theory of groups (in the sense of Badzioch). We
define cyclic, symmetric and representation homology for `group algebras' over
such groups and construct canonical trace maps relating these homology
theories. In the case of one-dimensional representations, we show that our
trace maps are of topological origin: they are induced by natural maps of
(iterated) loop spaces that are well studied in homotopy theory. Using this
topological interpretation, we deduce some algebraic results about
representation homology: in particular, we prove that the symmetric homology of
group algebras and one-dimensional representation homology are naturally
isomorphic, provided the base ring $k$ is a field of characteristic zero. We
also study the behavior of the derived character maps of $n$-dimensional
representations in the stable limit as $ n\to \infty$, in which case we show
that they `converge' to become isomorphisms."
math,Automorphism groups of dense subgroups of R^n,"By an automorphism of a topological group G we mean an isomorphism of G onto
itself which is also a homeomorphism. In this article, we study the
automorphism group Aut(G) of a dense subgroup G of R^n, n>=1. We show that
Aut(G) can be naturally identified with the subgroup I(G)={A in GL(n,R): G A
=G} of the group GL(n,R) of all non-degenerated (n x n)-matrices over R, where
G A={g A:g in G}. We describe $I(G) for many dense subgroups G of either R or
R^2. We consider also an inverse problem of which symmetric subgroups of
GL(n,R) can be realized as I(G) for some dense subgroup G of R^n. For example,
for n>=2, we show that the group {A in GL(n,R): det A=+-1} cannot be realized
in this way. The realization problem is quite non-trivial even in the
one-dimensional case and has deep connections to number theory."
math,Hopf-type Theorems For $f$-neighbors,"We work within the framework of a program aimed at exploring various extended
versions for theorems from a class containing Borsuk-Ulam type theorems, some
fixed point theorems, the KKM lemma, Radon, Tverberg, and Helly theorems. In
this paper we study variations of the Hopf theorem concerning continuous maps
of a compact Riemannian manifold $M$ of dimension $n$ to $\mathbb{R}^n$. We
investigate the case of maps $f\colon M \to \mathbb{R}^m$ with $n < m$ and
introduce several notions of varied types of $f$-neighbors, which is a pair of
distinct points in $M$ such that $f$ takes it to a 'small' set of some type.
Next for each type, we ask what distances on $M$ are realized as distances
between $f$-neighbors of this type and study various characteristics of this
set of distances. One of our main results is as follows. Let $f\colon M \to
\mathbb{R}^{m}$ be a continuous map. We say that two distinct points $a$ and
$b$ in $M$ are visual $f$-neighbors if the segment in $\mathbb{R}^{m}$ with
endpoints $f(a)$ and $f(b)$ intersects $f(M)$ only at $f(a)$ and $f(b)$. Then
the set of distances that are realized as distances between visual
$f$-neighbors is infinite. Besides we generalize the Hopf theorem in a
quantitative sense."
math,Axiomatization of geometry employing group actions,"The aim of this paper is to develop a new axiomatization of planar geometry
by reinterpreting the original axioms of Euclid. The basic concept is still
that of a line segment but its equivalent notion of betweenness is viewed as a
topological, not a metric concept. That leads quickly to the notion of
connectedness without any need to dwell on the definition of topology. In our
approach line segments must be connected. Lines and planes are unified via the
concept of separation: lines are separated into two components by each point,
planes contain lines that separate them into two components as well. We add a
subgroup of bijections preserving line segments and establishing unique
isomorphism of basic geometrical sets, and the axiomatic structure is complete.
Of fundamental importance is the Fixed Point Theorem that allows for creation
of the concepts of length and congruency of line segments. The resulting
structure is much more in sync with modern science than other axiomatic
approaches to planar geometry. For instance, it leads naturally to the Erlangen
Program in geometry. Our Conditions of Homogeneity and Rigidity have two
interpretations. In physics, they correspond to the basic tenet that
independent observers should arrive at the same measurement and are related to
boosts in special relativity. In geometry, they mean uniqueness of congruence
for certain geometrical figures.
  Another thread of the paper is the introduction of boundary at infinity, an
important concept of modern mathematics, and linking of Pasch Axiom to endowing
boundaries at infinity with a natural relation of betweenness. That way
spherical geometry can be viewed as geometry of boundaries at infinity."
math,"Roe C*-algebra for groupoids and generalized Lichnerowicz Vanishing
  theorem for foliated manifolds","We introduce the concept of Roe C*-algebra for a locally compact groupoid
whose unit space is in general not compact, and that is equipped with an
appropriate coarse structure and Haar system. Using Connes' tangent groupoid
method, we introduce an analytic index for an elliptic differential operator on
a Lie groupoid equipped with additional metric structure, which takes values in
the K-theory of the Roe C*-algebra. We apply our theory to derive a
Lichnerowicz type vanishing result for foliations on open manifolds."
math,Gorenstein complexes and recollements from cotorsion pairs,"We describe a general correspondence between injective (resp. projective)
recollements of triangulated categories and injective (resp. projective)
cotorsion pairs. This provides a model category description of these
recollement situations. Our applications focus on displaying several
recollements that glue together various full subcategories of K(R), the
homotopy category of chain complexes of modules over a general ring R. When R
is (left) Noetherian ring, these recollements involve complexes built from the
Gorenstein injective modules. When R is a (left) coherent ring for which all
flat modules have finite projective dimension we obtain the duals. These
results extend to a general ring R by replacing the Gorenstein modules with the
Gorenstein AC-modules introduced recently in the work of Bravo-Gillespie-Hovey.
We also see that in any abelian category with enough injectives, the Gorenstein
injective objects enjoy a maximality property in that they contain every other
class making up the right half of an injective cotorsion pair."
math,"Adjoints, wrapping, and morphisms at infinity","For a localization of a smooth proper category, we show that morphisms in
Efimov's algebraizable categorical formal punctured neighborhood of infinity
can be computed using the natural cone between right and left adjoints of the
localization functor. In particular, this recovers the following result of
Ganatra--Gao--Venkatesh: morphisms in categorical formal punctured
neighborhoods of wrapped Fukaya categories are computed by Rabinowitz wrapping."
math,"Measures on Cantor sets: the good, the ugly, the bad","We translate Akin's notion of {\it good} (and related concepts) from measures
on Cantor sets to traces on dimension groups, and particularly for invariant
measures of minimal homeomorphisms (and their corresponding simple dimension
groups), this yields characterizations and examples, which translate back to
the original context. Good traces on a simple dimension group are characterized
by their kernel having dense image in their annihilating set of affine
functions on the trace space; this makes it possible to construct many examples
with seemingly paradoxical properties. In order to study the related property
of {\it refinability,} we consider goodness for sets of measures (traces on
dimension groups), and obtain partial characterizations in terms of (special)
convex subsets of Choquet simplices. These notions also very closely related to
unperforation of quotients of dimension groups by convex subgroups (that are
not order ideals), and we give partial characterizations. Numerous examples
illustrate the results."
math,Algebraic Kasparov K-theory. I,"This paper is to construct unstable, Morita stable and stable bivariant
algebraic Kasparov $K$-theory spectra of $k$-algebras. These are shown to be
homotopy invariant, excisive in each variable $K$-theories. We prove that the
spectra represent universal unstable, Morita stable and stable bivariant
homology theories respectively."
math,"Categories of complex variations of Hodge structure over compact K""ahler
  manifolds","We give a complex polarized variation of Hodge structure over a compact
K""ahler manifold $M$ which controls all finite-dimensional complex polarized
variations of Hodge structure over $M$ and their tensor relations. As a
corollary, we obtain the cohomology algebra with values in a local system
admitting multiplicative Hodge structures."
math,"Non-Commutative classifying spaces of groups via quasi-topologies and
  pro-$C^*$-algebras","For a completely Hausdorff quasi-topological group $G$, we construct a
universal pro-$C^*$-algebra $C(E^+G)$ as the non-commutative geometer's
analogue of the total space $EG$ of the classifying principal $G$-bundle $EG\to
BG$. The pro-$C^*$-algebra $C(EG)$ of (possibly unbounded) continuous functions
on $EG$ is then recoverable as the abelianization of $C(E^+G)$. Along the way,
we develop various aspects of the theory of quasi-topological $G$-spaces and
$G$-pro-$C^*$-algebras."
math,The Spectrum of the Burnside Tambara Functor of a Cyclic Group,"We derive a family of prime ideals of the Burnside Tambara functor for a
finite group $G$. In the case of cyclic groups, this family comprises the
entire prime spectrum. We include some partial results towards the same result
for a larger class of groups."
math,On the structure of asymptotic expanders,"In this paper, we use geometric tools to study the structure of asymptotic
expanders and show that a sequence of asymptotic expanders always admits a
""uniform exhaustion by expanders"". It follows that asymptotic expanders cannot
be coarsely embedded into any $L^p$-space, and that asymptotic expanders can be
characterised in terms of their uniform Roe algebra. Moreover, we provide
uncountably many new counterexamples to the coarse Baum--Connes conjecture.
These appear to be the first counterexamples that are not directly constructed
by means of spectral gaps. Finally, we show that vertex-transitive asymptotic
expanders are actually expanders. In particular, this gives a $C^*$-algebraic
characterisation of expanders for vertex-transitive graphs."
math,Repetitive equivalences and good Wakamatsu-tilting modules,"Let $R$ be a ring and $T$ be a good Wakamatsu-tilting module with $S$ the
endomorphism ring. We prove that $T$ induces an equivalence between stable
categories of repetitive algebras of $R$ and $S$."
math,"Unbounded derived categories of small and big modules: Is the natural
  functor fully faithful?","Consider the obvious functor from the unbounded derived category of all
finitely generated modules over a left noetherian ring $R$ to the unbounded
derived category of all modules. We answer the natural question whether this
functor defines an equivalence onto the full subcategory of complexes with
finitely generated cohomology modules in two special cases. If $R$ is a
quasi-Frobenius ring of infinite global dimension, then this functor is not
full. If $R$ has finite left global dimension, this functor is an equivalence.
We also prove variants of the latter assertion for left coherent rings, for
noetherian schemes and for locally noetherian Grothendieck categories."
math,"Finite domination and Novikov homology over strongly
  $\mathbb{Z}^2$-graded rings","Let $R$ be a strongly $\mathbb{Z}^2$-graded ring, and let $C$ be a bounded
chain complex of finitely generated free $R$-modules. The complex $C$ is
$R_{(0,0)}$-finitely dominated, or of type FP over $R_{(0,0)}$, if it is chain
homotopy equivalent to a bounded complex of finitely generated projective
$R_{(0,0)}$-modules. We show that this happens if and only if $C$ becomes
acyclic after taking tensor product with a certain eight rings of formal power
series, the graded analogues of classical Novikov rings. This extends results
of Ranicki, Quinn and the first author on Laurent polynomial rings in one and
two indeterminates."
math,Rational homotopy theory of function spaces and Hochschild cohomology,"Given a map $f: X\rightarrow Y$ of simply connected spaces of finite type
such. The space of based loops at $f$ of the space of maps between $X$ and $Y$
is denoted by $\Omega_{f} Map(X,Y)$. For $n> 0$, we give a model categorical
interpretation of the existence (in functorial way) of an injective map of
$\mathbb{Q}$-vector spaces $\pi_{n} \Omega_{f}Map(X,Y_{\mathbb{Q}}) \rightarrow
HH^{-n}(C^{\ast}(Y),C^{\ast}(X)_{f})$, where $HH^{\ast}$ is the (negative)
Hochschild cohomology and $C^{\ast}(X)_{f}$ is the rational cochain complex
associated to $X$ equipped with a structure of $C^{\ast}(Y)$-differential
graded bimodule via the induced map of differential graded algebras $f^{\ast}:
C^{\ast}(Y)\rightarrow C^{\ast}(X)$. Moreover, we identifiy the image in
presice way by using the Hodge filtration on Hochschild cohomology. In
particular, when $X=Y$, we describe the fundamental group of the identity
component of the monoid of self equivalence of a (rationalization of) space $X$
i.e., $\pi_{1} Aut(X_{\mathbb{Q}})_{id}$."
math,Hochschild (Co)Homology of Exterior Algebras using AMT,"In 'Hochschild (co)homology of exterior algebras' (Han, Xu, 2007), the
authors computed the additive and multiplicative structure of
$H\!H^\ast\!(A;\!A)$, where $A$ is the $n$-th exterior algebra over a field. In
this paper, we derive all their results using a different method (AMT), as well
as calculate the additive structure of $H\!H_k\!(A;\!A)$ and $H\!H^k\!(A;\!A)$
over $\mathbb{Z}$. We provide concise presentations of algebras
$H\!H_\ast\!(A;\!A)$ and $H\!H^\ast\!(A;\!A)$, as well as determine their
generators in the Hochschild complex. Lastly, we compute an explicit free
resolution (spanned by multisets) of the $A^e$-module $A$ and describe the
homotopy equivalence to its bar resolution."
math,"Bott Integrability and Higher Integrability; Higher Cheeger-Simons and
  Godbillon-Vey Invariants","This paper studies the interaction of $\pi_1(M)$ for a $C^\infty$ manifold
$M$ with Bott's original obstruction to integrability, and with differential
geometric invariants such as Godbillon-Vey and Cheeger-Simons invariants of a
foliation. We prove that the ring of higher Pontrjagin and higher Chern classes
of an integrable subbundle $E$ of the tangent bundle of a manifold vanishes
above dimension $2k$ where $k=dim(TM/E)$, and where the higher Pontrjagin and
Chern rings are rings generated by $i^*y \cup p_j(TM/E)$ and by $i^*y \cup
c_j(TM/E)$ respectively, with $p_j$ the $j$-th Pontrjagin class, $c_j$ the
$j$-th Chern class, $i:M \to B\pi$ and $\pi=\pi_1(BG)$, where $BG$ is the
classifying space of the holonomy groupoid corresponding to $E$ and $y \in
H^*(B\pi)$, provided that the fundamental group of $BG$ satisfies the Novikov
conjecture. In addition, we show the vanishing of higher Pontrjagin and Chern
rings generated by $i^*x \cup p_j(TM/E)$, and by $i^*x \cup c_j(TM/E)$ as
before but with $i:M \to BG$, $BG$ as above and $x \in H^*(BG)$ provided
$(M,\mathcal{F})$ satisfied the foliated Novikov conjecture, where
$\mathcal{F}$ is the foliation whose tangent bundle is $E$. We give examples of
this obstruction and of higher Godbillon-Vey and Cheeger-Simons invariants."
math,"Structured matrices, continued fractions, and root localization of
  polynomials","We give a detailed account of various connections between several classes of
objects: Hankel, Hurwitz, Toeplitz, Vandermonde and other structured matrices,
Stietjes and Jacobi-type continued fractions, Cauchy indices, moment problems,
total positivity, and root localization of univariate polynomials. Along with a
survey of many classical facts, we provide a number of new results."
math,Bimodule complexes via strong homotopy actions,"We present a new and explicit method for lifting a tilting complex to a
bimodule complex. The key ingredient of our method is the notion of a strong
homotopy action in the sense of Stasheff."
math,"Rigid objects, triangulated subfactors and abelian localizations","We study abelian localizations of triangulated categories induced by rigid
contravariantly finite subcategories, and also triangulated structures on
subfactor categories of triangulated categories. In this context we generalize
recent results of Buan-Marsh and Iyama-Yoshino. We also extend basic results of
Keller-Reiten concerning the Gorenstein and the Calabi-Yau property for
categories arising from certain rigid, not necessarily cluster tilting,
subcategories, as well as several results of the literature concerning the
connections between 2-cluster tilting subcategories of triangulated categories
and tilting subcategories of the associated abelian category of coherent
functors. Finally we characterize 2-cluster tilting subcategories along these
lines."
math,Matrix factorizations for quantum complete intersections,"We introduce twisted matrix factorizations for quantum complete intersections
of codimension two. For such an algebra, we show that in a given dimension,
almost all the indecomposable modules with bounded minimal projective
resolutions correspond to such matrix factorizations."
math,"Symmetric approximation sequences, Beilinson-Green algebras and derived
  equivalences","In this paper, we will consider a class of locally $\Phi$-Beilinson-Green
algebras, where $\Phi$ is an infinite admissible set of the integers, and show
that symmetric approximation sequences in $n$-exangulated categories give rise
to derived equivalences between quotient algebras of locally
$\Phi$-Beilinson-Green algebras in the principal diagonals modulo some
factorizable ghost and coghost ideals by the locally finite tilting family.
Then we get a class of derived equivalent algebras that have not been obtained
by using previous techniques. From higher exact sequences, we obtain derived
equivalences between subalgebras of endomorphism algebras by constructing
tilting complexes, which generalizes Chen and Xi's result for exact sequences.
From a given derived equivalence, we get derived equivalences between locally
$\Phi$-Beilinson-Green algebras of semi-Gorenstein modules. Finally, from given
graded derived equivalences of group graded algebras, we get derived
equivalences between associated Beilinson-Green algebras of group graded
algebras."
math,"Leavitt path algebras, $B_\infty$-algebras and Keller's conjecture for
  singular Hochschild cohomology","For a finite quiver without sinks, we establish an isomorphism in the
homotopy category $\mathrm {Ho}(B_\infty)$ of $B_{\infty}$-algebras between the
Hochschild cochain complex of the Leavitt path algebra $L$ and the singular
Hochschild cochain complex of the corresponding radical square zero algebra
$\Lambda$. Combining this isomorphism with a description of the dg singularity
category of $\Lambda$ in terms of the dg perfect derived category of $L$, we
verify Keller's conjecture for the singular Hochschild cohomology of $\Lambda$.
More precisely, we prove that there is an isomorphism in
$\mathrm{Ho}(B_\infty)$ between the singular Hochschild cochain complex of
$\Lambda$ and the Hochschild cochain complex of the dg singularity category of
$\Lambda$. One ingredient of the proof is the following duality theorem on
$B_\infty$-algebras: for any $B_\infty$-algebra, there is a natural
$B_\infty$-isomorphism between its opposite $B_\infty$-algebra and its
transpose $B_\infty$-algebra.
  We prove that Keller's conjecture is invariant under one-point (co)extensions
and singular equivalences with levels. Consequently, Keller's conjecture holds
for those algebras obtained inductively from $\Lambda$ by one-point
(co)extensions and singular equivalences with levels. These algebras include
all finite dimensional gentle algebras."
math,Homology of complexes over finite tensor categories,"We generalize a recent result by J.F. Carlson to finite tensor categories
having finitely generated cohomology. Specifically, we show that if the Krull
dimension of the cohomology ring is sufficiently large, then there exist
infinitely many non-isomorphic and nontrivial bounded complexes of projective
objects, and with small homology. We also prove a version for finite
dimensional algebras with finitely generated cohomology."
math,The Intrinsic Fundamental Group of a Linear Category,"We provide an intrinsic definition of the fundamental group of a linear
category over a ring as the automorphism group of the fibre functor on Galois
coverings. If the universal covering exists, we prove that this group is
isomorphic to the Galois group of the universal covering. The grading deduced
from a Galois covering enables us to describe the canonical monomorphism from
its automorphism group to the first Hochschild-Mitchell cohomology vector
space."
math,On algebras of finite Cohen-Macaulay type,"We study Artin algebras $A$ and commutative Noetherian complete local rings
$R$ in connection with the following decomposition property of
Gorenstein-projective modules: $(*)$ any Gorenstein-projective module is a
direct sum of finitely generated modules. We show that this direct
decomposition property is related to the property of the algebra $A$, or the
ring $R$, being (virtually) Gorenstein of finite Cohen-Macaquly type. Along the
way we generalize classical results of Auslander and Ringel-Tachikawa from the
early seventies, and results of Chen and Yoshino on the structure of
Gorenstein-projective modules. Finally we study homological properties of
(stable) relative Auslander algebras of virtually Gorenstein algebras of finite
Cohen-Macaulay type and, under the presence of a cluster-tilting object, we
give descriptions of the stable category of Gorenstein-projective modules in
terms of suitable cluster categories."
math,"Monoidal categories and the Gerstenhaber bracket in Hochschild
  cohomology","In this monograph, we extend S. Schwede's exact sequence interpretation of
the Gerstenhaber bracket in Hochschild cohomology to certain exact and monoidal
categories. Therefore we establish an explicit description of an isomorphism by
A. Neeman and V. Retakh, which links $\mathrm{Ext}$-groups with fundamental
groups of categories of extensions and relies on expressing the fundamental
group of a (small) category by means of the associated Quillen groupoid.
  As a main result, we show that our construction behaves well with respect to
structure preserving functors between exact monoidal categories. We use our
main result to conclude, that both the Lie bracket and the squaring map in
Hochschild cohomology are invariants under Morita equivalence. For
quasi-triangular bialgebras, we further determine a significant part of the Lie
bracket's kernel, and thereby prove a conjecture by L. Menichi. Along the way,
we introduce $n$-extension closed and entirely extension closed subcategories
of abelian categories, and study some of their properties."
math,Singular Equivalence of Morita Type with Level,"We generalize the notion of stable equivalence of Morita type and define what
is called ""singular equivalence of Morita type with level"". Such an equivalence
of induces an equivalence between singular categories. We will also prove that
a derived equivalence of standard type induces a singular equivalence of Morita
type with level."
math,Singular Hochschild Cohomology and Gerstenhaber Algebra Structure,"In this paper, we define the singular Hochschild cohomology groups
$HH_{sg}^i(A, A)$ of an associative $k$-algebra $A$ as morphisms from $A$ to
$A[i]$ in the singular category $D_{sg}(A\otimes_k A^{op})$ for $i\in
\mathbb{Z}$. We prove that $HH_{sg}^*(A, A)$ has a Gerstenhaber algebra
structure and in the case of a symmetric algebra $A$, $HH_{sg}^*(A, A)$ is a
Batalin-Vilkovisky (BV) algebra."
math,"Hochschild cohomology of algebras arising from categories and from
  bounded quivers","The main objective of this paper is to provide a theory for computing the
Hochschild cohomology of algebras arising from a linear category with finitely
many objects and zero compositions. For this purpose, we consider such a
category using an ad hoc quiver $Q$, with an algebra associated to each vertex
and a bimodule to each arrow. The computation relies on cohomological functors
that we introduce, and on the combinatorics of the quiver. One point extensions
are occurrences of this situation, and Happel's long exact sequence is a
particular case of the long exact sequence of cohomology that we obtain via the
study of trajectories of the quiver. We introduce cohomology along paths, and
we compute it under suitable Tor vanishing hypotheses. The cup product on
Hochschild cohomology enables us to describe the connecting homomorphism of the
long exact sequence.
  Algebras arising from a linear category where the quiver is the round trip
one, provide square matrix algebras which have two algebras on the diagonal and
two bimodules on the corners. If the bimodules are projective, we show that
five-terms exact sequences arise. If the bimodules are free of rank one, we
provide a complete computation of the Hochschild cohomology. On the other hand,
if the corner bimodules are projective without producing new cycles, Hochschild
cohomology in large enough degrees is that of the product of the algebras on
the diagonal.
  As a by-product, we obtain some families of bound quiver algebras which are
of infinite global dimension, and have Hochschild cohomology zero in large
enough degrees."
math,"Hochschild-Mitchell (co)homology of skew categories and of Galois
  coverings","Let $\mathcal C$ be category over a commutative ring $k$, its
Hochschild-Mitchell homology and cohomology are denoted respectively
$HH_*(\mathcal C)$ and $HH^*(\mathcal C).$ Let $G$ be a group acting on
$\mathcal C$, and $\mathcal C[G]$ be the skew category. We provide
decompositions of the (co)homology of $\mathcal C[G]$ along the conjugacy
classes of $G$. For Hochschild homology of a $k$-algebra, this corresponds to
the decomposition obtained by M. Lorenz.
  If the coinvariants and invariants functors are exact, we obtain isomorphisms
$\left(HH_*(C)\right)_G\simeq HH^{\{1\}}_* (\mathcal C[G])$ and
$\left(HH^*(\mathcal C)\right)^G\simeq HH^*_{\{1\}} (\mathcal C[G]), $ where
$\{ {1}\}$ is the trivial conjugacy class of $G$.
  We first obtain these isomorphisms in case the action of $G$ is free on the
objects of $\mathcal C$. Then we introduce an auxiliary category $M_G(\mathcal
C)$ with an action of $G$ which is free on its objects, related to the infinite
matrix algebra considered by J. Cornick. This category enables us to show that
the isomorphisms hold in general, and in particular for the Hochschild
(co)homology of a $k$-algebra with an action of $G$ by automorphisms.
  We infer that $\left(HH^*(\mathcal C)\right)^G$ is a canonical direct summand
of $HH^*(\mathcal C[G])$. This provides a frame for monomorphisms obtained
previously, and which have been described in low degrees."
math,"Auslander-Reiten triangles and Grothendieck groups of triangulated
  categories","We prove that if the Auslander-Reiten triangles generate the relations for
the Grothendieck group of a Hom-finite Krull-Schmidt triangulated category with
a (co)generator, then the category has only finitely many isomorphism classes
of indecomposable objects up to translation. This gives a triangulated converse
to a theorem of Butler and Auslander-Reiten on the relations for Grothendieck
groups. Our approach has applications in the context of Frobenius categories."
math,"Green correspondence and relative projectivity for pairs of adjoint
  functors between triangulated categories","Auslander and Kleiner proved in 1994 an abstract version of Green
correspondence for pairs of adjoint functors between three categories. They
produce additive quotients of certain subcategories giving the classical Green
correspondence in the special setting of modular representation theory.
Carlson, Peng and Wheeler showed in 1998 that Green correspondence in the
classical setting of modular representation theory is actually an equivalence
between triangulated categories with respect to a non standard triangulated
structure. In the present note we first define and study a version of relative
projectivity, respectively relative injectivity with respect to pairs of
adjoint functors. We then modify Auslander Kleiner's construction such that the
correspondence holds in the setting of triangulated categories."
math,Locally finitely presented and coherent hearts,"Starting with a Grothendieck category $\mathcal{G}$ and a torsion pair
$\mathbf{t}=(\mathcal{T},\mathcal{F})$ in $\mathcal G$, we study the local
finite presentability and local coherence of the heart
$\mathcal{H}_{\mathbf{t}}$ of the associated Happel-Reiten-Smal{\o}
$t$-structure in the derived category $\mathrm{Der} (\mathcal{G})$. We start by
showing that, in this general setting, the torsion pair $\mathbf t$ is of
finite type, if and only if it is quasi-cotilting, if and only if it is
cosilting. We then proceed to study those $\mathbf t$ for which
$\mathcal{H}_{\mathbf{t}}$ is locally finitely presented, obtaining a complete
answer under some additional assumptions on the ground category $\mathcal{G}$,
which are general enough to include all locally coherent categories, all
categories of modules and several categories of quasi-coherent sheaves over
schemes. The third problem that we tackle is that of local coherence. In this
direction we characterize those torsion pairs $\mathbf t=(\mathcal T,\mathcal
F)$ in a locally finitely presented $\mathcal G$ for which
$\mathcal{H}_{\mathbf{t}}$ is locally coherent in two cases: when the tilted
t-structure in $\mathcal{H}_{\mathbf{t}}$ is assumed to restrict to finitely
presented objects, and when $\mathcal F$ is cogenerating. In the last part of
the paper we concentrate on the case when $\mathcal G$ is a category of modules
over a small preadditive category, giving several examples and obtaining very
neat (new) characterizations even in this more classical setting, also
underlying connections with the notion of an elementary cogenerator."
math,"The dg Leavitt algebra, singular Yoneda category and singularity
  category","For any finite dimensional algebra $\Lambda$ given by a quiver with
relations, we prove that its dg singularity category is quasi-equivalent to the
perfect dg derived category of a dg Leavitt path algebra. The result might be
viewed as a deformed version of the known description of the dg singularity
category of a radical-square-zero algebra in terms of a Leavitt path algebra
with trivial differential.
  The above result is achieved in two steps. We first introduce the singular
Yoneda dg category of $\Lambda$, which is quasi-equivalent to the dg
singularity category of $\Lambda$. The construction of this new dg category
follows from a general operation for dg categories, namely an explicit dg
localization inverting a natural transformation from the identity functor to a
dg endofunctor. This localization turns out to be quasi-equivalent to a dg
quotient category. Secondly, we prove that the endomorphism algebra of the
quotient of $\Lambda$ modulo its Jacobson radical in the singular Yoneda dg
category is isomorphic to the dg Leavitt path algebra. The appendix is devoted
to an alternative proof of the result using Koszul-Moore duality and derived
localizations."
math,A Survey on Han's Conjecture,"In 1989, D. Happel pointed out for a possible connection between the global
dimension of a finite-dimensional algebra and its Hochschild cohomology: is it
true that the vanishing of Hochschild cohomology higher groups is sufficient to
deduce that the global dimension is finite? After the discovery of a
counterexample, Y. Han proposed, in 2006, to reformulate this question to
homology. In this survey, after introducing the concepts and results involved,
I present the efforts made until now towards the comprehension of Han's
conjecture; which includes: examples of algebras that have been proven to
satisfy it and extensions that preserve it."
math,Differential graded enhancements of singularity categories,"The singularity category of a ring detects the homological singularity of the
given ring, and appears in many different contexts. We describe two different
dg enhancements of the singularity category, that is, the Vogel dg category and
the singular Yoneda dg category. These two dg enhancements turn out to be
quasi-equivalent. We report some progress on the Singular Presilting
Conjecture."
math,"Simplicity, primitivity and semiprimitivity of etale groupoid algebras
  with applications to inverse semigroup algebras","This paper studies simplicity, primitivity and semiprimitivity of algebras
associated to \'etale groupoids. Applications to inverse semigroup algebras are
presented. The results also recover the semiprimitivity of Leavitt path
algebras and can be used to recover the known primitivity criterion for Leavitt
path algebras."
math,Relative Calabi-Yau structures and ice quivers with potential,"In 2015, Van den Bergh showed that complete 3-Calabi-Yau algebras over an
algebraically closed field of characteristic 0 are equivalent to Ginzburg dg
algebras associated with quivers with potential. He also proved the natural
generalisation to higher dimensions and non-algebraically closed ground fields.
The relative version of the notion of Ginzburg dg algebra is that of Ginzburg
morphism. For example, every ice quiver with potential gives rise to a Ginzburg
morphism. We generalise Van den Bergh's theorem by showing that, under suitable
assumptions, any morphism with a relative Calabi-Yau structure is equivalent to
a Ginzburg(-Lazaroiu) morphism. In particular, in dimension 3 and over an
algebraically closed ground field of characteristic 0, it is given by an ice
quiver with potential. Thanks to the work of Bozec-Calaque-Scherotzke, this
result can also be viewed as a non-commutative analogue of Joyce-Safronov's
Lagrangian neighbourhood theorem in derived symplectic geometry."
math,"The AKSZ Construction in Derived Algebraic Geometry as an Extended
  Topological Field Theory","We construct a family of oriented extended topological field theories using
the AKSZ construction in derived algebraic geometry, which can be viewed as an
algebraic and topological version of the classical AKSZ field theories that
occur in physics. These have as their targets higher categories of symplectic
derived stacks, with higher morphisms given by iterated Lagrangian
correspondences. We define these, as well as analogous higher categories of
oriented derived stacks and iterated oriented cospans, and prove that all
objects are fully dualizable. Then we set up a functorial version of the AKSZ
construction, first implemented in this context by
Pantev-To\""en-Vaqui\'e-Vezzosi, and show that it induces a family of symmetric
monoidal functors from oriented stacks to symplectic stacks. Finally, we
construct forgetful functors from the unoriented bordism $(\infty,n)$-category
to cospans of spaces, and from the oriented bordism $(\infty,n)$-category to
cospans of spaces equipped with an orientation; the latter combines with the
AKSZ functors by viewing spaces as constant stacks, giving the desired field
theories."
math,Fusion Bialgebras and Fourier Analysis,"We introduce fusion bialgebras and their duals and systematically study their
Fourier analysis. As an application, we discover new efficient analytic
obstructions on the unitary categorification of fusion rings. We prove the
Hausdorff-Young inequality, uncertainty principles for fusion bialgebras and
their duals. We show that the Schur product property, Young's inequality and
the sum-set estimate hold for fusion bialgebras, but not always on their duals.
If the fusion ring is the Grothendieck ring of a unitary fusion category, then
these inequalities hold on the duals. Therefore, these inequalities are
analytic obstructions of categorification. We classify simple integral fusion
rings of Frobenius type up to rank 8 and of Frobenius-Perron dimension less
than 4080. We find 34 ones, 4 of which are group-like and 28 of which can be
eliminated by applying the Schur product property on the dual. In general,
these inequalities are obstructions to subfactorize fusion bialgebras."
math,"The Novikov conjecture for algebraic K-theory of the group algebra over
  the ring of Schatten class operators","In this paper, we prove the algebraic K-theory Novikov conjecture for group
algebras over the ring of Schatten class operators. The main technical tool in
the proof is an explicit construction of the Connes-Chern character."
math,"On the group of spheromorphisms of the homogeneous non-locally finite
  tree","Consider a tree $\mathbb T$, all whose vertices have countable valence; its
boundary is the Baire space $\mathbb{B} \simeq\mathbb{N}^{\mathbb N}$;
continued fractions expansions identify the set of irrational numbers
$\mathbb{R}\setminus \mathbb{Q}$ with $\mathbb B$. Removing $k$ edges from
$\mathbb T$ we get a forest consisting of copies of $\mathbb T$. A
spheromorphism (or hierarchomorphism) of $\mathbb T$ is an isomorphisms of two
such subforests considered as a transformation of $\mathbb T$ or of $\mathbb
B$. Denote the group of all spheromorphisms by $\mathrm{Hier}({\mathbb T})$. We
a show that the correspondence ${\mathbb R}\setminus{\mathbb Q}\simeq{\mathbb
B}$ sends the Thompson group realized by piecewise $\mathrm{PSL}_2({\mathbb
Z})$-transformations to a subgroup of $\mathrm{Hier}({\mathbb T})$. We
construct some unitary representations of the group $\mathrm{Hier}({\mathbb
T})$, show that the group of automorphisms $\mathrm{Aut}({\mathbb T})$ is
spherical in $\mathrm{Hier}({\mathbb T})$, and describe the train (enveloping
category) of $\mathrm{Hier}({\mathbb T})$."
math,"Groups of isometries of ultrametric Urysohn spaces and their unitary
  representations","We consider groups $\mathbb{I}$ of isometries of ultrametric Urysohn spaces
$\mathbb{U}$. Such spaces $\mathbb{U}$ admit transparent realizations as
boundaries of certain $R$-trees and the groups $\mathbb{I}$ are groups of
automorphisms of these $R$-trees. Denote by $\mathbb{I}[X]\subset \mathbb{I}$
stabilizers of finite subspaces $X\subset \mathbb{U}$. Double cosets
$\mathbb{I}[X]\cdot g\cdot \mathbb{I}[Y]$, where $g\in \mathbb{I}$, are
enumerated by ultrametrics on union of spaces $X\cup Y$. We construct natural
associative multiplications on double coset spaces $\mathbb{I}[X]\backslash
\mathbb{I}/\mathbb{I}[X]$ and, more generally, multiplications
$\mathbb{I}[X]\backslash \mathbb{I}/\mathbb{I}[Y]\,\times\,
\mathbb{I}[Y]\backslash \mathbb{I}/\mathbb{I}[Z]\to \mathbb{I}[X]\backslash
\mathbb{I}/\mathbb{I}[Z]$. These operations are a kind of canonical
amalgamations of ultrametric spaces. On the other hand, this product can be
interpreted in terms of partial isomorphisms of certain $R$-trees (in
particular, we come to an inverse category). This allows us to classify all
unitary representations of the groups $\mathbb{I}$ and to prove that groups
$\mathbb{I}$ have type $I$. We also describe a universal semigroup
compactification of $\mathbb{I}$ whose image in any unitary representation of
$\mathbb{I}$ is compact."
math,Non-degeneracy results for (multi-)pushouts of compact groups,"We prove that embeddings of compact groups are equalizers, and a number of
results on pushouts (and more generally, amalgamated free products) in the
category of compact groups. Call a family of compact-group embeddings $H\le
G_i$ algebraically sound if the corresponding group-theoretic pushout embeds in
its Bohr compactification. We (a) show that a family of normal embeddings is
algebraically sound in the sense that $G_i$ admit embeddings $G_i\le G$ into a
compact group which agree on $H$; (b) give equivalent characterizations of
coherently embeddable families of normal embeddings in representation-theoretic
terms, via Clifford theory; (c) characterize those compact connected Lie groups
$H$ for which all finite families of normal embeddings $H\trianglelefteq G_i$
are coherently embeddable (not having central 2-tori is a sufficient, but not
necessary condition), and (d) show that families of split embeddings of compact
groups are always algebraically sound."
math,Regular Finite Decomposition Complexity,"We introduce the notion of regular finite decomposition complexity of a
metric family. This generalizes Gromov's finite asymptotic dimension and is
motivated by the concept of finite decomposition complexity (FDC) due to
Guentner, Tessera and Yu. Regular finite decomposition complexity implies FDC
and has all the permanence properties that are known for FDC, as well as a new
one called Finite Quotient Permanence. We show that for a collection containing
all metric families with finite asymptotic dimension all other permanence
properties follow from Fibering Permanence."
math,Coronas for properly combable spaces,"This paper is a systematic approach to the construction of coronas (i.e.
Higson dominated boundaries at infinity) of combable spaces. We introduce three
additional properties for combings: properness, coherence and expandingness.
Properness is the condition under which our construction of the corona works.
Under the assumption of coherence and expandingness, attaching our corona to a
Rips complex construction yields a contractible $\sigma$-compact space in which
the corona sits as a $Z$-set. This results in bijectivity of transgression
maps, injectivity of the coarse assembly map and surjectivity of the coarse
co-assembly map. For groups we get an estimate on the cohomological dimension
of the corona in terms of the asymptotic dimension. Furthermore, if the group
admits a finite model for its classifying space $BG$, then our constructions
yield a $Z$-structure for the group."
math,The Weil Representation in Characteristic Two,"In this paper we construct a new variant of the Weil representation,
associated with a symplectic vector space V defined over a finite field of
characteristic two. Our variant is a representation of a bigger group than that
of Weil. In the course, we develop the formalism of canonical vector spaces,
which enables us to realize the bigger symmetry group and the representation in
a transparent manner."
math,On the classification of symplectic DQ-algebroids,"DQ-algebroids locally defined on a symplectic manifold form a 2-gerbe. By
adapting the method of P. Deligne to the setting of DQ-algebroids we show that
this 2-gerbe admits a canonical global section, namely that every symplectic
manifold admits a canonical DQ-algebroid quantizing the structure sheaf. The
construction relies on methods of non-abelian cohomology and local computations
in the Weyl algebra. As a corollary we obtain a classification of symplectic
DQ-algebroids."
math,Representation stability for filtrations of Torelli groups,"We show, finitely generated rational $\mathsf{VIC}_{\mathbb Q}$-modules and
$\mathsf{SI}_{\mathbb Q}$-modules are uniformly representation stable and all
their submodules are finitely generated. We use this to prove two conjectures
of Church and Farb, which state that the quotients of the lower central series
of the Torelli subgroups of $\mathrm{Aut}(F_n)$ and
$\mathrm{Mod}(\Sigma_{g,1})$ are uniformly representation stable as sequences
of representations of the general linear groups and the symplectic groups,
respectively. Furthermore we prove an analogous statement for their Johnson
filtrations."
math,"Groups, conjugation and powers","We introduce the notion of the power quandle of a group, an algebraic
structure that forgets the multiplication but keeps the conjugation and the
power maps. Compared with plain quandles, power quandles are much better
invariants of groups. We show that they determine the central quotient of any
group and the center of any finite group. Any group can be canonically
approximated by the associated group of its power quandle, which we show to be
a central extension, with a universal property, and a computable kernel. This
allows us to present any group as a quotient of a group with a
power-conjugation presentation by an abelian subgroup that is determined by the
power quandle and low-dimensional homological invariants."
math,"Decomposition of the Hochschild Complex of a Scheme in Arbitrary
  Characteristic","The paper has been withdrawn by the author, due a gap in the proof of Theorem
6.1. The gap was discovered by M. Van den Bergh.
  Theorem 6.1 is used to prove the main result of the paper, namely Theorem 0.7
(decomposition in arbitrary characteristic). At this time we do not have an
alternate proof.
  Other results of the paper (Theorems 0.2, 0.3, 0.6 and 3.1) are not effected
by this problem, and they remain valid."
math,On Weighted Simplicial Homology,"We develop a framework for computing the homology of weighted simplicial
complexes with coefficients in a discrete valuation ring. A weighted simplicial
complex, $(X,v)$, introduced by Dawson [Cah. Topol. G\'{e}om. Diff\'{e}r.
Cat\'{e}g. 31 (1990), pp. 229--243], is a simplicial complex, $X$, together
with an integer-valued function, $v$, assigning weights to simplices, such that
the weight of any of faces are monotonously increasing. In addition, weighted
homology, $H_n^v(X)$, features a new boundary operator, $\partial_n^v$. In
difference to Dawson, our approach is centered at a natural homomorphism
$\theta$ of weighted chain complexes. The key object is $H^v_{n}(X/\theta)$,
the weighted homology of a quotient of chain complexes induced by $\theta$,
appearing in a long exact sequence linking weighted homologies with different
weights. We shall construct bases for the kernel and image of the weighted
boundary map, identifying $n$-simplices as either $\kappa_n$- or
$\mu_n$-vertices. Long exact sequences of weighted homology groups and the
bases, allow us to prove a structure theorem for the weighted simplicial
homology with coefficients in a ring of formal power series
$R=\mathbb{F}[[\pi]]$, where $\mathbb{F}$ is a field. Relative to simplicial
homology new torsion arises and we shall show that the torsion modules are
connected to a pairing between distinguished $\kappa_n$ and $\mu_{n+1}$
simplices."
math,"(Quantum) discreteness, spectrum compactness and uniform continuity","We prove a number of results linking properties of actions by compact groups
(both quantum and classical) on Banach spaces, such as uniform continuity,
spectrum finiteness and extensibility of the actions across several
constructions. Examples include: (a) a unitary representation of a compact
quantum group induces a continuous action on the $C^*$-algebra of bounded
operators if and only if it has finitely many isotypic components, and hence is
uniformly continuous; (b) a compact quantum group is finite if and only if its
continuous actions on $C^*$-algebras lift to continuous actions on either the
multiplier algebras or von Neumann envelopes thereof; (c) a (classical) locally
compact group $\mathbb{G}$ is discrete if and only if the forgetful functor
from $\mathbb{G}$-acted-upon compact $T_2$ spaces back to compact $T_2$ spaces
creates coproducts; (d) a representation of a linearly reductive quantum group
has finitely many isotypic components if and only if its restrictions to two
topologically-generating quantum subgroups, one of which is normal, do; (e)
equivalent characterizations of uniform continuity for actions of compact
groups on Banach spaces, e.g. that such an action is uniformly continuous if
and only if its restrictions to a pro-torus and to pro-$p$ subgroups are."
math,The eventual image,"In a category with enough limits and colimits, one can form the universal
automorphism on an endomorphism in two dual senses. Sometimes these dual
constructions coincide, as in the categories of finite sets, finite-dimensional
vector spaces, and compact metric spaces. There, beginning with an endomorphism
$f$, there is a doubly-universal automorphism on $f$ whose underlying object is
the eventual image $\bigcap_n \mathrm{im}(f^n)$. Our main theorem unifies these
examples, stating that in any category with a factorization system satisfying
certain axioms, the eventual image has two dual universal properties. A further
theorem characterizes the eventual image as a terminal coalgebra. In all, nine
characterizations of the eventual image are given, valid at different levels of
generality."
math,Constructing KMS states from infinite-dimensional spectral triples,"We construct KMS-states from $\mathrm{Li}_1$-summable semifinite spectral
triples and show that in several important examples the construction coincides
with well-known direct constructions of KMS-states for naturally defined flows.
Under further summability assumptions the constructed KMS-state can be computed
in terms of Dixmier traces. For closed manifolds, we recover the ordinary
Lebesgue integral. For Cuntz-Pimsner algebras with their gauge flow, the
construction produces KMS-states from traces on the coefficient algebra and
recovers the Laca-Neshveyev correspondence. For a discrete group acting on its
Stone-\v{C}ech boundary, we recover the Patterson-Sullivan measures on the
Stone-\v{C}ech boundary for a flow defined from the Radon-Nikodym cocycle."
math,On Kuiper type theorems for uniform Roe algebras,"Generalizing the case of an infinite discrete metric space of finite
diameter, we say that a discrete metric space $(X,d)$ is a Kuiper space, if the
group of invertible elements of its uniform Roe algebra is norm-contractible.
Various sufficient conditions on $(X,d)$ to be or not to be a Kuiper space are
obtained."
math,Noncommutative Cantor-Bendixson derivatives and scattered $C^*$-algebras,"We analyze the sequence obtained by consecutive applications of the
Cantor-Bendixson derivative for a noncommutative scattered $C^*$-algebra
$\mathcal A$, using the ideal $\mathcal I^{At}(\mathcal A)$ generated by the
minimal projections of $\mathcal A$. With its help, we present some fundamental
results concerning scattered $C^*$-algebras, in a manner parallel to the
commutative case of scattered compact or locally compact Hausdorff spaces and
superatomic Boolean algebras. It also allows us to formulate problems which
have motivated the ""cardinal sequences"" programme in the classical topology, in
the noncommutative context.
  This leads to some new constructions of noncommutative scattered
$C^*$-algebras and new open problems. In particular, we construct a type $I$
$C^*$-algebra which is the inductive limit of stable ideals $\mathcal
A_\alpha$, along an uncountable limit ordinal $\lambda$, such that $\mathcal
A_{\alpha+1}/\mathcal A_\alpha$ is $*$-isomorphic to the algebra of all compact
operators on a separable Hilbert space and $\mathcal A_{\alpha+1}$ is
$\sigma$-unital and stable for each $\alpha<\lambda$, but $\mathcal A$ is not
stable and where all ideals of $\mathcal A$ are of the form $\mathcal
A_\alpha$. In particular, $\mathcal A$ is a nonseparable $C^*$-algebra with no
ideal which is maximal among the stable ideals.
  This answers a question of M. R\ordam in the nonseparable case. All the above
$C^*$-algebras $A_\alpha$s and $A$ satisfy the following version of the
definition of an AF algebra: any finite subset can be approximated from a
finite-dimensional subalgebra. Two more complex constructions based on the
language developed in this paper are presented in separate papers."
math,On large indecomposable Banach spaces,"Hereditarily indecomposable Banach spaces may have density at most continuum
(Plichko-Yost, Argyros-Tolias). In this paper we show that this cannot be
proved for indecomposable Banach spaces. We provide the first example of an
indecomposable Banach space of density two to continuum. The space exists
consistently, is of the form C(K) and it has few operators in the sense that
any bounded linear operator T on C(K) satisfies T(f)=gf+S(f) for every f in
C(K), where g is in C(K) and S is weakly compact (strictly singular)."
math,On automorphisms of the Banach space $\ell_\infty/c_0$,"We investigate Banach space automorphisms
$T:\ell_\infty/c_0\rightarrow\ell_\infty/c_0 $ focusing on the possibility of
representing their fragments of the form
$$T_{B,A}:\ell_\infty(A)/c_0(A)\rightarrow \ell_\infty(B)/c_0(B)$$ for $A,
B\subseteq N$ infinite by means of linear operators from $\ell_\infty(A)$ into
$\ell_\infty(B)$, infinite $A\times B$-matrices, continuous maps from
$B^*=\beta B\setminus B$ into $A^*$, or bijections from $B$ to $A$. This leads
to the analysis of general linear operators on $\ell_\infty/c_0$. We present
many examples, introduce and investigate several classes of operators, for some
of them we obtain satisfactory representations and for other give examples
showing that it is impossible. In particular, we show that there are
automorphisms of $\ell_\infty/c_0$ which cannot be lifted to operators on
$\ell_\infty$ and assuming OCA+MA we show that every automorphism of
$\ell_\infty/c_0$ with no fountains or with no funnels is locally, i.e., for
some infinite $A, B\subseteq N$ as above, induced by a bijection from $B$ to
$A$. This additional set-theoretic assumption is necessary as we show that the
continuum hypothesis implies the existence of counterexamples of diverse
flavours. However, many basic problems, some of which are listed in the last
section, remain open."
math,There is no bound on sizes of indecomposable Banach spaces,"Assuming the generalized continuum hypothesis we construct arbitrarily big
indecomposable Banach spaces. i.e., such that whenever they are decomposed as
$X\oplus Y$, then one of the closed subspaces $X$ or $Y$ must be finite
dimensional. It requires alternative techniques compared to those which were
initiated by Gowers and Maurey or Argyros with the coauthors. This is because
hereditarily indecomposable Banach spaces always embed into $\ell_\infty$ and
so their density and cardinality is bounded by the continuum and because dual
Banach spaces of densities bigger than continuum are decomposable by a result
due to Heinrich and Mankiewicz.
  The obtained Banach spaces are of the form $C(K)$ for some compact connected
Hausdorff space and have few operators in the sense that every linear bounded
operator $T$ on $C(K)$ for every $f\in C(K)$ satisfies $T(f)=gf+S(f)$ where
$g\in C(K)$ and $S$ is weakly compact or equivalently strictly singular. In
particular, the spaces carry the structure of a Banach algebra and in the
complex case even the structure of a $C^*$-algebra."
math,"An extension of compact operators by compact operators with no
  nontrivial multipliers","We construct an essential extension of $\mathcal K(\ell_2({\mathfrak{c}}))$
by $\mathcal K(\ell_2)$, where ${\mathfrak{c}}$ denotes the cardinality of
continuum, i.e., a $C^*$-algebra $\mathcal A\subseteq \mathcal B(\ell_2)$
satisfying the short exact sequence $$0\rightarrow \mathcal
K(\ell_2)\xrightarrow{\iota} \mathcal A \rightarrow\mathcal
K(\ell_2({\mathfrak{c}}))\rightarrow 0,$$ where $\iota[\mathcal K(\ell_2)]$ is
an essential ideal of $\mathcal A$ such that the algebra of multipliers
$\mathcal M(\mathcal A)$ of $\mathcal A$ is equal to the unitization of
$\mathcal A$. In particular $\mathcal A$ is not stable which sheds light on
permanence properties of the stability in the nonseparable setting. Namely, an
extension of a nonseparable algebra of compact operators, even by $\mathcal
K(\ell_2)$, does not have to be stable.
  This construction can be considered as a noncommutative version of Mr\'owka's
$\Psi$-space; a space whose one point compactification equals to its Cech-Stone
compactification and is induced by a special uncountable family of almost
disjoint subsets of ${\mathbb{N}}$. The role of the almost disjoint family is
played by an almost orthogonal family of projections in $\mathcal B(\ell_2)$,
but the almost matrix units corresponding to the matrix units in $\mathcal
K(\ell_2({\mathfrak{c}}))$ must be constructed with extra care.
  This example may also contribute in the future to our understanding of the
semigroups $Ext(\mathcal K(\ell_2({\kappa})))$ for $\omega_1\leq
\kappa\leq\mathfrak{c}$ which are unexplored at the moment."
math,A non-stable C*-algebra with an elementary essential composition series,"A C*-algebra $A$ is said to be stable if it is isomorphic to $A \otimes
K(\ell_2)$. Hjelmborg and R\o rdam have shown that countable inductive limits
of separable stable C*-algebras are stable. We show that this is no longer true
in the nonseparable context even for the most natural case of an uncountable
inductive limit of an increasing chain of separable stable and AF ideals: we
construct a GCR, AF (in fact, scattered) subalgebra $A$ of $B(\ell_2)$, which
is the inductive limit of length $\omega_1$ of its separable stable ideals
$I_\alpha$ ($\alpha<\omega_1$) satisfying $I_{\alpha+1}/I_\alpha\cong
K(\ell_2)$ for each $\alpha<\omega_1$, while $A$ is not stable.
  The sequence $(I_\alpha)_{\alpha\leq\omega_1}$ is the GCR composition series
of $A$ which in this case coincides with the Cantor-Bendixson composition
series as a scattered C*-algebra. $A$ has the property that all of its proper
two-sided ideals are listed as $I_\alpha$s for some $\alpha<\omega_1$ and
therefore the family of stable ideals of $A$ has no maximal element.
  By taking $A'=A\otimes K(\ell_2)$ we obtain a stable C*-algebra with
analogous composition series $(J_\alpha)_{\alpha<\omega_1}$ whose ideals
$J_\alpha$s are isomorphic to $I_\alpha$s for each $\alpha<\omega_1$. In
particular, there are nonisomorphic scattered C*-algebras whose GCR composition
series $(I_\alpha)_{\alpha\leq\omega_1}$ satisfy $I_{\alpha+1}/I_\alpha\cong
K(\ell_2)$ for all $\alpha<\omega_1$, for which the composition series differ
first at $\alpha=\omega_1$."
math,"A conjecture concerning *-algebras that unifies some matrix
  decompositions","In this note, we propose a simple-looking but broad conjecture about
star-algebras over the field of real numbers. The conjecture enables many
matrix decompositions to be represented by star-algebras and star-ideals. This
paper is written for people with a background in representation theory and
module theory. The motivation for investigating this is the possibility of
expressing polymorphic algorithms in numerical and theoretical linear algebra.
This is similar to but different from algebraic (semiring based) approaches to
dynamic programming. We prove certain cases of the conjecture."
math,On what I do not understand (and have something to say): Part I,"This is a non-standard paper, containing some problems in set theory I have
in various degrees been interested in. Sometimes with a discussion on what I
have to say; sometimes, of what makes them interesting to me, sometimes the
problems are presented with a discussion of how I have tried to solve them, and
sometimes with failed tries, anecdote and opinion. So the discussion is quite
personal, in other words, egocentric and somewhat accidental. As we discuss
many problems, history and side references are erratic, usually kept at a
minimum (``see ... '' means: see the references there and possibly the paper
itself).
  The base were lectures in Rutgers Fall'97 and reflect my knowledge then. The
other half, concentrating on model theory, will subsequently appear."
math,"Sheaf representations of MV-algebras and lattice-ordered abelian groups
  via duality","We study representations of MV-algebras -- equivalently, unital
lattice-ordered abelian groups -- through the lens of Stone-Priestley duality,
using canonical extensions as an essential tool. Specifically, the theory of
canonical extensions implies that the (Stone-Priestley) dual spaces of
MV-algebras carry the structure of topological partial commutative ordered
semigroups. We use this structure to obtain two different decompositions of
such spaces, one indexed over the prime MV-spectrum, the other over the maximal
MV-spectrum. These decompositions yield sheaf representations of MV-algebras,
using a new and purely duality-theoretic result that relates certain sheaf
representations of distributive lattices to decompositions of their dual
spaces. Importantly, the proofs of the MV-algebraic representation theorems
that we obtain in this way are distinguished from the existing work on this
topic by the following features: (1) we use only basic algebraic facts about
MV-algebras; (2) we show that the two aforementioned sheaf representations are
special cases of a common result, with potential for generalizations; and (3)
we show that these results are strongly related to the structure of the
Stone-Priestley duals of MV-algebras. In addition, using our analysis of these
decompositions, we prove that MV-algebras with isomorphic underlying lattices
have homeomorphic maximal MV-spectra. This result is an MV-algebraic
generalization of a classical theorem by Kaplansky stating that two compact
Hausdorff spaces are homeomorphic if, and only if, the lattices of continuous
[0, 1]-valued functions on the spaces are isomorphic."
math,Grothendieck topologies on posets,"Lindenhovius has studied Grothendieck topologies on posets and has given a
complete classification in the case that the poset is Artinian. We extend his
approach to more general posets, by translating known results in locale and
domain theory to the study of Grothendieck topologies. In particular, explicit
descriptions are given for the family of Grothendieck topologies with enough
points and the family of Grothendieck topologies of finite type. As an
application, we compute the cardinalities of these families in various
examples."
math,Batalin-Vilkovisky algebras and the J-homomorphism,"Let X be a topological space. The homology of the iterated loop space
$H_*\Omega^n X$ is an algebra over the homology of the framed n-disks operad
$H_*f\mathcal{D}_n$ \cite{Getzler:BVAlg,Salvatore-Wahl:FrameddoBVa}. We
determine completely this $H_*f\mathcal{D}_n$-algebra structure on
  $H_*(\Omega^n X;\mathbb{Q})$. We show that the action of $H_*(SO(n))$ on the
iterated loop space $H_*\Omega^n X$ is related to the J-homomorphism and that
the BV-operator vanishes on spherical classes only in characteristic other than
2."
math,K-homology and K-theory for the lamplighter groups of finite groups,"Let $F$ be a finite group. We consider the lamplighter group
$L=F\wr\mathbb{Z}$ over $F$. We prove that $L$ has a classifying space for
proper actions $\underline{E} L$ which is a complex of dimension two. We use
this to give an explicit proof of the Baum-Connes conjecture (without
coefficients), that states that the assembly map $\mu_i^L:K_i^L(\underline{E}
L)\rightarrow K_i(C^*L)\;(i=0,1)$ is an isomorphism. Actually, $K_0(C^*L)$ is
free abelian of countable rank, with an explicit basis consisting of
projections in $C^*L$, while $K_1(C^*L)$ is infinite cyclic, generated by the
unitary of $C^*L$ implementing the shift. Finally we show that, for $F$
abelian, the $C^*$-algebra $C^*L$ is completely characterized by $|F|$ up to
isomorphism."
math,"Equivariant K-homology and K-theory for some discrete planar affine
  groups","We consider the semi-direct products $G=\mathbb Z^2\rtimes GL_2(\mathbb Z),
\mathbb Z^2\rtimes SL_2(\mathbb Z)$ and $\mathbb Z^2\rtimes\Gamma(2)$ (where
$\Gamma(2)$ is the congruence subgroup of level 2). For each of them, we
compute both sides of the Baum-Connes conjecture, namely the equivariant
$K$-homology of the classifying space $\underline{E}G$ for proper actions on
the left-hand side, and the analytical K-theory of the reduced group
$C^*$-algebra on the right-hand side. The computation of the LHS is made
possible by the existence of a 3-dimensional model for $\underline{E}G$, which
allows to replace equivariant K-homology by Bredon homology. We pay due
attention to the presence of torsion in $G$, leading to an extensive study of
the wallpaper groups associated with finite subgroups. For the second and third
groups, the computations in $K_0$ provide explicit generators that are matched
by the Baum-Connes assembly map."
math,A finite dimensional approach to the strong Novikov conjecture,"The aim of this paper is to introduce an approach to the (strong) Novikov
conjecture based on continuous families of finite dimensional representations:
this is partly inspired by ideas of Lusztig using the Atiyah-Singer families
index theorem, and partly by Carlsson's deformation $K$--theory. Using this
approach, we give new proofs of the strong Novikov conjecture in several
interesting cases, including crystallographic groups and surface groups. The
method presented here is relatively accessible compared with other proofs of
the Novikov conjecture, and also yields some information about the $K$--theory
and cohomology of representation spaces."
math,"Compact operators and algebraic $K$-theory for groups which act properly
  and isometrically on Hilbert space","We prove the $K$-theoretic Farrell-Jones conjecture for groups as in the
title with coefficient rings and $C^*$-algebras which are stable with respect
to compact operators. We use this and Higson-Kasparov's result that the
Baum-Connes conjecture with coefficients holds for such groups, to show that if
$G$ is as in the title then the algebraic and the $C^*$-crossed products of $G$
with a stable $C^*$-algebra have the same $K$-theory."
math,"K-theory and K-homology of the wreath products of finite with free
  groups","Consider the wreath product $\Gamma = F\wr \mathrm{F_n} =
\bigoplus_{\mathrm{F_n}}F\rtimes\mathrm{F_n}$, with $F$ a finite group and
$\mathrm{F_n}$ the free group on $n$ generators. We study the Baum-Connes
conjecture for this group. Our aim is to explicitly describe the Baum-Connes
assembly map for $F\wr \mathrm{F_n}$. To this end, we compute the topological
and the analytical K-groups and exhibit their generators. Moreover, we present
a concrete 2-dimensional model for $\underline{E} \Gamma$. As a result of our
K-theoretic computations, we obtain that $\mathrm K_0(\mathrm C^*_{\mathrm
r}(\Gamma))$ is the free abelian group of countable rank with a basis
consisting of projections in $\mathrm C^*_{\mathrm
r}(\bigoplus_{\mathrm{F_n}}F)$ and $\mathrm K_1(\mathrm C^*_{\mathrm
r}(\Gamma))$ is the free abelian group of rank $n$ with a basis consisting of
the unitaries coming from the free group."
math,"A$_\infty$ deformations of extended Khovanov arc algebras and Stroppel's
  Conjecture","Extended Khovanov arc algebras $\mathrm{K}_m^n$ are graded associative
algebras which naturally appear in a variety of contexts, from knot and link
homology, low-dimensional topology and topological quantum field theory to
representation theory and symplectic geometry. C. Stroppel conjectured in her
ICM 2010 address that the bigraded Hochschild cohomology groups of
$\mathrm{K}_m^n$ vanish in a certain range, implying that the algebras $\mathrm
K_m^n$ admit no nontrivial A$_\infty$ deformations, in particular that the
algebras are intrinsically formal.
  Whereas Stroppel's Conjecture is known to hold for the algebras $\mathrm
K_m^1$ and $\mathrm K_1^n$ by work of Seidel and Thomas, we show that $\mathrm
K_m^n$ does in fact admit nontrivial A$_\infty$ deformations with nonvanishing
higher products for all $m, n \geq 2$.
  We describe both $\mathrm K_m^n$ and its Koszul dual concretely as path
algebras of quivers with relations and give an explicit algebraic construction
of A$_\infty$ deformations of $\mathrm K_m^n$ by using the correspondence
between A$_\infty$ deformations of a Koszul algebra and filtered associative
deformations of its Koszul dual. These deformations can also be viewed as
A$_\infty$ deformations of Fukaya--Seidel categories associated to Hilbert
schemes of surfaces based on recent work of Mak and Smith."
math,A note on iterated maps of the unit sphere,"Let $\mathcal{C}(S^{m})$ denote the set of continuous maps from the unit
sphere $S^{m}$ in $\mathbb{R}^{m+1}$ into itself endowed with the supremum
norm. We prove that the set $\{f^n: f\in \mathcal{C}(S^{m})~\text{and}~n\ge
2\}$ of iterated maps is not dense in $\mathcal{C}(S^{m})$. This, in
particular, proves that the periodic points of the iteration operator of order
$n$ are not dense in $\mathcal{C}(S^m)$ for all $n\ge 2$, providing an
alternative proof of the result that these operators are not Devaney chaotic on
$\mathcal{C}(S^m)$ proved in [M. Veerapazham, C. Gopalakrishna, W. Zhang,
Dynamics of the iteration operator on the space of continuous self-maps, Proc.
Amer. Math. Soc., 149(1) (2021), 217--229]."
math,The Geometry and Fundamental Groups of Solenoid Complements,"When a solenoid is embedded in three space, its complement is an open three
manifold. We discuss the geometry and fundamental groups of such manifolds, and
show that the complements of different solenoids (arising from different
inverse limits) have different fundamental groups. Embeddings of the same
solenoid can give different groups; in particular, the nicest embeddings are
unknotted at each level, and give an Abelian fundamental group, while other
embeddings have non-Abelian groups. We show using geometry that every solenoid
has uncountably many embeddings with non-homeomorphic complements."
math,"Assembly maps with coefficients in topological algebras and the integral
  K-theoretic Novikov conjecture","We prove that any countable discrete and torsion free subgroup of a general
linear group over an arbitrary field or a similar subgroup of an almost
connected Lie group satisfies the integral algebraic K-theoretic (split)
Novikov conjecture over \cpt and \S, where \cpt denotes the C^*-algebra of
compact operators and \S denotes the algebra of Schatten class operators. We
introduce assembly maps with finite coefficients and under an additional
hypothesis, we prove that such a group also satisfies the algebraic K-theoretic
Novikov conjecture over \bar{\mathbb{Q}} and \mathbb{C} with finite
coefficients. For all torsion free Gromov hyperbolic groups G, we demonstrate
that the canonical algebra homomorphism \cpt[G]\map C^*_r(G)\hat{\otimes}\cpt
induces an isomorphism between their algebraic K-theory groups."
math,On the Relation between K- and L-Theory of $C^*$-Algebras,"We prove the existence of a map of spectra $\tau_A \colon kA \to lA$ between
connective topological K-theory and connective algebraic L-theory of a complex
$C^*$-algebra A which is natural in A and compatible with multiplicative
structures. We determine its effect on homotopy groups and as a consequence
obtain a natural equivalence $KA[1/2] \to LA[1/2]$ of periodic K- and L-theory
spectra after inverting 2. We show that this equivalence extends to K- and
L-theory of real $C^*$-algebras. Using this we give a comparison between the
real Baum-Connes conjecture and the L-theoretic Farrell-Jones conjecture. We
conclude that these conjectures are equivalent after inverting 2 if and only if
a certain completion conjecture in L-theory is true."
math,"On Grothendieck's Conjecture about Principal Homogeneous Spaces for some
  Classical Algebraic Groups","In the present paper we investigate the question about the injectivity of the
map F(R) --> F(K) induced by the canonical inclusion of a local regular ring of
geometric type R to its field of fractions K for a homotopy invariant functor F
with transfers satisfying some additional properties. As an application we get
the original proof of Special Unitary Case of Grothendieck's conjecture about
principal homogeneous spaces and some other interesting examples."
math,Characters for Complex Bundles and their Connections,"The paper combines several fortunate mini miracles to achieve its two
objectives. These were woven together in a several year's effort to answer a
question raised by Iz Singer a decade ago. Our answer is accessible to the
topologist, to the differential geometer and to the analyst who appreciates the
statement of the Index theorem of Atiyah,Patodi,Singer for manifolds with
boundary. The mini miracles are these: a] The Conner Floyd miracle that complex
bordism tensored over the Todd genus and the Bott miracle that stable complex
vector bundles respectively satisfy the axioms of a generalized homology theory
and of a generalized cohomology theory. b] That these theories, with the
covariant and contravariant geometric representations indicated, stably almost
complex (SAC) manifolds modulo product relations and stable complex bundles,
are not only related by Alexander duality but they are also related by
Pontryagin duality. c] The abstract corollary of b] that stable complex bundles
have a complete system of numerical invariants and that these can be computed
by integrals of chern weil characteristic forms over manifolds with boundary
reduced modulo integers, thanks to the APS Index Theorem. d] The adiabatic
limit argument of the appendix to the last section showing a direct sum
connection on the total space of a riemannian family of Riemannian manifolds
with connection is Chern Simons equivalent in the limit to the Levi Civita
connection of the direct sum metric. This allows the invariants to be described
by the eta invariants of odd SAC manifolds reduced mod integers."
math,"Geometry of moduli spaces of meromorphic connections on curves, Stokes
  data, wild nonabelian Hodge theory, hyperkahler manifolds, isomonodromic
  deformations, Painleve equations, and relations to Lie theory",Summary of main work 1999-2012
math,BNSR invariants and $\ell^2$-homology,"We prove that if the $n$th $\ell^2$-Betti number of a group is non-zero then
its $n$th BNSR invariant over $\mathbb{Q}$ is empty, under suitable finiteness
conditions. We apply this to answer questions of Friedl--Vidussi and Llosa
Isenrich--Py about aspherical K\""ahler manifolds, to verify some cases of the
Singer Conjecture, and to compute certain BNSR invariants of poly-free and
poly-surface groups."
math,A Survey on Connes' Embedding Conjecture,"In a very celebrated paper A. Connes has formulated a conjecture which is now
one of the most important open problem in Operator Algebras. This importance
comes from the works of many mathematicians who have found some unexpected
equivalent statements showing as this conjecture is transversal to almost all
the sub-specialization of Operator Algebras. In this survey I would like to
give a more or less detailed description of all these approaches."
math,Smooth Blowups: Global vs. Local Perspectives,"We show that the global and local constructions of three types of blowup of a
smooth manifold along a closed submanifold in differential topology are
equivalent."
math,Green 2-functors,"We extend the theory of Mackey 2-functors introduced in arXiv:1808.04902 by
defining the appropriate notion of rings, namely Green 2-functors. After
providing the first results of our theory and abundant examples, we show how
all classical Green functors familiar from representation theory and topology
arise by decategorification, in various ways, of some Green 2-functor occurring
in Nature."
math,Global Mackey functors with operations and n-special lambda rings,"Systematically using the language of groupoids, we survey the theory of
global Mackey functors, global Green functors and global power functors. Given
a global power functor, we study rings with similar operations. The example of
n-class functions leads to the notion of an n-special lambda ring."
math,"Asymptotic dimension and small subsets in locally compact topological
  groups","We prove that for a coarse space $X$ the ideal $S(X)$ of small subsets of $X$
coincides with the ideal $D_<(X)$ of subsets $A\subset X$ of asymptotic
dimension $asdim(A)<asdim(X)$ provided that $X$ is coarsely equivalent to an
Euclidean space $R^n$. Also we prove that for a locally compact Abelian group
$X$, the equality $S(X)=D_<(X)$ holds if and only if the group $X$ is compactly
generated."
math,On the isometrization of groups of homeomorphisms,"Let $G$ be a group of homeomorphisms of a topological space $X$. $G$ is
$\textit{(properly) isometrizable}$ if there exists a $G$-invariant (proper)
gauge structure on $X$. $G$ is $\textit{equiregular}$ if for every $x \in X$
and every open neighborhood $U$ of $x$ in $X$ there is an open neighborhood $V$
of $x$ in $X$ such that $cl(V) \subset U$ and every $y \in X$ has an open
neighborhood $N_y$ with the property that for every $g \in G$, if $g(N_y) \cap
cl(V) \neq \emptyset$, then $g(N_y) \subset U$. $G$ is $\textit{nearly proper}$
if for all compact subsets $A$ and $B$ of $X$, $cl$ ( $\bigcup$ { $g(A):g\in G$
and $g(A)\cap B \neq \emptyset$ } ) is compact. $G$ $\textit{acts properly on}$
$X$ if for all compact subsets $A$ and $B$ of $X$, the subset $G_{A,B}$ = {
$g\in G : g(A) \cap B \neq \emptyset$ } is compact when $G$ is endowed with the
compact-open topology.
  THE ISOMETRIZATION THEOREM: If $X$ is a Hausdorff space and $G$ \ $X$ is a
paracompact regular space, then: $G$ is isometrizable if and only if $G$ is
equiregular.
  THE PROPER ISOMETRIZATION THEOREM: If $X$ is a locally compact
$\sigma$-compact Hausdorff space and $G$ \ $X$ is a regular space, then: $G$ is
properly isometrizable if and only if $G$ is equiregular and nearly proper.
  The PROPER ISOMETRIZATION THEOREM has the following corollary.
  THEOREM OF ABEL-MANOUSSOS-NOSKOV: If $X$ is a locally compact
$\sigma$-compact Hausdorff space and $G$ acts properly on $X$, then $X$ is
properly isometrizable."
math,"The definable content of homological invariants II: Čech cohomology
  and homotopy classification","This is the second installment in a series of papers applying descriptive set
theoretic techniques to both analyze and enrich classical functors from
homological algebra and algebraic topology. In it, we show that the \v{C}ech
cohomology functors $\check{\mathrm{H}}^n$ on the category of locally compact
separable metric spaces each factor into (i) what we term their definable
version, a functor $\check{\mathrm{H}}^n_{\mathrm{def}}$ taking values in the
category $\mathsf{GPC}$ of groups with a Polish cover (a category first
introduced in this work's predecessor), followed by (ii) a forgetful functor
from $\mathsf{GPC}$ to the category of groups. These definable cohomology
functors powerfully refine their classical counterparts: we show that they are
complete invariants, for example, of the homotopy types of mapping telescopes
of $d$-spheres or $d$-tori for any $d\geq 1$, and, in contrast, that there
exist uncountable families of pairwise homotopy inequivalent mapping telescopes
of either sort on which the classical cohomology functors are constant. We then
apply the functors $\check{\mathrm{H}}^n_{\mathrm{def}}$ to provide strong
solutions to higher-dimensional and equivariant generalizations of a seminal
problem in the development of algebraic topology, namely Borsuk and Eilenberg's
1936 problem of classifying, up to homotopy, the maps from a solenoid
complement $S^3\backslash\Sigma$ to the $2$-sphere.
  In the course of this work, we record Borel definable versions of a number of
classical results bearing on both the combinatorial and homotopical
formulations of \v{C}ech cohomology; in aggregate, this work may be regarded as
laying foundations for the descriptive set theoretic study of the homotopy
relation on the space of maps from a locally compact Polish space to a
polyhedron, a relation which embodies a substantial variety of classification
problems arising throughout mathematics."
math,An Invitation to Noncommutative Algebra,"This is a brief introduction to the world of Noncommutative Algebra aimed at
advanced undergraduate and beginning graduate students."
math,Floer Field Philosophy,"Floer field theory is a construction principle for e.g. 3-manifold invariants
via decomposition in a bordism category and a functor to the symplectic
category, and is conjectured to have natural 4-dimensional extensions. This
survey provides an introduction to the categorical language for the
construction and extension principles and provides the basic intuition for two
gauge theoretic examples which conceptually frame Atiyah-Floer type conjectures
in Donaldson theory as well as the relations of Heegaard Floer homology to
Seiberg-Witten theory."
math,"Modified mixed realizations, new additive invariants, and periods of dg
  categories","To every scheme, not necessarily smooth neither proper, we can associate its
different mixed realizations (de Rham, Betti, etale, Hodge, etc) as well as its
ring of periods. In this note, following an insight of Kontsevich, we prove
that, after suitable modifications, these classical constructions can be
extended from schemes to the broad setting of dg categories. This leads to new
additive invariants, which we compute in the case of differential operators, as
well as to a theory of periods of dg categories. Among other applications, we
prove that the ring of periods of a scheme is invariant under projective
homological duality. Along the way, we explicitly describe the modified mixed
realizations using the Tannakian formalism."
math,On the Structure of Lie Group C*-Algebras and Compact Quantum Groups,"We expose a K-theoretic approach to study group C*-algebras and C*-algebraic
compact quantum groups: 1. The conception of multidimensional geometric
quantization and the index of group C*-algebras; 2. the entire homology of
noncommutative de Rham currents and the noncommutative Chern characters, and
their computation for C*-algebras of compact Lie groups and compact quantum
groups."
math,Balanced factorisations in some algebras,"We prove that, in any field of characteristic not two and not three except
the five-element field, each element decomposes into a product of four factors
whose sum vanishes. We also find all $k,n,q$ such that every $n\times n$ matrix
over the $q$-element field decomposes into a product of $k$ commuting matrices
whose sum vanishes."
math,Balanced factorisations,"Any rational number can be factored into a product of several rationals whose
sum vanishes. This simple but nontrivial fact was suggested as a problem on a
maths olympiad for high-school students. We completely solve similar questions
in all finite fields and in some other rings, e.g., in the complex and real
matrix algebras. Also, we state several open questions."
math,"Picard-Fuchs equations, Integrable Systems, and higher Algebraic
  K-theory","This paper continues our previous work done in math.AG/0008207 and is an
attempt to establish a conceptual framework which generalizes the work of Manin
on the relation between non-linear second order ODEs of type Painleve VI and
integrable systems. The principle behind everything is a strong interaction
between K-theory and Picard-Fuchs type differential equations via Abel-Jacobi
maps. Our main result is an extension of a theorem of Donagi and Markman to our
setup."
math,"Who Gave you the Cauchy-Weierstrass Tale? The Dual History of Rigorous
  Calculus","Cauchy's contribution to the foundations of analysis is often viewed through
the lens of developments that occurred some decades later, namely the
formalisation of analysis on the basis of the epsilon-delta doctrine in the
context of an Archimedean continuum. What does one see if one refrains from
viewing Cauchy as if he had read Weierstrass already? One sees, with Felix
Klein, a parallel thread for the development of analysis, in the context of an
infinitesimal-enriched continuum. One sees, with Emile Borel, the seeds of the
theory of rates of growth of functions as developed by Paul du Bois-Reymond.
One sees, with E. G. Bjorling, an infinitesimal definition of the criterion of
uniform convergence. Cauchy's foundational stance is hereby reconsidered."
math,K-theory of locally finite graph $C^*$-algebras,"We calculate the K-theory of the Cuntz-Krieger algebra ${\cal O}_E$
associated with an infinite, locally finite graph, via the Bass-Hashimoto
operator. The formulae we get express the Grothendieck group and the Whitehead
group in purely graph theoretic terms.
  We consider the category of finite (black-and-white, bi-directed) subgraphs
with certain graph homomorphisms and construct a continuous functor to abelian
groups. In this category $K_0$ is an inductive limit of $K$-groups of finite
graphs, which were calculated in \cite{MM}.
  In the case of an infinite graph with the finite Betti number we obtain the
formula for the Grothendieck group $K_0({\cal O}_E)= {\mathbb
Z}^{\beta(E)+\gamma(E)},\,$ where $\beta(E)$ is the first Betti number and
$\gamma(E)$ is the valency number of the graph $E$. We note, that in the
infinite case the torsion part of $K_0$, which is present in the case of a
finite graph, vanishes. The Whitehead group depends only on the first Betti
number: $K_1({\cal O}_E)= {\mathbb Z}^{\beta(E)}$. These allow us to provide a
counterexample to the fact, which holds for finite graphs, that $K_1({\cal
O}_E)$ is the torsion free part of $K_0({\cal O}_E)$."
math,From Finite Sets to Feynman Diagrams,"`Categorification' is the process of replacing equations by isomorphisms. We
describe some of the ways a thoroughgoing emphasis on categorification can
simplify and unify mathematics. We begin with elementary arithmetic, where the
category of finite sets serves as a categorified version of the set of natural
numbers, with disjoint union and Cartesian product playing the role of addition
and multiplication. We sketch how categorifying the integers leads naturally to
the infinite loop space Omega^infinity S^infinity, and how categorifying the
positive rationals leads naturally to a notion of the `homotopy cardinality' of
a tame space. Then we show how categorifying formal power series leads to
Joyal's `especes des structures', or `structure types'. We also describe a
useful generalization of structure types called `stuff types'. There is an
inner product of stuff types that makes the category of stuff types into a
categorified version of the Hilbert space of the quantized harmonic oscillator.
We conclude by sketching how this idea gives a nice explanation of the
combinatorics of Feynman diagrams."
math,Relative critical loci and quiver moduli,"In this paper we identify the cotangent to the derived stack of
representations of a quiver $Q$ with the derived moduli stack of modules over
the Ginzburg dg-algebra associated with $Q$. More generally, we extend this
result to finite type dg-categories, to a relative setting as well, and to
deformations of these. It allows us to recover and generalize some results of
Yeung, and leads us to the discovery of seemingly new lagrangian subvarieties
in the Hilbert scheme of points in the plane."
math,"Amenability, connected components, and definable actions","We study amenability of definable and topological groups.
  Among our main technical tools is an elaboration on and strengthening of the
Massicot-Wagner version of the stabilizer theorem, and some results around
measures.
  As an application we show that if $G$ is an amenable topological group, then
the Bohr compactification of $G$ coincides with a certain ""weak Bohr
compactification"" introduced in [24]. Formally, $G^{00}_{topo} =
G^{000}_{topo}$. We also prove wide generalizations of this result, implying in
particular its extension to a ""definable-topological"" context, confirming the
main conjectures from [24].
  We introduce $\bigvee$-definable group topologies on a given
$\emptyset$-definable group $G$ (including group topologies induced by
type-definable subgroups as well as uniformly definable group topologies), and
prove that the existence of a mean on the lattice of closed, type-definable
subsets of $G$ implies (under some assumption) that $cl(G^{00}_M) =
cl(G^{000}_M)$ for any model $M$.
  We study the relationship between definability of an action of a definable
group on a compact space, weakly almost periodic actions, and stability. We
conclude that for any group $G$ definable in a sufficiently saturated
structure, every definable action of $G$ on a compact space supports a
$G$-invariant probability measure. This gives negative solutions to some
questions and conjectures from [22] and [24].
  We give an example of a $\emptyset$-definable approximate subgroup $X$ in a
saturated extension of the group $\mathbb{F}_2 \times \mathbb{Z}$ in a suitable
language for which the $\bigvee$-definable group $H:=\langle X \rangle$
contains no type-definable subgroup of bounded index. This refutes a conjecture
by Wagner and shows that the Massicot-Wagner approach to prove that a locally
compact ""model"" exists for each approximate subgroup does not work in general."
math,Central units of integral group rings,"We give an explicit description for a basis of a subgroup of finite index in
the group of central units of the integral group ring $\Z G$ of a finite
abelian-by-supersolvable group such that every cyclic subgroup of order not a
divisor of 4 or 6 is subnormal in $G$. The basis elements turn out to be a
natural product of conjugates of Bass units. This extends and generalizes a
result of Jespers, Parmenter and Sehgal showing that the Bass units generate a
subgroup of finite index in the center $\mathcal{Z} (\U (\Z G))$ of the unit
group $\U (\Z G)$ in case $G$ is a finite nilpotent group. Next, we give a new
construction of units that generate a subgroup of finite index in
$\mathcal{Z}(\U(\Z G))$ for all finite strongly monomial groups $G$. We call
these units generalized Bass units. Finally, we show that the commutator group
$\U(\Z G)/\U(\Z G)'$ and $\mathcal{Z}(\U(\Z G))$ have the same rank if $G$ is a
finite group such that $\Q G$ has no epimorphic image which is either a
non-commutative division algebra other than a totally definite quaternion
algebra, or a two-by-two matrix algebra over a division algebra with center
either the rationals or a quadratic imaginary extension of $\Q$. This allows us
to prove that in this case the natural images of the Bass units of $\Z G$
generate a subgroup of finite index in $\U(\Z G)/\U(\Z G)'$."
math,Adams operations and symmetries of representation categories,"Adams operations are the natural transformations of the representation ring
functor on the category of finite groups, and they are one way to describe the
usual lambda-ring structure on these rings. From the representation-theoretical
point of view, they codify some of the symmetric monoidal structure of the
representation category. We show that the monoidal structure on the category
alone, regardless of the particular symmetry, determines all the odd Adams
operations. On the other hand, we give examples to show that monoidal
equivalences do not have to preserve the second Adams operations and to show
that monoidal equivalences that preserve the second Adams operations do not
have to be symmetric. Along the way, we classify all possible symmetries and
all monoidal autoequivalences of representation categories of finite groups."
math,Parametrized K-Theory,"In nature, one observes that a K-theory of an object is defined in two steps.
First a ""structured"" category is associated to the object. Second, a K-theory
machine is applied to the latter category to produce an infinite loop space. We
develop a general framework that deals with the first step of this process. The
K-theory of an object is defined via a category of ""locally trivial"" objects
with respect to a pretopology. We study conditions ensuring an exact structure
on such categories. We also consider morphisms in K-theory that such contexts
naturally provide. We end by defining various K-theories of schemes and
morphisms between them."
math,Completion by Derived Double Centralizer,"Let A be a commutative ring, and let \a be a weakly proregular ideal in A.
(If A is noetherian then any ideal in it is weakly proregular.) Suppose M is a
compact generator of the category of cohomologically \a-torsion complexes. We
prove that the derived double centralizer of M is isomorphic to the \a-adic
completion of A. The proof relies on the MGM equivalence from [PSY] and on
derived Morita equivalence. Our result extends earlier work of
Dwyer-Greenlees-Iyengar [DGI] and Efimov [Ef]."
math,Chern characters via connections up to homotopy,"The aim of this note is to point out that Chern characters can be computed
using curvatures o ``super-connections up to homotopy'. We also present an
application to the vanishing theorem for Lie algebroids which is at the origin
of new secondary classes of algebroids (Fernandes), hence, in particular, of
Poisson manifolds."
math,On determinant functors and $K$-theory,"In this paper we introduce a new approach to determinant functors which
allows us to extend Deligne's determinant functors for exact categories to
Waldhausen categories, (strongly) triangulated categories, and derivators. We
construct universal determinant functors in all cases by original methods which
are interesting even for the known cases. Moreover, we show that the target of
each universal determinant functor computes the corresponding $K$-theory in
dimensions 0 and 1. As applications, we answer open questions by Maltsiniotis
and Neeman on the $K$-theory of (strongly) triangulated categories and a
question of Grothendieck to Knudsen on determinant functors. We also prove
additivity theorems for low-dimensional $K$-theory and obtain generators and
(some) relations for various $K_{1}$-groups."
math,The six operations in topology,"In this paper we show that the six functor formalism for sheaves on locally
compact Hausdorff topological spaces, as developed for example in Kashiwara and
Schapira's book Sheaves on Manifolds, can be extended to sheaves with values in
any closed symmetric monoidal $\infty$-category which is stable and bicomplete.
Notice that, since we do not assume that our coefficients are presentable or
restrict to hypercomplete sheaves, our arguments are not obvious and are
substantially different from the ones explained by Kashiwara and Schapira.
Along the way we also study locally contractible geometric morphisms and prove
that, if $f:X\rightarrow Y$ is a continuous map which induces a locally
contractible geometric morphism, then the exceptional pullback functor $f^!$
preserves colimits and can be related to the pullback $f^*$. At the end of our
paper we also show how one can express Atiyah duality by means of the six
functor formalism."
math,Motivic toposes,"We present a research programme aimed at constructing classifying toposes of
Weil-type cohomology theories and associated categories of motives, and
introduce a number of notions and preliminary results already obtained in this
direction. In order to analyze the properties of Weil-type cohomology theories
and their relations, we propose a framework based on atomic two-valued toposes
and homogeneous models. Lastly, we construct a syntactic triangulated category
whose dual maps to the derived categories of all the usual cohomology theories."
math,T-motives,"Considering a (co)homology theory $\mathbb{T}$ on a base category
$\mathcal{C}$ as a fragment of a first-order logical theory we here construct
an abelian category $\mathcal{A}[\mathbb{T}]$ which is universal with respect
to models of $\mathbb{T}$ in abelian categories. Under mild conditions on the
base category $\mathcal{C}$, e.g. for the category of algebraic schemes, we get
a functor from $\mathcal{C}$ to ${\rm Ch}({\rm Ind}(\mathcal{A}[\mathbb{T}]))$
the category of chain complexes of ind-objects of $\mathcal{A}[\mathbb{T}]$.
This functor lifts Nori's motivic functor for algebraic schemes defined over a
subfield of the complex numbers. Furthermore, we construct a triangulated
functor from $D({\rm Ind}(\mathcal{A}[\mathbb{T}]))$ to Voevodsky's motivic
complexes."
math,Definable categories and T-motives,"Making use of Freyd's free abelian category on a preadditive category we show
that if $T:D\rightarrow \mathcal{A}$ is a representation of a quiver $D$ in an
abelian category $\mathcal{A}$ then there is an abelian category $\mathcal{A}
(T)$, a faithful exact functor $F_T: \mathcal{A} (T) \to \mathcal{A}$ and an
induced representation $\tilde T: D \to \mathcal{A} (T)$ such that $F_T\tilde
T= T$ universally. We then can show that $\mathbb{T}$-motives as well as Nori's
motives are given by a certain category of functors on definable categories."
math,Syntactic categories for Nori motives,"We give a new construction, based on categorical logic, of Nori's $\mathbb
Q$-linear abelian category of mixed motives associated to a cohomology or
homology functor with values in finite-dimensional vector spaces over $\mathbb
Q$. This new construction makes sense for infinite-dimensional vector spaces as
well, so that it associates a $\mathbb Q$-linear abelian category of mixed
motives to any (co)homology functor, not only Betti homology (as Nori had done)
but also, for instance, $\ell$-adic, $p$-adic or motivic cohomology. We prove
that the $\mathbb Q$-linear abelian categories of mixed motives associated to
different (co)homology functors are equivalent if and only a family (of logical
nature) of explicit properties is shared by these different functors. The
problem of the existence of a universal cohomology theory and of the
equivalence of the information encoded by the different classical cohomology
functors thus reduces to that of checking these explicit conditions."
math,Group structures of a function spaces with the set-open topology,"In this paper, we find at the properties of the family lambda which imply
that the function space C(X,R^alpha) with the lambda-open topology is a
semitopological group (paratopological group, topological group, topological
vector space and other algebraic structures) under the usual operations of
addition and multiplication (and multiplication by scalars)."
math,"Modular categories as representations of the 3-dimensional bordism
  2-category","We show that once-extended anomalous 3-dimensional topological quantum field
theories valued in the 2-category of k-linear categories are in canonical
bijection with modular tensor categories equipped with a square root of the
global dimension in each factor."
math,Algebra+Homotopy=Operad,"This survey provides an elementary introduction to operads and to their
applications in homotopical algebra. The aim is to explain how the notion of an
operad was prompted by the necessity to have an algebraic object which encodes
higher homotopies. We try to show how universal this theory is by giving many
applications in Algebra, Geometry, Topology, and Mathematical Physics. (This
text is accessible to any student knowing what tensor products, chain
complexes, and categories are.)"
math,Derivations of Group Algebras,"In the paper, a method of describing the outer derivations of the group
algebra of a finitely presentable group is given. The description of
derivations is given in terms of characters of the groupoid of the adjoint
action of the group."
math,On triangle equivalences of stable categories,"We apply the Auslander-Buchweitz approximation theory to show that the Iyama
and Yoshino's subfactor triangulated category can be realized as a triangulated
quotient. Applications of this realization go in three directions. Firstly, we
recover both a result of Iyama and Yang and a result of the third author.
Secondly, we extend the classical Buchweitz's triangle equivalence from
Iwanaga-Gorenstein rings to Noetherian rings. Finally, we obtain the converse
of Buchweitz's triangle equivalence and a result of Beligiannis, and give
characterizations for Iwanaga-Gorenstein rings and Gorenstein algebras"
math,When Ext is a Batalin-Vilkovisky algebra,"We show under what conditions the complex computing general Ext-groups
carries the structure of a cyclic operad such that Ext becomes a
Batalin-Vilkovisky algebra. This is achieved by transferring cyclic cohomology
theories for the dual of a (left) Hopf algebroid to the complex in question,
which asks for the notion of contramodules introduced along with comodules by
Eilenberg-Moore half a century ago. Another crucial ingredient is an explicit
formula for the inverse of the Hopf-Galois map on the dual, by which we
illustrate recent categorical results and answer a long-standing open question.
As an application, we prove that the Hochschild cohomology of an associative
algebra A is Batalin-Vilkovisky if A itself is a contramodule over its
enveloping algebra A \otimes A^op. This is, for example, the case for symmetric
algebras and Frobenius algebras with semisimple Nakayama automorphism. We also
recover the construction for Hopf algebras."
math,A noncommutative calculus on the cyclic dual of Ext,"We show that if the cochain complex computing Ext groups (in the category of
modules over Hopf algebroids) admits a cocyclic structure, then the
noncommutative Cartan calculus structure on Tor over Ext dualises in a cyclic
sense to a calculus on Coext over Cotor. More precisely, the cyclic duals of
the chain resp. cochain spaces computing the two classical derived functors
lead to complexes that compute the more exotic ones, giving a cyclic opposite
module over an operad with multiplication that induce operations such as a Lie
derivative, a cap product (or contraction), and a (cyclic) differential, along
with higher homotopy operators defining a noncommutative Cartan calculus up to
homotopy. In particular, this allows to recover the classical Cartan calculus
from differential geometry or the Chevalley-Eilenberg calculus for
Lie(-Rinehart) algebras without any finiteness conditions or the use of
topological tensor products."
math,Cyclic duality between BV algebras and BV modules,"We show that if an operad is at the same time a cosimplicial object such that
the respective structure maps are compatible with the operadic composition in a
natural way, then one obtains a Gerstenhaber algebra structure on cohomology,
and if the operad is cyclic, even that of a BV algebra. In particular, if a
cyclic opposite module over an operad with multiplication is itself a cyclic
operad that meets the cosimplicial compatibility conditions, the cohomology of
its cyclic dual turns into a BV algebra. This amounts to conditions for when
the cyclic dual of a BV module is endowed with a BV algebra structure, a result
we exemplify by looking at classical and less classical (co)homology groups in
Hopf algebra theory."
math,Entropy on normed semigroups (Towards a unifying approach to entropy),"We present a unifying approach to the study of entropies in Mathematics, such
as measure entropy, topological entropy, algebraic entropy, set-theoretic
entropy. We take into account discrete dynamical systems, that is, pairs
$(X,T)$, where $X$ is the underlying space and $T:X\to X$ a transformation. We
see entropies as functions $h:\mathfrak X\to \mathbb R_+$, associating to each
flow $(X,T)$ of a category $\mathfrak X$ either a non negative real or
$\infty$. We introduce the notion of semigroup entropy $h_\mathfrak S:\mathfrak
S\to\mathbb R_+$, which is a numerical invariant attached to endomorphisms of
the category $\mathfrak S$ of normed semigroups. Then, for a functor
$F:\mathfrak X\to\mathfrak S$ from any specific category $\mathfrak X$ to
$\mathfrak S$, we define the functorial entropy $h_F:\mathfrak X\to\mathbb R_+$
as the composition $h_{\mathfrak S}\circ F$. Clearly, $h_F$ inherits many of
the properties of $h_\mathfrak S$, depending also on the properties of $F$.
Such general scheme permits to obtain relevant known entropies as functorial
entropies $h_F$, for appropriate categories $\mathfrak X$ and functors $F$, and
to establish the properties shared by them. In this way we point out their
common nature. Finally, we discuss and deeply analyze through the looking glass
of our unifying approach the relations between pairs of entropies. To this end
we formalize the notion of Bridge Theorem between two entropies $h_i:\mathfrak
X_i\to \mathbb R_+$, $i=1,2$, with respect to a functor $\varepsilon:\mathfrak
X_1\to\mathfrak X_2$. Then, for pairs of functorial entropies we use the above
scheme to introduce the notion and the related scheme of Strong Bridge Theorem,
which allows us to put under the same umbrella various relations between pairs
of entropies."
math,"From Freudenthal's Spectral Theorem to projectable hulls of unital
  Archimedean lattice-groups, through compactifications of minimal spectra","We use a landmark result in the theory of Riesz spaces - Freudenthal's 1936
Spectral Theorem - to canonically represent any Archimedean lattice-ordered
group $G$ with a strong unit as a (non-separating) lattice-group of real valued
continuous functions on an appropriate $G$-indexed zero-dimensional
compactification $w_GZ_G$ of its space $Z_G$ of \emph{minimal} prime ideals.
The two further ingredients needed to establish this representation are the
Yosida representation of $G$ on its space $X_G$ of \emph{maximal} ideals, and
the well-known continuous surjection of $Z_G$ onto $X_G$. We then establish our
main result by showing that the inclusion-minimal extension of this
representation of $G$ that separates the points of $Z_G$ - namely, the
sublattice subgroup of ${\rm C}\,(Z_G)$ generated by the image of $G$ along
with all characteristic functions of clopen (closed and open) subsets of $Z_G$
which are determined by elements of $G$ - is precisely the classical
projectable hull of $G$. Our main result thus reveals a fundamental
relationship between projectable hulls and minimal spectra, and provides the
most direct and explicit construction of projectable hulls to date. Our
techniques do require the presence of a strong unit."
math,"Factorization of quadratic polynomials in the ring of formal power
  series over Z","We establish necessary and sufficient conditions for a quadratic polynomial
to be irreducible in the ring $Z[[x]]$ of formal power series with integer
coefficients. For $n,m\ge 1$ and $p$ prime, we show that $p^n+p^m\beta x+\alpha
x^2$ is reducible in $Z[[x]]$ if and only if it is reducible in $Z_p[x]$, the
ring of polynomials over the $p$-adic integers."
math,Cellular categories and stable independence,"We exhibit a bridge between the theory of cellular categories, used in
algebraic topology and homological algebra, and the model-theoretic notion of
stable independence. Roughly speaking, we show that the combinatorial cellular
categories (those where, in a precise sense, the cellular morphisms are
generated by a set) are exactly those that give rise to stable independence
notions. We give two applications: on the one hand, we show that the abstract
elementary classes of roots of Ext studied by Baldwin-Eklof-Trlifaj are stable
and tame. On the other hand, we give a simpler proof (in a special case) that
combinatorial categories are closed under 2-limits, a theorem of Makkai and
Rosick\'y."
math,The Baum-Connes conjecture: an extended survey,"We present a history of the Baum-Connes conjecture, the methods involved, the
current status, and the mathematics it generated."
math,"Interpolated family of non group-like simple integral fusion rings of
  Lie type","This paper is motivated by the quest of a non-group irreducible finite index
depth 2 maximal subfactor. We compute the generic fusion rules of the
Grothendieck ring of Rep(PSL(2,q)), q prime-power, by applying a Verlinde-like
formula on the generic character table. We then prove that this family of
fusion rings R_q interpolates to all integers q>=2, providing (when q is not
prime-power) the first example of infinite family of non group-like simple
integral fusion rings. Furthermore, they pass all the known criteria of
(unitary) categorification. This provides infinitely many serious candidates
for solving the famous open problem of whether there exists an integral fusion
category which is not weakly group-theoretical. We prove that a complex
categorification (if any) of an interpolated fusion ring R_q (with q non
prime-power) cannot be braided, and so its Drinfeld center must be simple. In
general, this paper proves that a non-pointed simple fusion category is
non-braided if and only if its Drinfeld center is simple; and also that every
simple integral fusion category is weakly group-theoretical if and only if
every simple integral modular fusion category is pointed."
math,On Hilbert's fourth problem,"Hilbert's fourth problem asks for the construction and the study of metrics
on subsets of projective space for which the projective line segments are
geodesics. Several solutions of the problem were given so far, depending on
more precise interpretations of this problem, with various additional
conditions satisfied. The most interesting solutions are probably those
inspired from an integral formula that was first introduced in this theory by
Herbert Busemann. Besides that, Busemann and his school made a thorough
investigation of metrics defined on subsets of projective space for which the
projective lines are geodesics and they obtained several results,
characterizing several classes of such metrics. We review some of the
developments and important results related to Hilbert's problem, especially
those that arose from Busemann's work, mentioning recent results and
connections with several branches of mathematics, including Riemannian
geometry, the foundations of mathematics, the calculus of variations, metric
geometry and Finsler geometry."
math,A bug's eye view: the Riemannian exponential map on polyhedral surfaces,"We explore the perspective of a bug living on the two-dimensional surface of
a polyhedron. Images of various kinds of effects like lensing and cloaking are
shown via color pictures of three viewpoints: the first person perspective of
the bug, a map of the bug's viewpoint, and a look at the bug on the embedded
polyhedron from a three-dimensional exterior viewer. The pictures were
constructed by computing the exponential map of a polyhedron by cutting and
rotating faces into the tangent plane of the bug."
math,Igor Rostislavovich Shafarevich: in Memoriam,"The prominent Russian mathematician Igor Rostislavovich Shafarevich passed
away on February 19, 2017. In this article we supply his biography, discuss his
many important contributions to number theory, algebra and algebraic geometry,
and also discuss his political activity and some of his numerous publications
on social issues."
math,"Differentiable and algebroid cohomology, van Est isomorphisms, and
  characteristic classes","In the first section we discuss Morita invariance of differentiable/algebroid
cohomology.
  In the second section we present an extension of the van Est isomorphism to
groupoids. This immediately implies a version of Haefliger's conjecture for
differentiable cohomology.
  As a first application we clarify the connection between differentiable and
algebroid cohomology (proved in degree 1, and conjectured in degree 2 by
Weinstein-Xu).
  As a second application we extend van Est's argument for the integrability of
Lie algebras. Applied to Poisson manifolds, this immediately gives (a slight
improvement of) Hector-Dazord's integrability criterion.
  In the third section we describe the relevant characteristic classes of
representations, living in algebroid cohomology, as well as their relation to
the van Est map. This extends Evens-Lu-Weinstein's characteristic class
$\theta_{L}$ (hence, in particular, the modular class of Poisson manifolds),
and also the classical characteristic classes of flat vector bundles.
  In the last section we describe some applications to Poisson geometry (e.g.
we clarify the Morita invariance of Poisson cohomology, and of the modular
class)."
math,Connections up to homotopy and characteristic classes,"In this note we clarify the relevance of ``connections up to homotopy'' to
the theory of characteristic classes. We have already remarked \cite{Crai} that
such connections up to homotopy can be used to compute the classical Chern
characters. Here we present a slightly different argument for this, and then
proceed with the discussion of the flat (secondary) characteristic classes. As
an application, we clarify the relation between the two different approaches to
characteristic classes of algebroids (and of Poisson manifolds in particular):
we explain that the intrinsic characteristic classes are precisely the
secondary classes of the adjoint representation."
math,"Kazhdan projections, random walks and ergodic theorems","In this paper we investigate generalizations of Kazhdan's property $(T)$ to
the setting of uniformly convex Banach spaces. We explain the interplay between
the existence of spectral gaps and that of Kazhdan projections. Our methods
employ Markov operators associated to a random walk on the group, for which we
provide new norm estimates and convergence results. They exhibit useful
properties and flexibility, and allow to view Kazhdan projections in Banach
spaces as natural objects associated to random walks on groups.
  We give a number of applications of these results. In particular, we address
several open questions. We give a direct comparison of properties $(TE)$ and
$FE$ with Lafforgue's reinforced Banach property $(T)$; we obtain shrinking
target theorems for orbits of Kazhdan groups; finally, answering a question of
Willett and Yu we construct non-compact ghost projections for warped cones. In
this last case we conjecture that such warped cones provide counterexamples to
the coarse Baum-Connes conjecture."
math,Almost arithmetic progressions in the primes and other large sets,"A celebrated and deep result of Green and Tao states that the primes contain
arbitrarily long arithmetic progressions. In this note I provide a
straightforward argument demonstrating that the primes get arbitrarily close to
arbitrarily long arithmetic progressions. The argument also applies to `large
sets' in the sense of Erd\H{o}s-Tur\'an. The proof is short, completely
self-contained, and aims to give a heuristic explanation of why the primes, and
other large sets, possess arithmetic structure."
math,Coherence of the ring of periodic distributions,"It is shown that the ring of periodic distributions is a coherent ring (with
the operations of pointwise addition and convolution) by showing that the
isomorphic ring $s'$ of the Fourier coefficients (of sequences of at most
polynomial growth) with termwise operations is coherent. Moreover, it is shown
that the subring $\ell^\infty$ of $s'$ of all bounded sequences is coherent
too, while the subring $c$ of $\ell^\infty$ of all convergent sequences is not
coherent. It is also observed that $s'$ is a Hermite ring, but not a projective
free ring."
math,Multi-way expanders and imprimitive group actions on graphs,"For n at least 2, the concept of n-way expanders was defined by various
researchers. Bigger n gives a weaker notion in general, and 2-way expanders
coincide with expanders in usual sense. Koji Fujiwara asked whether these
concepts are equivalent to that of ordinary expanders for all n for a sequence
of Cayley graphs. In this paper, we answer his question in the affirmative.
Furthermore, we obtain universal inequalities on multi-way isoperimetric
constants on any finite connected vertex-transitive graph, and show that gaps
between these constants imply the imprimitivity of the group action on the
graph."
math,Iterated magnitude homology,"Magnitude homology is an invariant of enriched categories which generalizes
ordinary categorical homology -- the homology of the classifying space of a
small category. The classifying space can also be generalized in a different
direction: it extends from categories to bicategories as the geometric
realization of the geometric nerve. This paper introduces a hybrid of the two
ideas: an iterated magnitude homology theory for categories with a second- or
higher-order enrichment. This encompasses, for example, groups equipped with
extra structure such as a partial ordering or a bi-invariant metric. In the
case of a strict 2-category, iterated magnitude homology recovers the homology
of the classifying space; we investigate its content and behaviour when
interpreted for partially ordered groups, normed groups, and strict
$n$-categories for $n > 2$."
math,Auslander Bounds and Homological Conjectures,"Inspired by recent works on rings satisfying Auslander's conjecture, we study
invariants, which we call Auslander bounds, and prove that they have strong
relations to some homological conjectures."
math,"Asymptotic behaviors of representations of graded categories with
  inductive functors","In this paper we describe an inductive machinery to investigate asymptotic
behaviors of homology groups and related invariants of representations of
certain graded combinatorial categories over a commutative Noetherian ring $k$,
via introducing inductive functors which generalize important properties of
shift functors of $\mathrm{FI}$-modules. In particular, a sufficient criterion
for finiteness of Castelnuovo-Mumford regularity of finitely generated
representations of these categories is obtained. As applications, we show that
a few important infinite combinatorial categories appearing in representation
stability theory are equipped with inductive functors, and hence the finiteness
of Castelnuovo-Mumford regularity of their finitely generated representations
is guaranteed. We also prove that truncated representations of these categories
have linear minimal resolutions by relative projective modules, which are
precisely linear minimal projective resolutions when $k$ is a field of
characteristic 0."
math,Gorenstein homological theory for differential modules,"We show that a differential module is Gorenstein projective if and only if
its underlying module is Gorenstein projective. Dually, a differential module
is Gorenstein injective if and only if its underlying module is Gorenstein
injective."
math,Han's conjecture for bounded extensions,"Let $B\subset A$ be a left or right bounded extension of finite dimensional
algebras. We use the Jacobi-Zariski long nearly exact sequence to show that $B$
satisfies Han's conjecture if and only if $A$ does, regardless if the extension
splits or not. We provide conditions ensuring that an extension by arrows and
relations is left or right bounded. Finally we give a structure result for
extensions of an algebra given by a quiver and admissible relations, and
examples of non split left or right bounded extensions."
math,"Noncommutative Poisson structures, derived representation schemes and
  Calabi-Yau algebras","Recantly, William Crawley-Boevey proposed the definition of a Poisson
structure on a noncommutative algebra $A$ based on the Kontsevich principle.
His idea was to find the {\it weakest} possible structure on $A$ that induces
standard (commutative) Poisson structures on all representation spaces $
\Rep_V(A) $. It turns out that such a weak Poisson structure on $A$ is a Lie
algebra bracket on the 0-th cyclic homology $ \HC_0(A) $ satisfying some extra
conditions; it was thus called in an {\it $ H_0$-Poisson structure}.
  This paper studies a higher homological extension of this construction. In
our more general setting, we show that noncommutative Poisson structures in the
above sense behave nicely with respect to homotopy (in the sense that homotopy
equivalent NC Poisson structures on $A$ induce (via the derived representation
functor) homotopy equivalent Poisson algebra structures on the derved
representation schemes $\DRep_V(A) $). For an ordinary algebra $A$, a
noncommutative Poisson structure on a semifree (more generally, cofibrant)
resolution of $A$ yields a graded (super) Lie algebra structure on the full
cyclic homology $ \HC_\bullet(A) $ extending Crawley-Boevey's $\H_0$-Poisson
structure on $ \HC_0(A) $. We call such structures {\it derived Poisson
structures} on $A$.
  We also show that derived Poisson structures do arise in nature: the cobar
construction $\Omega(C)$ of an $(-n)$-cyclic coassociative DG coalgebra (in
particular, of the linear dual of a finite dimensional $n$-cyclic DG algebra)
$C$ carries a $(2-n)$-double Poisson bracket in the sense of Van den Bergh.
This in turn induces a corresponding noncommutative $(2-n)$-Poisson structure
on $\Omega(C)$. When (the semifree) DG algebra $\Omega(C)$ resolves an honest
algebra $A$, $A$ acquires a derived $(2-n)$-Poisson structure."
math,Beth definability and the Stone-Weierstrass Theorem,"The Stone-Weierstrass Theorem for compact Hausdorff spaces is a basic result
of functional analysis with far-reaching consequences. We introduce an
equational logic $\vDash_{\Delta}$ associated with an infinitary variety
$\Delta$ and show that the Stone-Weierstrass Theorem is a consequence of the
Beth definability property of $\vDash_{\Delta}$, stating that every implicit
definition can be made explicit. Further, we define an infinitary propositional
logic $\vdash_{\Delta}$ by means of a Hilbert-style calculus and prove a strong
completeness result whereby the semantic notion of consequence associated with
$\vdash_{\Delta}$ coincides with $\vDash_{\Delta}$."
math,"Ueber Eigenwerte, Integrale und pi^2/6: Die Idee der Spurformel (On
  eigenvalues, integrals and pi^2/6: The idea of the trace formula)","This is an expository article that results from a talk given to second year
students at Oldenburg university. The aim of the talk was to show what
beautiful and unexpected results may be obtained if one plays with daring
analogies in a way that is usually not done in undergraduate education
(unfortunately): We start from the fact that the sum of diagonal entries of a
symmetric matrix equals the sum of its eigenvalues. We then guess an analogous
formula where the matrix is replaced by a function of two real variables and
sums are replaced by integrals in a systematic way. We show that this is indeed
a worthwhile process: In a special case it yields that the sum of inverse
squares of the positive integers is pi^2/6. Finally, an outline of the proof of
the guessed formula is given, and further applications, for example to the
connection between billiards and the frequencies of a drum, are explained."
math,Shuffle Algebras and Non-Commutative Probability for Pairs of Faces,"One can build an operatorial model for freeness by considering either the
right-handed or the left-handed representation of algebras of operators acting
on the free product of the underlying pointed Hilbert spaces. Considering both
at the same time, that is, computing distributions of operators in the algebra
generated by the left- and right-handed representations, led Voiculescu in 2013
to define and study bifreeness and, in the sequel, triggered the development of
an extension of noncommutative probability now frequently referred to as
multi-faced (two-faced in the example given above). Many examples of two-faced
independences emerged these past years. Of great interest to us are biBoolean,
bifree and type I bimonotone independences. In this paper, we extend the preLie
calculus pertaining to free, Boolean, and monotone moment-cumulant relations
initiated by K. Ebrahimi-Fard and F. Patras to their above-mentioned two-faced
equivalents."
math,"On the dimension of $H^{*}((\mathbb Z_2)^{\times t}, \mathbb Z_2)$ as a
  module over Steenrod ring","We write $\mathbb P$ for the polynomial algebra in one variable over the
finite field $\mathbb Z_2$ and $\mathbb P^{\otimes t} = \mathbb Z_2[x_1,
\ldots, x_t]$ for its $t$-fold tensor product with itself. We grade $\mathbb
P^{\otimes t}$ by assigning degree $1$ to each generator. We are interested in
determining a minimal set of generators for the ring of invariants $(\mathbb
P^{\otimes t})^{G_t}$ as a module over Steenrod ring, $\mathscr A_2.$ Here
$G_t$ is a subgroup of the general linear group $GL(t, \mathbb Z_2).$ An
equivalent problem is to find a monomial basis of the space of ""unhit""
elements, $\mathbb Z_2\otimes_{\mathscr A_2} (\mathbb P^{\otimes t})^{G_t}$ in
each $t$ and degree $n\geq 0.$ The structure of this tensor product is proved
surprisingly difficult and has been not yet known for $t\geq 5,$ even for the
trivial subgroup $G_t = \{e\}.$ In the present paper, we consider the subgroup
$G_t = \{e\}$ for $t \in \{5, 6\},$ and obtain some new results on $\mathscr
A_2$-generators of $(\mathbb P^{\otimes t})^{G_t}$ in some degrees. At the same
time, some of their applications have been proposed. We also provide an
algorithm in MAGMA for verifying the results. This study can be understood as a
continuation of our recent works in [23, 25]."
math,A Thom Isomorphism for Infinite Rank Euclidean Bundles,"An equivariant Thom isomorphism theorem in operator K-theory is formulated
and proven for infinite rank Euclidean vector bundles over finite dimensional
Riemannian manifolds. The main ingredient in the argument is the construction
of a non-commutative C*-algebra associated to a bundle E -> M, equipped with a
compatible connection, which plays the role of the algebra of functions on the
infinite dimensional total space E. If the base M is a point, we obtain the
Bott periodicity isomorphism theorem of Higson-Kasparov-Trout for infinite
dimensional Euclidean spaces. The construction applied to an even (finite rank)
spin-c-bundle over an even-dimensional proper spin-c-manifold reduces to the
classical Thom isomorphism in topological K-theory. The techniques involve
non-commutative geometric functional analysis."
math,On C*-algebras and K-theory for infinite-dimensional Fredholm Manifolds,"Let M be a smooth Fredholm manifold modeled on a separable
infinite-dimensional Euclidean space E with Riemannian metric g. Given an
(augmented) Fredholm filtration F of M by finite-dimensional submanifolds
(M_n), we associate to the triple (M, g, F) a non-commutative direct limit
C*-algebra A(M, g, F) = lim A(M_n) that can play the role of the algebra of
functions vanishing at infinity on the non-locally compact space M. The
C*-algebra A(E), as constructed by Higson-Kasparov-Trout for their Bott
periodicity theorem for infinite dimensional Euclidean spaces, is isomorphic to
our construction when M = E. If M has an oriented Spin_q-structure (1 <= q
<=\infty), then the K-theory of this C*-algebra is the same (with dimension
shift) as the topological K-theory of M defined by Mukherjea. Furthermore,
there is a Poincare' duality isomorphism of this K-theory of M with the
compactly supported K-homology of M, just as in the finite-dimensional spin
setting."
math,"Elliptic regularity for Dirac operators on families of noncompact
  manifolds","We develop elliptic regularity theory for Dirac operators in a very general
framework: we consider Dirac operators linear over $C^*$-algebras, on
noncompact manifolds, and in families which are not necessarily locally trivial
fibre bundles."
math,Categorical Foundations for K-Theory,"Recall that the definition of the $K$-theory of an object C (e.g., a ring or
a space) has the following pattern. One first associates to the object C a
category A_C that has a suitable structure (exact, Waldhausen, symmetric
monoidal, ...). One then applies to the category A_C a ""$K$-theory machine"",
which provides an infinite loop space that is the $K$-theory K(C) of the object
C.
  We study the first step of this process. What are the kinds of objects to be
studied via $K$-theory? Given these types of objects, what structured
categories should one associate to an object to obtain $K$-theoretic
information about it? And how should the morphisms of these objects interact
with this correspondence?
  We propose a unified, conceptual framework for a number of important examples
of objects studied in $K$-theory. The structured categories associated to an
object C are typically categories of modules in a monoidal (op-)fibred
category. The modules considered are ""locally trivial"" with respect to a given
class of trivial modules and a given Grothendieck topology on the object C's
category."
math,"Restriction to finite-index subgroups as étale extensions in topology,
  KK-theory and geometry","For equivariant stable homotopy theory, equivariant KK-theory and equivariant
derived categories, we show how restriction to a subgroup of finite index
yields a finite commutative separable extension, analogous to finite \'etale
extensions in algebraic geometry."
math,"Brane actions, Categorification of Gromov-Witten theory and Quantum
  K-theory","Let X be a smooth projective variety. Using the idea of brane actions
discovered by To\""en, we construct a lax associative action of the operad of
stable curves of genus zero on the variety X seen as an object in
correspondences in derived stacks. This action encodes the Gromov-Witten theory
of X in purely geometrical terms and induces an action on the derived category
Qcoh(X) which allows us to recover the Quantum K-theory of Givental-Lee."
math,"The special fiber of the motivic deformation of the stable homotopy
  category is algebraic","For each prime $p$, we define a $t$-structure on the category
$\widehat{S^{0,0}}/\tau\text{-}\mathbf{Mod}_{harm}^b$ of harmonic
$\mathbb{C}$-motivic left module spectra over $\widehat{S^{0,0}}/\tau$, whose
MGL-homology has bounded Chow-Novikov degree, such that its heart is equivalent
to the abelian category of $p$-completed $BP_*BP$-comodules that are
concentrated in even degrees. We prove that
$\widehat{S^{0,0}}/\tau\text{-}\mathbf{Mod}_{harm}^b$ is equivalent to
$\mathcal{D}^b({{BP}_*{BP}\text{-}\mathbf{Comod}}^{{ev}})$ as stable
$\infty$-categories equipped with $t$-structures.
  As an application, for each prime $p$, we prove that the motivic Adams
spectral sequence for $\widehat{S^{0,0}}/\tau$, which converges to the motivic
homotopy groups of $\widehat{S^{0,0}}/\tau$, is isomorphic to the algebraic
Novikov spectral sequence, which converges to the classical Adams-Novikov
$E_2$-page for the sphere spectrum $\widehat{S^0}$. This isomorphism of
spectral sequences allows Isaksen and the second and third authors to compute
the stable homotopy groups of spheres at least to the 90-stem, with ongoing
computations into even higher dimensions."
math,"On weight complexes, pure functors, and detecting weights","This paper is dedicated to the study of weight complexes (defined on
triangulated categories endowed with weight structures) and their applications.
We introduce pure (co)homological functors that ""ignore all non-zero weights"";
these have a nice description in terms of weight complexes. For the weight
structure $w^G$ generated by the orbit category in the $G$-equivariant stable
homotopy category $SH(G)$ the corresponding pure cohomological functors into
abelian groups are the Bredon cohomology associated to Mackey functors ones;
pure functors related to motivic weight structures are also quite useful.
  Our results also give some (more) new weight structures. Moreover, we prove
that certain exact functors are conservative and ""detect weights""."
math,"Trace theories, Bokstedt periodicity and Bott periodicity","We flesh out the theory of ""trace theories"" and ""trace functors"" sketched in
arXiv:1308.3743, extend it to a homotopical setting, and prove a reconstruction
theorem claiming that a trace theory is completely determined by the associated
trace functor. As an application, we consider Topological Hoshschild Homology
$THH(A,M)$ of a algebra $A$ over a perfect field of positive characteristic,
with coefficients in a bimodule $M$, and prove two comparison results. Firstly,
we give a very simple algebraic model for THH in terms of Hochschild-Witt
Homology WHH of arXiv:1604.01588 (and we also identify $TP(A)$ with the
periodic version $WHP(A)$ of WHH). Secondly, we prove that $THH(A)$ is
identified with the zero term of the conjugate filtration on the co-periodic
cyclic homology $\overline{HP}(A)$ of arXiv:1509.08784, and the isomorphism
sends the Bokstedt periodicity generator to the Bott periodicity generator. We
also give an independent proof of Bokstedt periodicity that is somewhat shorter
than the usual ones."
math,DG quotients of DG categories,"Keller introduced a notion of quotient of a differential graded category
modulo a full differential graded subcategory which agrees with Verdier's
notion of quotient of a triangulated category modulo a triangulated
subcategory. This work is an attempt to further develop his theory.
  More than a half of the text is devoted to an overview of ""well known""
definitions and results. As a result, the e-print is essentially
self-contained."
math,A remark on K-theory and S-categories,"It is now well known that the K-theory of a Waldhausen category depends on
more than just its (triangulated) homotopy category (see [Schlichting]). The
purpose of this note is to show that the K-theory spectrum of a (good)
Waldhausen category is completely determined by its Dwyer-Kan simplicial
localization, without any additional structure. As the simplicial localization
is a refined version of the homotopy category which also determines the
triangulated structure, our result is a possible answer to the general
question: ``To which extent $K$-theory is not an invariant of triangulated
derived categories ?''"
math,"The Mukai pairing, I: a categorical approach","We study the Hochschild homology of smooth spaces, emphasizing the importance
of a pairing which generalizes Mukai's pairing on the cohomology of K3
surfaces. We show that integral transforms between derived categories of spaces
induce, functorially, linear maps on homology. Adjoint functors induce adjoint
linear maps with respect to the Mukai pairing. We define a Chern character with
values in Hochschild homology, and we discuss analogues of the
Hirzebruch-Riemann-Roch theorem and the Cardy Condition from physics. This is
done in the context of a 2-category which has spaces as its objects and
integral kernels as its 1-morphisms."
math,(Co)Simplicial Descent Categories,"In this paper we study the question of how to transfer homotopic structure
from the category sD of simplicial objects in a fixed category D to D. To this
end we use a sort of homotopy colimit s : sD --> D, which we call simple
functor. For instance, the Bousfield-Kan homotopy colimit in a Quillen
simplicial model category is an example of simple functor. As a remarkable
example outside the setting of Quillen models we include Deligne simple of
mixed Hodge complexes. We prove here that the simple functor induces an
equivalence on the corresponding localized categories. We also describe a
natural structure of Brown category of cofibrant objects on sD. We use these
facts to produce cofiber sequences on the localized category of D by E, which
give rise to a natural Verdier triangulated structure in the stable case."
math,Realizable homotopy colimits,"In this paper we prove that for any model category, the Bousfield-Kan
construction of the homotopy colimit is the absolute left derived functor of
the colimit. This is achieved by showing that the Bousfield-Kan homotopy
colimit is moreover a realizable homotopy colimit, defined by means of a
suitable 2-category of relative categories. In addition, in the case of exact
coproducts, we characterize the realizable homotopy colimits that satisfy a
cofinality property as those given by a formula following the pattern of
Bousfield-Kan construction: they are the composition of a ""geometric
realization"" with the simplicial replacement."
math,A derivability criterion based on the existence of adjunctions,"In this paper we introduce a derivability criterion of functors based on the
existence of adjunctions rather than on the existence of resolutions. It
constitutes a converse of Quillen-Maltsiniotis Derived Adjunction Theorem. We
present two consequences of our derivability criterion. On the one hand, we
prove that the two notions for homotopy colimits corresponding to Grothendieck
derivators and Quillen model categories are equivalent. On the other hand, we
deduce that the internal hom for derived Morita theory constructed by B. Toen
is indeed the right derived functor of the internal hom of dg-categories."
math,Non-connective K-theory of relative exact categories,"The main objective of this paper is to propose a definition of non-connective
K-theory for a wide class of relative exact categories which, in general, do
not satisfy the factorization axiom and confirm that it agrees with the
non-connective K-theory for exact categories and complicial exact categories
with weak equivalences. The main application is to study the topological
filtrations of non-connective K-theory of a noetherian commutative ring with
unit in terms of Koszul cubes."
math,Delooping of relative exact categories,"We introduce a delooping model of relative exact categories. It gives us a
condition that the negative K-group of a relative exact category becomes
trivial."
math,Model Structures on Commutative Monoids in General Model Categories,"We provide conditions on a monoidal model category $\mathcal{M}$ so that the
category of commutative monoids in $\mathcal{M}$ inherits a model structure
from $\mathcal{M}$ in which a map is a weak equivalence or fibration if and
only if it is so in $\mathcal{M}$. We then investigate properties of
cofibrations of commutative monoids, rectification between $E_\infty$-algebras
and commutative monoids, the relationship between commutative monoids and
monoidal Bousfield localization functors, when the category of commutative
monoids can be made left proper, and functoriality of the passage from a
commutative monoid $R$ to the category of commutative $R$-algebras. In the
final section we provide numerous examples of model categories satisfying our
hypotheses."
math,Quillen-Segal objects and structures: an overview,"Let $\mathscr{M}$ be a combinatorial and left proper model category, possibly
with a monoidal structure. If $\mathscr{O}$ is either a monad on $\mathscr{M}$
or an operad enriched over $\mathscr{M}$, define a QS-algebra in $\mathscr{M}$
to be a weak equivalence $\mathscr{F}: s(\mathscr{F})
\xrightarrow{\sim}t(\mathscr{F})$ such that the target $t(\mathscr{F})$ is an
$\mathscr{O}$-algebra in the usual sense. A classical $\mathscr{O}$-algebra is
a QS-algebra supported by an isomorphism $\mathscr{F}$. A QS-structure
$\mathscr{F}$ is also a weak equivalence such that $t(\mathscr{F})$ has a
structure, e.g, Hodge, twistorial, schematic, sheaf, etc. We build a homotopy
theory of these objects and compare it with that of usual
$\mathscr{O}$-algebras/structures. Our results rely on Smith's theorem on left
Bousfield localization for combinatorial and left proper model categories.
These ideas are derived from the theory of co-Segal algebras and categories."
math,Understanding higher structures through Quillen-Segal objects,"If $\mathscr{M}$ is a model category and $\mathcal{U}: \mathscr{A}
\rightarrow \mathscr{M}$ is a functor, we defined a Quillen-Segal
$\mathcal{U}$-object as a weak equivalence $\mathscr{F}: s(\mathscr{F})
\xrightarrow{\sim} t(\mathscr{F})$ such that $t(\mathscr{F})=\mathcal{U}(b)$
for some $b\in \mathscr{A}$. If $\mathcal{U}$ is the nerve functor
$\mathcal{U}: \mathbf{Cat} \rightarrow \mathbf{sSet}_J$, with the Joyal model
structure on $\mathbf{sSet}$, then studying the comma category
$(\mathbf{sSet}_J \downarrow \mathcal{U})$ leads naturally to concepts, such as
Lurie's $\infty$-operad. It also gives simple examples of presentable, stable
$\infty$-category, and higher topos. If we consider the \textit{coherent nerve}
$\mathcal{U}: \mathbf{sCat}_B \rightarrow \mathbf{sSet}_J$, then the theory of
QS-objects directly connects with the program of Riehl and Verity. If we apply
our main result when $\mathcal{U}$ is the identity $Id: \mathbf{sSet}_Q
\rightarrow \mathbf{sSet}_Q$, with the Quillen model structure, the homotopy
theory of QS-objects is equivalent to that of Kan complexes and we believe that
this is an \textit{avatar} of Voevodsky's \textit{Univalence axiom}. This
equivalence holds for any combinatorial and left proper $\mathscr{M}$. This
result agrees with our intuition, since by essence the `\textit{Quillen-Segal
type}' is the \textit{Equivalence type}"
math,"Biextensions, bimonoidal functors, multilinear functor calculus, and
  categorical rings","We associate to a bimonoidal functor, i.e. a bifunctor which is monoidal in
each variable, a nonabelian version of a biextension. We show that such a
biextension satisfies additional triviality conditions which make it a bilinear
analog of the kind of spans known as butterflies and, conversely, these data
determine a bimonoidal functor. We extend this result to $n$-variables, and
prove that, in a manner analogous to that of butterflies, these
multi-extensions can be composed. This is phrased in terms of a multilinear
functor calculus in a bicategory. As an application, we study a bimonoidal
category or stack, treating the multiplicative structure as a bimonoidal
functor with respect to the additive one. In the context of the multilinear
functor calculus, we view the bimonoidal structure as an instance of the
general notion of pseudo-monoid. We show that when the structure is ring-like,
i.e. the pseudo-monoid is a stack whose fibers are categorical rings, we can
recover the classification by the third Mac Lane cohomology of a ring with
values in a bimodule."
math,Stacks of Ann-Categories and their morphisms,"We show that $\mathit{ann}$-categories admit a presentation by crossed
bimodules, and prove that morphisms between them can be expressed by special
kinds spans between the presentations. More precisely, we prove the groupoid of
morphisms between two $\mathit{ann}$-categories is equivalent to that of
bimodule butterflies between the presentations. A bimodule butterfly is a
specialization of a butterfly, i.e. a special kind of span or fraction, between
the underlying complexes"
math,On the category of stratifolds,"Stratifolds are considered from a categorical point of view. We show among
others that the category of stratifolds fully faithfully embeds into the
category of ${\mathbb R}$-algebras as does the category of smooth manifolds. We
prove that a variant of the Serre-Swan theorem holds for stratifolds. In
particular, the category of vector bundles over a stratifold is shown to be
equivalent to the category of vector bundles over an associated affine scheme
although the latter is in general larger than the stratifold itself."
math,Homotopical Adjoint Lifting Theorem,"This paper provides a homotopical version of the adjoint lifting theorem in
category theory, allowing for Quillen equivalences to be lifted from monoidal
model categories to categories of algebras over colored operads. The generality
of our approach allows us to simultaneously answer questions of rectification
and of changing the base model category to a Quillen equivalent one. We work in
the setting of colored operads, and we do not require them to be
$\Sigma$-cofibrant. Special cases of our main theorem recover many known
results regarding rectification and change of model category, as well as
numerous new results. In particular, we recover a recent result of
Richter-Shipley about a zig-zag of Quillen equivalences between commutative
$H\mathbb{Q}$-algebra spectra and commutative differential graded
$\mathbb{Q}$-algebras, but our version involves only three Quillen equivalences
instead of six. We also work out the theory of how to lift Quillen equivalences
to categories of colored operad algebras after a left Bousfield localization."
math,"On torsion pairs, (well generated) weight structures, adjacent
  $t$-structures, and related (co)homological functors","The paper contains a collection of results related to weight structures,
$t$-structures, and (more generally) to torsion pairs. For any weight structure
$w$ we study (co)homological pure functors; these ""ignore all weights except
weight zero"" and have already found several applications. We also study virtual
$t$-truncations of cohomological functors coming from $w$. These are closely
related to $t$-structures; so we prove in several cases (including certain
categories of coherent sheaves) that $w$ ""gives"" a $t$-structure (that is
adjacent or $\Phi$-orthogonal to it). We also study in detail ""well generated""
weight structures (and prove that any perfect set of objects generates a weight
structure). The existence of weight structures right adjacent to compactly
generated $t$-structures (and constructed using Brown-Comenetz duality) implies
that the hearts of the latter have injective cogenerators and satisfy the AB3*
axiom; actually, ""most of them"" are Grothendieck abelian (due to the existence
of ""regularly orthogonal"" weight structures).
  It is convenient for us to use the notion of torsion pairs; these essentially
generalize both weight structures and $t$-structures. We prove several
properties of torsion pairs (that are rather parallel to that of weight
structures); we also generalize a theorem of D. Pospisil and J. Stovicek to
obtain a classification of compactly generated torsion pairs."
math,Arrow Categories of Monoidal Model Categories,"We prove that the arrow category of a monoidal model category, equipped with
the pushout product monoidal structure and the projective model structure, is a
monoidal model category. This answers a question posed by Mark Hovey, and has
the important consequence that it allows for the consideration of a monoidal
product in cubical homotopy theory. As illustrations we include numerous
examples of non-cofibrantly generated monoidal model categories, including
chain complexes, small categories, topological spaces, and pro-categories."
math,Smith Ideals of Operadic Algebras in Monoidal Model Categories,"Building upon Hovey's work on Smith ideals for monoids, we develop a homotopy
theory of Smith ideals for general operads in a symmetric monoidal category.
For a sufficiently nice stable monoidal model category and an operad satisfying
a cofibrancy condition, we show that there is a Quillen equivalence between a
model structure on Smith ideals and a model structure on algebra maps induced
by the cokernel and the kernel. For symmetric spectra, this applies to the
commutative operad and all Sigma-cofibrant operads. For chain complexes over a
field of characteristic zero and the stable module category, this Quillen
equivalence holds for all operads. This paper ends with a comparison between
the semi-model category approach and the $\infty$-category approach to encoding
the homotopy theory of algebras over Sigma-cofibrant operads that are not
necessarily admissible."
math,The categorified Grothendieck-Riemann-Roch theorem,"In this paper we prove a categorification of the Grothendieck-Riemann-Roch
theorem. Our result implies in particular a Grothendieck-Riemann-Roch theorem
for To\""en and Vezzosi's secondary Chern character. As a main application, we
establish a comparison between the To\""en-Vezzosi Chern character and the
classical Chern character, and show that the categorified Chern character
recovers the classical de Rham realization."
math,Categorified algebra and equivariant homotopy theory,"This dissertation comprises three collections of results, all united by a
common theme. The theme is the study of categories via algebraic techniques,
considering categories themselves as algebraic objects. This algebraic approach
to category theory is central to noncommutative algebraic geometry, as realized
by recent advances in the study of noncommutative motives.
  We have success proving algebraic results in the general setting of symmetric
monoidal and semiring $\infty$-categories, which categorify abelian groups and
rings, respectively. For example, we prove that modules over the semiring
category Fin of finite sets are cocartesian monoidal $\infty$-categories, and
modules over Burn (the Burnside $\infty$-category) are additive
$\infty$-categories.
  As a consequence, we can regard Lawvere theories as cyclic
$\text{Fin}^\text{op}$-modules, leading to algebraic foundations for the higher
categorical study of Lawvere theories. We prove that Lawvere theories function
as a home for an algebraic Yoneda lemma.
  Finally, we provide evidence for a formal duality between naive and genuine
equivariant homotopy theory, in the form of a group-theoretic Eilenberg-Watts
Theorem. This sets up a parallel between equivariant homotopy theory and
motivic homotopy theory, where Burnside constructions are analogous to Morita
theory. We conjecture that this relationship could be made precise within the
context of noncommutative motives over the field with one element."
math,The triangulated categories of framed bispectra and framed motives,"An alternative approach to the classical Morel-Voevodsky stable motivic
homotopy theory $SH(k)$ is suggested. The triangulated category of framed
bispectra $SH_{nis}^{fr}(k)$ and effective framed bispectra
$SH_{nis}^{fr,eff}(k)$ are introduced in the paper. Both triangulated
categories only use Nisnevich local equivalences and have nothing to do with
any kind of motivic equivalences. It is shown that $SH_{nis}^{fr}(k)$ and
$SH_{nis}^{fr,eff}(k)$ recover the classical Morel-Voevodsky triangulated
categories of bispectra $SH(k)$ and effective bispectra $SH^{eff}(k)$
respectively.
  We also recover $SH(k)$ and $SH^{eff}(k)$ as the triangulated category of
framed motivic spectral functors $SH_{S^1}^{fr}[\mathcal Fr_0(k)]$ and the
triangulated category of framed motives $\mathcal {SH}^{fr}(k)$ respectively
constructed in the paper."
math,The spectrum of derived Mackey functors,"We compute the spectrum of the category of derived Mackey functors (in the
sense of Kaledin) for all finite groups. We find that this space captures
precisely the top and bottom layers (i.e. the height infinity and height zero
parts) of the spectrum of the equivariant stable homotopy category. Due to this
truncation of the chromatic information, we are able to obtain a complete
description of the spectrum for all finite groups, despite our incomplete
knowledge of the topology of the spectrum of the equivariant stable homotopy
category. From a different point of view, we show that the spectrum of derived
Mackey functors can be understood as the space obtained from the spectrum of
the Burnside ring by ""ungluing"" closed points. In order to compute the
spectrum, we provide a new description of Kaledin's category, as the derived
category of an equivariant ring spectrum, which may be of independent interest.
In fact, we clarify the relationship between several different categories,
establishing symmetric monoidal equivalences and comparisons between the
constructions of Kaledin, the spectral Mackey functors of Barwick, the ordinary
derived category of Mackey functors, and categories of modules over certain
equivariant ring spectra. We also illustrate an interesting feature of the
ordinary derived category of Mackey functors that distinguishes it from other
equivariant categories relating to the behavior of its geometric fixed points."
math,"Nilpotent invariance of semi-topological K-theory of dg-algebras and the
  lattice conjecture","We show existence of a natural rational structure on periodic cyclic
homology, conjectured by L. Katzarkov, M. Kontsevich, T. Pantev, for several
classes of dg-categories, including proper connective $\mathbb{C}$-dg-algebras
and dg-categories of local systems. The main ingredient is derived nilpotent
invariance of A. Blanc's semi-topological K-theory, which we establish along
the way."
math,Godement resolution and operad sheaf homotopy theory,"We show how to induce products in sheaf cohomology for a wide variety of
coefficients: sheaves of dg commutative and Lie algebras, symmetric
Omega-spectra, filtered dg algebras, operads and operad algebras."
math,Galois descent criteria,"This paper gives an introduction to homotopy descent, and its applications in
algebraic $K$-theory computations for fields. On the \'etale site of a field, a
fibrant model of a simplicial presheaf can be constructed from naive Galois
cohomological objects given by homotopy fixed point constructions, but only up
to pro-equivalence. The homotopy fixed point spaces define finite Galois
descent for simplicial presheaves (and their relatives) over a field, but a
pro-categorical construction is a necessary second step for passage from finite
descent conditions to full homotopy descent in a Galois cohomological setting."
math,The universal six-functor formalism,"We prove that Morel-Voevodsky's stable $\mathbb{A}^1$-homotopy theory affords
the universal coefficient system, giving rise to Grothendieck's six operations."
math,Motivic colimits and extended powers,"We define a notion of colimit for diagrams in a motivic category indexed by a
presheaf of spaces (e.g. an \'etale classifying space), and we study basic
properties of this construction. As a case study, we construct the motivic
analogs of the classical extended and generalized powers, which refine the
categorical versions of these constructions as special cases. We also offer
more computationally tractable models of these constructions using equivariant
motivic homotopy theory. This is the first in a series of papers on power
operations in motivic stable homotopy theory."
math,On topological motives,"Following Eilenberg-Steenrod axiomatic approach we construct the universal
ordinary homology theory for any homological structure on a given category by
representing ordinary theories with values in abelian categories. For a
convenient category of spaces we then obtain a universal abelian category which
can be actually described for CW-complexes as the category of hieratic modules."
math,Riemann-Roch theorems in monoidal 2-categories,"Smooth and proper dg-algebras have an Euler class valued in the Hochschild
homology of the algebra. This Euler class is worthy of this name since it
satisfies many familiar properties including compatibility with the familiar
pairing on the Hochschild homology of the algebra and that of its opposite.
This compatibility is the Riemann-Roch theorems of Shklyarov and Petit.
  In this paper we prove a broad generalization of these Riemann-Roch theorems.
We generalize from the bicategory of dg-algebras and their bimodules to
monoidal bicategories and from Euler class to traces of non identity maps. Our
generalization also implies spectral Riemann-Roch theorems.
  We regard this result as an instantiation of a 2-dimensional generalized
cobordism hypothesis. This perspective draws the result close to many others
that generalize results about Euler characteristics and classes to
bicategorical traces."
math,Finite approximations as a tool for studying triangulated categories,"Small, finite entities are easier and simpler to manipulate than gigantic,
infinite ones. Consequently huge chunks of mathematics are devoted to methods
reducing the study of big, cumbersome objects to an analysis of their finite
building blocks. The manifestation of this general pattern, in the study of
derived and triangulated categories, dates back almost to the beginnings of the
subject -- more precisely to articles by Illusie in SGA6, way back in the early
1970s.
  What's new, at least new in the world of derived and triangulated categories,
is that one gets extra mileage from analysing more carefully and quantifying
more precisely just how efficiently one can estimate infinite objects by finite
ones. This leads one to the study of metrics on triangulated categories, and of
how accurately an object can be approximated by finite objects of bounded size."
math,Global Koszul duality,"We construct a monoidal model structure on the category of all curved
coalgebras and show that it is Quillen equivalent, via the extended bar-cobar
adjunction, to another model structure we construct on the category of curved
algebras. When the coalgebras under consideration are conilpotent and the
algebras are dg, i.e. uncurved, this corresponds to the ordinary dg Koszul
duality of Positselski and Keller-Lef\`evre. As an application we construct
global noncommutative moduli spaces for flat connections on vector bundles,
holomorphic structures on almost complex vector bundles, dg modules over a dg
algebra, objects in a dg category, and others."
math,"K-flatness in Grothendieck categories: Application to quasi-coherent
  sheaves","Let $(\mathcal{G},\otimes)$ be any closed symmetric monoidal Grothendieck
category. We show that K-flat covers exist universally in the category of chain
complexes and that the Verdier quotient of $K(\mathcal{G})$ by the K-flat
complexes is always a well generated triangulated category. Under the further
assumption that $\mathcal{G}$ has a set of $\otimes$-flat generators we can
show more: (i) The category is in recollement with the $\otimes$-pure derived
category and the usual derived category, and (ii) The usual derived category is
the homotopy category of a cofibrantly generated and monoidal model structure
whose cofibrant objects are precisely the K-flat complexes. We also give a
condition guaranteeing that the right orthogonal to K-flat is precisely the
acyclic complexes of $\otimes$-pure injectives. We show this condition holds
for quasi-coherent sheaves over a quasi-compact and semiseparated scheme."
math,Rational Enriched Motivic Spaces,"Enriched motivic $\mathcal A$-spaces are introduced and studied in this
paper, where $\mathcal A$ is an additive category of correspondences. They are
linear counterparts of motivic $\Gamma$-spaces. It is shown that rational
special enriched motivic $\widetilde{\mathrm{Cor}}$-spaces recover connective
motivic bispectra with rational coefficients, where $\widetilde{\mathrm{Cor}}$
is the category of Milnor--Witt correspondences."
math,Cohomology and deformations of Courant pairs,"In this note we define a notion of Courant pair as a Courant algebra over the
Lie algebra of linear derivations on an associative algebra. We study formal
deformations of Courant pairs by constructing a cohomology bicomplex with
coefficients in a module from the cochain complexes defining Hochschild
cohomology and Leibniz cohomology."
math,A Kronecker-Weyl theorem for subsets of abelian groups,"Let N be the set of non-negative integer numbers, T the circle group and c
the cardinality of the continuum. Given an abelian group G of size at most 2^c
and a countable family F of infinite subsets of G, we construct ""Baire many""
monomorphisms p: G --> T^c such that p(E) is dense in {y in T^c : ny=0}
whenever n in N, E in F, nE={0} and {x in E: mx=g} is finite for all g in G and
m such that n=mk for some k in N--{1}. We apply this result to obtain an
algebraic description of countable potentially dense subsets of abelian groups,
thereby making a significant progress towards a solution of a problem of Markov
going back to 1944. A particular case of our result yields a positive answer to
a problem of Tkachenko and Yaschenko. Applications to group actions and
discrete flows on T^c, diophantine approximation, Bohr topologies and Bohr
compactifications are also provided."
math,New directions in Nielsen-Reidemeister theory,"The purpose of this expository paper is to present new directions in the
classical Nielsen-Reidemeister fixed point theory. We describe twisted
Burnside-Frobenius theorem, groups with $R_\infty$ \emph{property} and a
connection between Nielsen fixed point theory and symplectic Floer homology."
math,Subgroup proximity in Banach Lie groups,"Let $U$ be a Banach Lie group and $G\le U$ a compact subgroup. We show that
closed Lie subgroups of $U$ contained in sufficiently small neighborhoods
$V\supseteq G$ are compact, and conjugate to subgroups of $G$ by elements close
to $1\in U$; this generalizes a well-known result of Montgomery and Zippin's
from finite- to infinite-dimensional Lie groups. Along the way, we also prove
an approximate counterpart to Jordan's theorem on finite subgroups of general
linear groups: finite subgroups of $U$ contained in sufficiently small
neighborhoods $V\supseteq G$ have normal abelian subgroups of index bounded in
terms of $G\le U$ alone.
  Additionally, various spaces of compact subgroups of $U$, equipped with the
Hausdorff metric attached to a complete metric on $U$, are shown to be analytic
Banach manifolds; this is the case for both (a) compact groups of a given,
fixed dimension, or (b) compact (possibly disconnected) semisimple subgroups.
Finally, we also prove that the operation of taking the centralizer (or
normalizer) of a compact subgroup of $U$ is continuous (respectively upper
semicontinuous) in the appropriate sense."
math,"Additive invariants of toric and twisted projective homogeneous
  varieties via noncommutative motives","I. Panin proved in the nineties that the algebraic K-theory of twisted
projective homogeneous varieties can be expressed in terms of central simple
algebras. Later, Merkurjev and Panin described the algebraic K-theory of toric
varieties as a direct summand of the algebraic K-theory of separable algebras.
In this article, making use of the recent theory of noncommutative motives, we
extend Panin and Merkurjev-Panin computations from algebraic K-theory to every
additive invariant. As a first application, we fully compute the cyclic
homology (and all its variants) of twisted projective homogeneous varieties. As
a second application, we show that the noncommutative motive of a twisted
projective homogeneous variety is trivial if and only if the Brauer classes of
the associated central simple algebras are trivial. Along the way we construct
a fully-faithful tensor functor from Merkurjev-Panin's motivic category to
Kontsevich's category of noncommutative Chow motives, which is of independent
interest."
physics,"German to Spanish translation of Einstein's work on the formation of
  meanders in rivers","In 1926 Albert Einstein gave a clear explanation of the physical processes
involved in the meander formation and evolution in open channels (Einstein,
1926). Although this work is far from being recognized as one of his greatest
achievements, such as his annus mirabilis papers in 1905, he shows a truly
remarkable didactic skills that make it easy to understand even to the
non-specialist. In particular, a brilliant explanation of the tea leaf paradox
can be found in this paper of 1926, presented as a simple experiment for
clarifying the role of Earth rotation and flow curvature in the differential
river banks erosion. This work deserves to be considered as a pioneering work
that has laid a basic knowledge in currently very active research fields in
fluvial geomorphology, estuarine physics, and hydraulic engineering. In
response to the curiosity aroused and transmitted to the authors over the years
by undergraduates and MSc. students, and also due to its historical and
scientific significance, we present here the Spanish translation of Einstein's
original work published in German in 1926 in Die Naturwissenschaften (Einstein,
1926). Einstein's drawings have not been interpreted, but just updated
preserving their original spirit."
physics,Scientific Metaphors in the journalistic discourse,"Scientific education and divulgation not only amplify people's vocabulary and
repertory of scientific concepts but, at the same time, promote the diffusion
of certain conceptual and cognitive metaphors. Here we make some hypothesis
about this process, proposing a classification in terms of visible, invisible,
basic and derived metaphors. We focus our attention in contemporary and
classical physics metaphors applied to psychological and socio-economical
phenomena, and we study two exemplar cases through an exhaustive exam of the
online content of large Brazilian journalistic portals. Finally, we present
implications and suggestions from the cognitive metaphor theory for the
scientific education and divulgation process."
physics,How a fake Kepler portrait became iconic,"For several decades a portrait of Johannes Kepler has been widely circulating
among professional astronomers, scientific and academic institutions, and the
general public. Despite its provenance and identification having been
questioned in the early part of the last century, this painting has reached
iconic status. We review its history from its first mention in the literature
in the 1870s to a published but virtually unknown judgment of competent art
experts of the 1920s that the work is in fact an early nineteenth century
forgery. We display the painting in context with other more secure portraits
and suggest that if it is based on anything, the painting may derive from the
well known portrait from life of Michael M\""astlin. This correction takes on
certain urgency since 2021 is the 450th anniversary of Kepler's birth."
physics,Ab Initio Study of Different Acid Molecules Interacting with H2O,"Using the Gaussian-03 for ab initio calculations, we have studied interaction
of different acid molecules with a single water molecule. The molecular and
supermolecular optimized structures were found with the Becke-3-Lee-Yang-Parr
(B3LYP-hybrid potential) calculations of density-functional theory (DFT)
methods as well as the Moeller-Plesset second-order perturbation theory, using
the basis set of Aug-cc-pVDZ quality and the CRENBL ECP effective core
potential for molecules containing heavy iodine atom. Possible isomers of
studied acids and supermolecules, consisting of acid molecules coupled with a
single water molecule, are shown. Energies, zero-point energies (ZPEs), thermal
enthalpies and free energies, as well as the corresponding binding energies for
the theoretical methods were calculated. It was found that optimized structures
of supermolecular isomers with lowest energies corresponding to the global
minimum on the potential energy surfaces can be different for both theories.
The simplest structure acids H2S and H2Se, forming acid-water supermolecules,
can give clear evidence of disagreement of the two theoretical methods
concerning optimization of lowest energy structures, because the B3LYP-DFT
method gives the lowest-energy structure for the first supermolecular isomer,
but the MP2 method for the second possible isomer. A dramatic difference
between potential energy surfaces for both theories applying to the optimized
structure finding of the H2SO3-H2O supermolecular isomers was found, because
MP2 supermolecular geometries cannot exist for the corresponding B3LYP-DFT
ones, for which the frequency characteristics of the supermolecular isomers
were also calculated. In general, the binding energies and ZPE ones for the MP2
method are 10-15% larger than those for the B3LYP-DFT method."
physics,Hollywood Blockbusters: Unlimited Fun but Limited Science Literacy,"In this article, we examine specific scenes from popular action and sci-fi
movies and show how they blatantly break the laws of physics, all in the name
of entertainment, but coincidentally contributing to science illiteracy."
physics,"Revealing pre-earthquake signatures in atmosphere and ionosphere
  associated with 2015 M7.8 and M7.3 events in Nepal. Preliminary results","We analyze retrospectively/prospectively the transient variations of three
different physical parameters of atmosphere during the time of M7.8 and M7.3
events in Nepal: outgoing earth radiation (OLR), GPS/TEC and the thermodynamic
proprieties in the lower atmosphere. We found that in mid March 2015 a rapid
augment of satellite observed earth radiation in atmosphere and the anomaly
located in close vicinity to the future M7.8 epicenter reached the maximum on
April 21-22. Our continuous satellite analysis revealed prospectively the new
strong anomaly on May 3th, which was the reason to contemplate another large
event in the area. On May 12, 2015 a large aftershock of M7.3 occurred. The
analysis of air temperature from weather ground station near Katmandu shows
analogous patterns with offset 1-2 days earlier to the satellite anomalies. The
GPS/TEC data analysis indicates an augment and variation in electron density
reaching a maximum value during April 22-24 period. A strong negative TEC
anomaly in the crest of EIA (Equatorial Ionospheric Anomaly) has occurred on
April 21st and strong positive on April 24th, 2015. Our preliminary results
show correlation between the pre-earthquake atmospheric and ionospheric
anomalies and the occurrence of 2015 M7.8 and M7.3 events in Nepal."
physics,Climate Engineering Responses to Climate Emergencies,"Despite efforts to stabilize CO_2 concentrations, it is possible that the
climate system could respond abruptly with catastrophic consequences.
Intentional intervention in the climate system to avoid or ameliorate such
consequences has been proposed as one possible response, should such a scenario
arise. In a one-week study, the authors of this report conducted a technical
review and evaluation of proposed climate engineering concepts that might serve
as a rapid palliative response to such climate emergency scenarios.
  Because of their potential to induce a prompt (less than one year) global
cooling, this study concentrated on Shortwave Climate Engineering (SWCE)
methods for moderately reducing the amount of shortwave solar radiation
reaching the Earth. The study's main objective was to outline a decade-long
agenda of technical research that would maximally reduce the uncertainty
surrounding the benefits and risks associated with SWCE. For rigor of technical
analysis, the study focused the research agenda on one particular SWCE
concept--stratospheric aerosol injection--and in doing so developed several
conceptual frameworks and methods valuable for assessing any SWCE proposal."
physics,"Coherent radiation reaction effects in laser-vacuum acceleration of
  electron bunches","The effects of coherently enhanced radiation reaction on the motion of
subwavelength electron bunches in interaction with intense laser pulses are
analyzed. The radiation reaction force behaves as a radiation pressure in the
laser beam direction, combined with a viscous force in the perpendicular
direction. Due to Coulomb expansion of the electron bunch, coherent radiation
reaction effects only occur in the initial stage of the laser-bunch interaction
while the bunch is still smaller than the wavelength. It is shown that this
initial stage can have observable effects on the trajectory of the bunch. By
scaling the system to larger bunch charges, these effects may be increased to
such an extent that they can suppress the radial instability normally found in
ponderomotive acceleration schemes, thereby enabling the full potential of
laser-vacuum electron bunch acceleration to GeV energies."
physics,"Identifying ground scatter and ionospheric scatter signals by using
  their fine structure at Ekaterinburg decameter coherent radar","The analysis of the scattered signal was carried out in the cases of ground
scatter and ionospheric scatter. The analysis is based on the data of the
decameter coherent EKB ISTP SB RAS radar. In the paper the signals scattered in
each sounding run were analyzed before their statistical averaging. Based on
the analysis, a model is constructed for ionospheric scatter and ground scatter
signal, based on previously studied mechanisms. Within the framework of the
Bayesian approach and based on large number of the data, the technique for
identifying the two types of signals is constructed based on their different
nature. The technique works without using traditional SuperDARN methods for
estimating scattered signal parameters - spectral width, Doppler drift velocity
or ray-tracing. The statistical analysis of the results was carried out. The
total error produced by our IQ algorithm over the selected data was $13.3\%$,
that is about two times less than total error produced by traditional
algorithms."
physics,"Teaching Theoretical Physics: the cases of Enrico Fermi and Ettore
  Majorana","We report on theoretical courses by Fermi and Majorana, giving evidence of
the first appearance and further development of Quantum Mechanics teaching in
Italy. On the basis of original documents, we make a comparison between Fermi's
and Majorana's approaches. A detailed analysis is carried out of Fermi's course
on Theoretical Physics attended by Majorana in 1927-28. Three (previously
unknown) programs on advanced Physics courses submitted by Majorana to the
University of Rome between 1933 and 1936 and the course he held in Naples in
1938 complete our analysis: Fermi's phenomenological approach resounded in
Majorana, who however combined it with a deeper theoretical approach, closer to
the modern way of presenting Quantum Mechanics."
physics,Super-resolution imaging within reach,"Although several optical techniques have been recently developed in order to
overcome the resolution limit in microscopy, the imaging of sub-wavelength
features is still a real challenge. In practise, super-resolution techniques
remain difficult to build or are photo-toxic for the biological samples.
However, microsphere-assisted microscopy has recently made super-resolution
imaging accessible to scientists (e.g. optical metrologists, engineers and
biologists). This paper presents an easy-to-implement optical setup to perform
full-field and contactless super-resolution measurements of nanostructured
media or biological elements. For this purpose, a classical microscope was
enhanced by introducing a transparent microsphere. We show that this rather
simple approach makes it possible to achieve a lateral resolution of 200 nm in
air, i.e. the visualization of feature sizes of 100 nm."
physics,Complexity: An Introduction,"This article summarises a Web-book on ""Complexity"" that was developed to
introduce undergraduate students to interesting complex systems in the
biological, physical and social sciences, and the common tools, principles and
concepts used for their study."
physics,"A novel flexible and modular energy storage system for near future
  Energy Banks","We considered a novel energy storage system based on the compression of air
through pumped water. Differently from CAES on trial, the proposed indirect
compression leaves the opportunity to choose the kind of compression from
adiabatic to isothermal. The energy storage process could be both fast or slow
leading to different configuration and applications. These novel storage system
are modular and could be applied in different scales for different locations
and applications, being very flexible in charge and discharge process. The
system may offer an ideal energy buffer for wind and solar storage with no (or
negligible) environment hazard. The main features of this novel energy storage
system will be showed together with overall energy and power data."
physics,"$Ab\ initio$ molecular dynamics of temporary anions using complex
  absorbing potentials","Dissociative electron attachment, that is, the cleavage of chemical bonds
induced by low-energy electrons, is difficult to model with standard
quantum-chemical methods because the involved anions are not bound but subject
to autodetachment. We present here a new computational development for
simulating the dynamics of temporary anions on complex-valued potential energy
surfaces. The imaginary part of these surfaces describes electron loss, whereas
the gradient of the real part represents the force on the nuclei. In our
method, the forces are computed analytically based on Hartree-Fock theory with
a complex absorbing potential.
  $Ab\ initio$ molecular dynamics simulations for the temporary anions of
dinitrogen, ethylene, chloroethane, and the five mono- to tetrachlorinated
ethylenes show qualitative agreement with experiments and offer mechanistic
insights into dissociative electron attachments. The results also demonstrate
how our method evenhandedly deals with molecules that may undergo dissociation
upon electron attachment and those which only undergo autodetachment."
physics,"Improving the spatial resolution by effective subtraction technique at
  Irkutsk incoherent scatter radar: the theory and experiment","We describe a sounding technique that allows us to improve spatial resolution
of Irkutsk Incoherent Scatter Radar without loosing spectral resolution. The
technique is based on transmitting of rectangle pulses of different duration in
various sounding runs and subtracting correlation matrixes. Theoretically and
experimentally we have shown, that subtraction of the mean-square parameters of
the scattered signal for different kinds of the sounding signal one from
another allows us to solve the problem within the framework of quasi-static
ionospheric parameters approximation."
physics,An explanation of trans-ionospheric pulse pairs,"Trans-ionospheric pulse pairs are the most powerful natural radio signals on
the Earth and associated with lightning. They have been discovered for two
decades by satellites, but their origin still remains elusive. Here we
attribute these radio signals to relativistic electrons produced by
cloud-to-ground lightning. When these electrons strike the ground, radio bursts
are emitted towards space in a narrow cone. This model naturally explains the
interval, duration, polarization, coherence and bimodal feature of the pulse
pairs. Based on electron parameters inferred from x-ray observation of
lightning, the calculated signal intensity agrees with the measurement of
satellites. Our results are useful to develop global warning system of storms
and hurricane based on GPS satellites."
physics,"Molecular Force Fields with Gradient-Domain Machine Learning (GDML):
  Comparison and Synergies with Classical Force Fields","Modern machine learning force fields (ML-FF) are able to yield energy and
force predictions at the accuracy of high-level $ab~initio$ methods, but at a
much lower computational cost. On the other hand, classical molecular mechanics
force fields (MM-FF) employ fixed functional forms and tend to be less
accurate, but considerably faster and transferable between molecules of the
same class. In this work, we investigate how both approaches can complement
each other. We contrast the ability of ML-FF for reconstructing dynamic and
thermodynamic observables to MM-FFs in order to gain a qualitative
understanding of the differences between the two approaches. This analysis
enables us to modify the generalized AMBER force field (GAFF) by
reparametrizing short-range and bonded interactions with more expressive terms
to make them more accurate, without sacrificing the key properties that make
MM-FFs so successful."
physics,Louis de Broglie und die Quantenmechanik,"In 1923 Louis de Broglie (1892-1987) discovered the material waves and six
years later received the Nobel price for this discovery. Apart these well known
facts this French physicist nevertheless seems to be forgotten. Details of his
life are as unknown as his efforts to describe quantum mechanics in a
deterministic and objective way. Especially the actual discussion concerning
the interpretation of quantum mechanics seems to justify a deeper occupation
with the scientific work of Louis de Broglie. In this context the important
influence of Albert Einstein is of special interest; for his photons announce
the existence of material waves and it may surprise that Einstein himself did
not postulate them. The basis of this short scientific biography are the
publications of de Broglie (a complete bibliography is given at the end), some
more or less short memories of his students and some unpublished documents
found in the ""Archives de l'Academie des Sciences"" at Paris. The original text
of the correspondence between de Broglie and Einstein is enclosed in German
translation in the appendix."
physics,"Moons Are Planets: Scientific Usefulness Versus Cultural Teleology in
  the Taxonomy of Planetary Science","We argue that taxonomical concept development is vital for planetary science
as in all branches of science, but its importance has been obscured by unique
historical developments. The literature shows that the concept of planet
developed by scientists during the Copernican Revolution was theory-laden and
pragmatic for science. It included both primaries and satellites as planets due
to their common intrinsic, geological characteristics. About two centuries
later the non-scientific public had just adopted heliocentrism and was
motivated to preserve elements of geocentrism including teleology and the
assumptions of astrology. This motivated development of a folk concept of
planet that contradicted the scientific view. The folk taxonomy was based on
what an object orbits, making satellites out to be non-planets and ignoring
most asteroids. Astronomers continued to keep primaries and moons classed
together as planets and continued teaching that taxonomy until the 1920s. The
astronomical community lost interest in planets ca. 1910 to 1955 and during
that period complacently accepted the folk concept. Enough time has now elapsed
so that modern astronomers forgot this history and rewrote it to claim that the
folk taxonomy is the one that was created by the Copernican scientists.
Starting ca. 1960 when spacecraft missions were developed to send back detailed
new data, there was an explosion of publishing about planets including the
satellites, leading to revival of the Copernican planet concept. We present
evidence that taxonomical alignment with geological complexity is the most
useful scientific taxonomy for planets. It is this complexity of both primary
and secondary planets that is a key part of the chain of origins for life in
the cosmos."
physics,"On the concept of exergy and available enthalpy: Application to
  atmospheric energetics","The available enthalpy is an early form of the modern thermodynamic concept
of exergy, which is the generic name for the amount of work obtainable when
some matter is brought to a state of equilibrium with its surroundings by means
of reversible processes.
  It is shown in this paper that a study of the hydrodynamic properties of
available enthalpy leads to a generalization of the global meteorological
available energies previously introduced by Lorenz, Dutton and Pearce. A local
energy cycle is derived without approximation. Moreover, static instabilities
or topography do not prevent this theory from having practical applications.
The concept of available enthalpy is also presented in terms of the potential
change in total entropy. Using the hydrostatic assumption, limited-area
energetics is then rigorously defined, including new boundary fluxes and new
energy components. This innovative approach is especially suitable for the
study of energy conversions between isobaric layers of an open limited
atmospheric domain.
  Numerical evaluations of various energy components are presented for a
hemispheric field of zonal-average temperature. It is further shown that this
new energetic scheme realizes a hierarchical partition of the components so
that the smallest of those available enthalpy reservoirs are almost of the same
magnitude as the kinetic energy. This is actually the fundamental property that
induced Margules to define the primary concept of available kinetic energy in
meteorology."
physics,Modelling Complexity: the case of Climate Science,"We briefly review some of the scientific challenges and epistemological
issues related to climate science. We discuss the formulation and testing of
theories and numerical models, which, given the presence of unavoidable
uncertainties in observational data, the non-repeatability of
world-experiments, and the fact that relevant processes occur in a large
variety of spatial and temporal scales, require a rather different approach
than in other scientific contexts. A brief discussion of the intrinsic
limitations of geo-engineering solutions to global warming is presented, and a
framework of investigation based upon non-equilibrium thermodynamics is
proposed. We also critically discuss recently proposed perspectives of
development of climate science based purely upon massive use of supercomputer
and centralized planning of scientific priorities."
physics,On the airborne aspect of COVID-19 coronovirus,"It is a widely accepted view that COVID 19 is either transmitted via surface
contamination or via close contact of an un-infected person with an infected
person. Surface contamination usually happens when infected water droplets from
exhalation/sneeze/cough of COVID sick person settle on nearby surfaces. To curb
this, social distancing and good hand hygiene advise is advocated by World
health Organization (WHO). We argue that COVID 19 coronovirus can also be
airborne in a puff cloud loaded with infected droplets generated by COVID sick
person. An elementary calculation shows that a $5~\mu m$ respiratory infected
droplet can remain suspended for about 9.0 minutes and a $2~\mu m$ droplet can
remain suspended for about an hour! And social distancing advise of 3 feet by
WHO and 6 feet by CDC (Centers for Disease Control and Prevention) may not be
sufficient in some circumstances as discussed in the text."
physics,"On the Correct Use of Statistical Tests: Reply to ""Lies, damned lies and
  statistics (in Geology)""","In a Forum published in EOS Transactions AGU (2009) entitled ""Lies, damned
lies and statistics (in Geology)"", Vermeesch (2009) claims that ""statistical
significant is not the same as geological significant"", in other words,
statistical tests may be misleading. In complete contradiction, we affirm that
statistical tests are always informative. We detail the several mistakes of
Vermeesch in his initial paper and in his comments to our reply. The present
text is developed in the hope that it can serve as an illuminating pedagogical
exercise for students and lecturers to learn more about the subtleties,
richness and power of the science of statistics."
physics,"On the contribution of the horizontal sea-bed displacements into the
  tsunami generation process","The main reason for the generation of tsunamis is the deformation of the
bottom of the ocean caused by an underwater earthquake. Usually, only the
vertical bottom motion is taken into account while the horizontal co-seismic
displacements are neglected in the absence of landslides. In the present study
we propose a methodology based on the well-known Okada solution to reconstruct
in more details all components of the bottom coseismic displacements. Then, the
sea-bed motion is coupled with a three-dimensional weakly nonlinear water wave
solver which allows us to simulate a tsunami wave generation. We pay special
attention to the evolution of kinetic and potential energies of the resulting
wave while the contribution of the horizontal displacements into wave energy
balance is also quantified. Such contribution of horizontal displacements to
the tsunami generation has not been discussed before, and it is different from
the existing approaches. The methods proposed in this study are illustrated on
the July 17, 2006 Java tsunami and some more recent events."
physics,"Long wave interaction with a partially immersed body. Part I:
  Mathematical models","In the present article we consider the problem of wave interaction with a
partially immersed, but floating body. We assume that the motion of the body is
prescribed. The general mathematical formulation for this problem is presented
in the framework of a hierarchy of mathematical models. Namely, in this first
part we formulate the problem at every hierarchical level. The special
attention is payed to fully nonlinear and weakly dispersive models since they
are most likely to be used in practice. For this model we have to consider
separately the inner (under the body) and outer domains. Various approached to
the gluing of solutions at the boundary is discussed as well. We propose
several strategies which ensure the global conservation or continuity of some
important physical quantities."
physics,"Identification of high energy ions using backscattered particles in
  laser-driven ion acceleration with cluster-gas targets","A new diagnosis method for high energy ions utilizing a single CR-39 detector
mounted on plastic plates is demonstrated to identify the presence of the high
energy component beyond the CR-39's detection threshold limit. On irradiation
of the CR-39 detector unit with a 25 MeV per nucleon He ion beam from
conventional rf-accelerators, a large number of etch pits having elliptical
opening shapes are observed on the rear surface of the CR-39. Detailed
investigations reveal that these etch pits are created by heavy ions
inelastically backscattered from the plastic plates. This ion detection method
is applied to laser-driven ion acceleration experiments using cluster-gas
targets, and ion signals with energies up to 50 MeV per nucleon are identified."
physics,"Ash plume properties retrieved from infrared images: a forward and
  inverse modeling approach","We present a coupled fluid-dynamic and electromagnetic model for volcanic ash
plumes. In a forward approach, the model is able to simulate the plume dynamics
from prescribed input flow conditions and generate the corresponding synthetic
thermal infrared (TIR) image, allowing a comparison with field-based
observations. An inversion procedure is then developed to retrieve ash plume
properties from TIR images.
  The adopted fluid-dynamic model is based on a one-dimensional, stationary
description of a self-similar (top-hat) turbulent plume, for which an
asymptotic analytical solution is obtained. The electromagnetic
emission/absorption model is based on the Schwarzschild's equation and on Mie's
theory for disperse particles, assuming that particles are coarser than the
radiation wavelength and neglecting scattering. [...]
  Application of the inversion procedure to an ash plume at Santiaguito volcano
(Guatemala) has allowed us to retrieve the main plume input parameters, namely
the initial radius $b_0$, velocity $U_0$, temperature $T_0$, gas mass ratio
$n_0$, entrainment coefficient $k$ and their related uncertainty. Moreover,
coupling with the electromagnetic model, we have been able to obtain a reliable
estimate of the equivalent Sauter diameter $d_s$ of the total particle size
distribution.
  The presented method is general and, in principle, can be applied to the
spatial distribution of particle concentration and temperature obtained by any
fluid-dynamic model, either integral or multidimensional, stationary or
time-dependent, single or multiphase. The method discussed here is fast and
robust, thus indicating potential for applications to real-time estimation of
ash mass flux and particle size distribution, which is crucial for model-based
forecasts of the volcanic ash dispersal process."
physics,"Absolute L-shell ionization and X-ray production cross sections of Lead
  and Thorium by 16-45 keV electron impact","The absolute L subshell specific electron impact ionization cross sections
near the ionization threshold (16 < E < 45 keV) of Lead and Thorium are
obtained from the measured L X-ray production cross sections. Monte Carlo
simulation is done to account for the effect of the backscattered electrons and
the final experimental results are compared with calculations performed using
distorted wave Born approximation and the modified relativistic binary
encounter Bethe model.The sensitivity of the results on the atomic parameters
is explored. Observed agreements and discrepancies between the experimental
results and theoretical estimates, and their dependence on the specific atomic
parameters are reported."
physics,Ice friction at the nanoscale,"The origin of ice slipperiness has been a matter of great controversy for
more than a century, but an atomistic understanding of ice friction is still
lacking. Here, we perform computer simulations of an atomically smooth
substrate sliding on ice. Our results show that a very small extent of
interfacial premelting is sufficient to provide a lubricating quasi-liquid
layer with rheological properties similar to bulk undercooled water. Upon
shearing, one single water-like monolayer sandwiched between adsorption layers
is able to display a pattern consistent with lubricating Couette flow. For
hydrophobic walls, the flow exhibits large slip, while hydrophilic walls obey
stick boundary conditions with small negative slip. By compressing ice, the
lubricating layer grows continuously, and the rheological properties approach
bulk--like behavior. In either case, the energy dissipated by sliding under
skating conditions is sufficient to melt an ice bilayer in the scale of decades
of nanoseconds. Our results show the atomic scale frictional behavior is a
combination of spontaneous ice premelting, pressure melting and frictional
heating."
physics,"Quantum mechanical study of the attosecond nonlinear Fourier transform
  spectroscopy of carbon dioxide","Attosecond nonlinear Fourier transform (NFT) pump probe spectroscopy is an
experimental technique which allows investigation of the electronic excitation,
ionization, and unimolecular dissociation processes. The NFT spectroscopy
utilizes ultrafast multiphoton ionization in the extreme ultraviolet spectral
range and detects the dissociation products of the unstable ionized species. In
this paper, a quantum mechanical description of NFT spectra is suggested, which
is based on the second order perturbation theory in molecule-light interaction
and the high level ab initio calculations of CO2 and CO2+ in the Franck-Condon
zone. The calculations capture the characteristic features of the available
experimental NFT spectra of CO2. Approximate analytic expressions are derived
and used to assign the calculated spectra in terms of participating electronic
states and harmonic photon frequencies. The developed approach provides a
convenient framework within which the origin and the significance of near
harmonic and non-harmonic NFT spectral lines can be analyzed. The framework is
scalable and the spectra of di- and triatomic species as well as the
dependences on the control parameters can by predicted semi-quantitatively."
physics,Towards a new technique of incoherent scatter signal processing,"This paper offers a new technique of incoherent scattering signal processing.
The technique is based on the experimentally observed comb structure of the
spectral power of separate realizations. The technique implies determining the
positions and amplitudes of peaks in separate realizations, the formation - on
their basis - of the spectral power of an individual realization not distorted
by the smoothing function, and a subsequent summation of such spectra for the
realizations. The technique has been tested using data from the Irkutsk
incoherent scatter radar, both for the case of the incoherent scattering from
thermal irregularities of plasma and for the case of the aspect scattering from
instabilities elongated with the geomagnetic field."
physics,Uncovering MIT wind myths through micro-climatological CFD analysis,"Popular campus myths of unusually strong pedestrian level winds are
investigated with a Computational Fluid Dynamics (CFD) approach. The numerical
simulations confirm the existence of the reported phenomena and provide a
qualitative explanation of their physical mechanisms."
physics,"On two approaches to the building of local models for electron density
  based on Irkutsk digizond data","In the paper the step-by-step principles for making local model of electron
density are described. They are based on modulation principle - electron
density dependence on time is a product of a number of temporal variations
caused by solar radiation, magnetic activity, Earth orientation and unknown
additional periodical processes (not a sum, as they suppose sometimes when
making such models). A multiranges modulation principle is also suggested, that
allows automatically extend the set of parameters by using new ones, obtained
by filtration (or averaging) of basic set of parameters over the time. In the
paper we describe two approaches to the model creation - descriptional and
predictional ones.
  To test the approach three different models were created for daily electron
density logarithm using the described principles. We have used the data of
Irkutsk digisonde over the period 2003-2007 years for testing. It becomes clear
that a non-optimal choice of the number of model parameters could increase
prediction error, inspite the error over the set, used for analysis, will
decrease. It is shown that one year prediction has accuracy about 9-23%
depending on the height, and the highest error corresponds to the height about
200km. From the modelling we could also see that with increasing of the height
the number of parameters increases, and this could be caused by inaccuracy of
the model or by not taking additional physical mechanisms into consideration."
physics,Rotational properties of annulus dusty plasma in a strong magnetic field,"The collective dynamics of annulus dusty plasma formed between a co-centric
conducting (non-conducting) disk and ring configuration is studied in a
strongly magnetized radio-frequency (rf) discharge. A superconducting
electromagnet is used to introduce a homogeneous magnetic field to the dusty
plasma medium. In absence of the magnetic field, dust grains exhibit thermal
motion around their equilibrium position. The dust grains start to rotate in
anticlockwise direction with increasing magnetic field (B $>$ 0.02 T), and the
constant value of the angular frequency at various strengths of magnetic field
confirms the rigid body rotation. The angular frequency of dust grains linearly
increases up to a threshold magnetic field (B $>$ 0.6 T) and after that its
value remains nearly constant in a certain range of magnetic field. Further
increase in magnetic field (B $>$ 1 T) lowers the angular frequency. Low value
of angular frequency is expected by reducing the width of annulus dusty plasma
or the input rf power. The azimuthal ion drag force due to the magnetic field
is assumed to be the energy source which drives the rotational motion. The
resultant radial electric field in the presence of magnetic field determines
the direction of rotation. The variation of floating (plasma) potential across
the annular region at given magnetic field explains the rotational properties
of the annulus dusty plasma in the presence of magnetic field."
physics,"A LEGO Watt Balance: An apparatus to determine a mass based on the new
  SI","A global effort to redefine our International System of Units (SI) is
underway and the change to the new system is expected to occur in 2018. Within
the newly redefined SI, the present base units will still exist but be derived
from fixed numerical values of seven reference constants. More specifically,
the unit of mass, the kilogram, will be realized through a fixed value of the
Planck constant $h$. For instance, a watt balance can be used to realize the
kilogram unit of mass within a few parts in $10^8$. Such a balance has been
designed and constructed at the National Institute of Standards and Technology.
For educational outreach and to demonstrate the principle, we have constructed
a LEGO tabletop watt balance capable of measuring a gram size mass to 1 %
relative uncertainty. This article presents the design, construction, and
performance of the LEGO watt balance and its ability to determine $h$"
physics,"Reducing the Leak Rate from a Damaged Oil Well by Filling It with Dense
  Streamlined Objects","The enormous pressure lifting the column of oil in a leaking oil well can
thwart efforts to seal the top of the well and prevent oil from rising. When
the oil cannot be stopped completely, we propose to slow its flow by filling
the well with a porous medium. That medium consists of countless small, dense,
streamlined objects that are dropped into the well and descend through the
rising oil at terminal velocity. The resulting heap of objects couples to the
oil via viscous and drag forces, dissipating the oil's energy and upward
momentum and significantly reducing its rate of flow."
physics,The Cryogenic Storage Ring CSR,"An electrostatic cryogenic storage ring, CSR, for beams of anions and cations
with up to 300 keV kinetic energy per unit charge has been designed,
constructed and put into operation. With a circumference of 35 m, the ion-beam
vacuum chambers and all beam optics are in a cryostat and cooled by a
closed-cycle liquid helium system. At temperatures as low as (5.5 $\pm$ 1) K
inside the ring, storage time constants of several minutes up to almost an hour
were observed for atomic and molecular, anion and cation beams at an energy of
60 keV. The ion-beam intensity, energy-dependent closed-orbit shifts
(dispersion) and the focusing properties of the machine were studied by a
system of capacitive pickups. The Schottky-noise spectrum of the stored ions
revealed a broadening of the momentum distribution on a time scale of 1000 s.
Photodetachment of stored anions was used in the beam lifetime measurements.
The detachment rate by anion collisions with residual-gas molecules was found
to be extremely low. A residual-gas density below 140 cm$^{-3}$ is derived,
equivalent to a room-temperature pressure below 10$^{-14}$ mbar. Fast atomic,
molecular and cluster ion beams stored for long periods of time in a cryogenic
environment will allow experiments on collision- and radiation-induced
fragmentation processes of ions in known internal quantum states with merged
and crossed photon and particle beams."
physics,"A megathrust earthquake genesis process observed by a Global Positioning
  System","Japan's GPS observed the fifteen-month megathrust earthquake genesis process
of the 2011 Tohoku M9, suggesting the real-time predictability of such events."
physics,Nanophotonic materials for space applications,"Space exemplifies the ultimate test-bed environment for any materials
technology. The harsh conditions of space, with extreme temperature changes,
lack of gravity and atmosphere, intense solar and cosmic radiation, and
mechanical stresses of launch and deployment, represent a multifaceted set of
challenges. The materials we engineer must not only meet these challenges, but
they need to do so while keeping overall mass to a minimum and guaranteeing
performance over long periods of time with no opportunity for repair.
Nanophotonic materials -- materials that embody structural variations on a
scale comparable to the wavelength of light -- offer opportunities for
addressing some of these difficulties. Here, we examine how advances in
nanophotonics and nanofabrication are enabling ultrathin and lightweight
structures with unparalleled ability to shape light-matter interactions over a
broad electromagnetic spectrum. From solar panels that can be fabricated in
space to applications of light for propulsion, the next generation of
lightweight and multifunctional photonic materials stands to both impact
existing technologies and pave the way for new space technologies."
physics,Generalized fluid theory including non-Maxwellian kinetic effects,"The results obtained by the plasma physics community for the validation and
the prediction of turbulence and transport in magnetized plasma come mainly
from the use of very CPU-consuming particle-in-cell or (gyro)kinetic codes
which naturally include non-Maxwellian kinetic effects. To date, fluid codes
are not considered to be relevant for the description of these kinetic effects.
Here, after revisiting the limitations of the current fluid theory developed in
the 19th century, we generalize the fluid theory including kinetic effects such
as non-Maxwellian super-thermal tails with as few fluid equations as possible.
The collisionless and collisional fluid closures from the nonlinear Landau
Fokker-Planck collision operator are shown for an arbitrary collisionality.
Indeed, the first fluid models associated with two examples of collisionless
fluid closures are obtained by assuming an analytic non-Maxwellian distribution
function (e.g., the INMDF [O. Izacard, Phys. Plasmas 23, 082504 (2016)]). One
of the main differences with the literature is our analytic representation of
the distribution function in the velocity phase space with as few hidden
variables as possible thanks to the use of non-orthogonal basis sets. These new
non-Maxwellian fluid equations could initiate the next generation of fluid
codes including kinetic effects and can be expanded to other scientific
disciplines such as astrophysics, condensed matter, or hydrodynamics. As a
validation test, we perform a numerical simulation based on a minimal reduced
INMDF fluid model. The result of this test is the discovery of the origin of
particle and heat diffusion. The diffusion is due to the competition between a
growing INMDF on short time scales due to spatial gradients and the
thermalization on longer time scales. The results shown here could draw the
breaking of some unsolved understandings of the turbulence."
physics,Early Theories on the Distance to the Sun,"According to an ancient Indian text (c. 1700 BC?), the heavens are 1000 earth
diameters away from the earth. Other texts took the sun to be halfway to the
heavens, so this suggests a distance of the sun about 500 earth diameters from
the earth. The confirmation for this supposition comes from the later theories
(c. 500 AD) from the same region and from Greek ideas that speak of roughly the
same distance. We suggest that this original conception was transformed by the
later Indian and Greek theories in different ways to deal with contradictory
data related to outer planet periods."
physics,A Formula for the Rotation Periods of the Planets & Asteroids,"The note presents a formula for the prediction of the rotation periods of the
planets and asteroids. This formula, which is like the Titius-Bode law, gives a
good agreement with the rotation periods of most planets, shows that Venus is
retrograde, and that there must be five objects between Mars and Jupiter. This
formula may be of some relevance in understanding the dynamics of the early
solar system."
physics,"Enrico Fermi e Ettore Majorana: continuita' e rinnovamento
  nell'insegnamento della Fisica teorica","In 1927, just after he obtained a full professorship, Enrico Fermi delivered
his first course on Theoretical Physics at the Institute of Physics in Rome.
The following year Edoardo Amaldi, Emilio Segre' and Ettore Majorana became
students of that course. The lectures given in 1927-28, whose content may be
easily reconstructed, probably had a deep impact in forming such young
students, who participated actively in the Physics researches carried on in
Rome soon after. In this perspective, the case of Ettore Majorana is certainly
the most important one: as a lecturer, in 1933-36 he planned to give three
advanced Physics courses in Rome, before obtaining his full professorship in
Theoretical Physics ""for high and well-deserved repute"" in 1937. From the
analysis of the lectures he delivered in Naples in 1938, we can conclude that,
in part, Majorana referred to the Fermi lectures he followed as a student, but
he also introduced some advanced (for that time) topics, rendering his course a
very modern one. Much of these frontier topics were already cited in the
programmes of the mentioned three courses he presented few years earlier."
physics,"Simple circuit theory and the solution of two electricity problems from
  the Victorian Age","Two problems from the Victorian Age, the subdivision of light and the
determination of the leakage point in an undersea telegraphic cable are
discussed and suggested as a concrete illustrations of the relationships
between textbook physics and the real world. Ohm's law and simple algebra are
the only tools we need to discuss them in the classroom."
physics,"The ""Relativistic"" Mug","This note is an attempt to explain in simple words why the famous relation
$E=mc^2$ misrepresents the essence of Einstein's relativity theory. The note is
addressed to high-school teachers, and a part of it - to those university
professors who permit themselves to say that the mass of a body increases with
its velocity or momentum and thus mislead the teachers and their students.
  -----
  Contains both English and Russian versions."
physics,"Spreading scientific philosophies with instruments: the case of Atwood's
  machine","We study how the paradigm of Newton's science, based on the organization of
scientific knowledge as a series of mathematical laws, was definitively
accepted in science courses - in the last decades of the XVIII century, in
England as well as in the Continent - by means of the ""universal"" dynamical
machine invented by George Atwood in late 1770s just for this purpose. The
spreading of such machine, occurred well before the appearance of Atwood's
treatise where he described the novel machine and the experiments to be
performed with it, is a quite interesting historical case, which we consider in
some detail. In particular, we focus on the ""improvement"" introduced by the
Italian Giuseppe Saverio Poli and the subsequent ""simplifications"" of the
machine, underlying the ongoing change of perspective after the definitive
success of Newtonianism. The case studied here allows to recognize the relevant
role played by a properly devised instrument in the acceptance of a new
paradigm by non-erudite scholars, in addition to the traditional ways involving
erudite scientists, and thus the complementary role of machine philosophy with
respect to mathematical, philosophical or even physical reasoning."
physics,"The golden age of Calcutta physics: Difficulties in reconstructing the
  history","Classes started in the newly established Physics Department of Calcutta
University Science College in 1916. Raman, Bose and Saha were three young
members of the small physics faculty consisting of barely half a dozen faculty
members. Within about one decade, three extraordinary discoveries came from
these young men---Saha ionization equation in 1920, Bose statistics in 1924,
Raman effect in 1928. However, fortunes of Calcutta University quickly got
intertwined with India's freedom struggle led by Mahatma Gandhi exactly at the
same time and the physics group got tragically disrupted. Indian physics never
succeeded in reaching that height again. This paper discusses the difficulties
in reconstructing a critical history of this Calcutta school of physics during
the very short epoch of unmatched brilliance."
physics,"Understanding quantum physics through simple experiments: from
  wave-particle duality to Bell's theorem","Quantum physics, which describes the strange behavior of light and matter at
the smallest scales, is one of the most successful descriptions of reality, yet
it is notoriously inaccessible. Here we provide an approachable explanation of
quantum physics using simple thought experiments. We derive all relevant
quantum predictions using minimal mathematics, without introducing the advanced
calculations that are typically used to describe quantum physics. We focus on
the two key surprises of quantum physics, namely wave-particle duality, a term
that was introduced to capture the fact that single quantum particles in some
respects behave like waves and in other respects like particles, and
entanglement, which applies to two or more quantum particles and brings out the
inherent contradiction between quantum physics and seemingly obvious
assumptions regarding the nature of reality. Following arguments originally
made by John Bell and Lucien Hardy, we show that the so-called local hidden
variables are inadequate at explaining the behavior of entangled quantum
particles. This means that one either has to give up on hidden variables, i.e.,
the idea that the outcomes of measurements on quantum particles are determined
before an experiment is actually carried out, or one has to relinquish the
principle of locality, which requires that no causal influences should be
faster than the speed of light and is a cornerstone of Einstein's theory of
relativity. Finally, we describe how these remarkable predictions of quantum
physics have been confirmed in experiments. We have successfully used the
present approach in a course that is open to all undergraduate students at the
University of Calgary, without any prerequisites in mathematics or physics."
physics,On times and shadows: the observational analemma,"The observation that the shadows of objects change during the course of the
day and also for a fixed time during a year led curious minds to realize that
the Sun could be used as a timekeeper. However, the daily motion of the Sun has
some subtleties, for example, with regards to the precise time at which it
crosses the meridian near noon. When the Sun is on the meridian, a clock is
used to ascertain this time and a vertical stick determines the angle the Sun
is above the horizon. These two measurements lead to the construction of a
diagram (called an analemma) as an extremely useful resource for the teaching
of astronomy. In this paper we report on the construction of this diagram from
roughly weekly observations during more than a year."
physics,"The colours of Newton's Opticks: an advanced project for excellent
  students","We describe in detail an advanced project devised for outstanding High School
(or undergraduate) students with appropriate abilities in physical reasoning
(rather than with a good standard preparation), centered around the well-known
historical case of Newton's theory of light and colours. The different action
lines along which the project is developed are aimed to let the students
involved to: 1) think as Newton did, by building step by step all his knowledge
and reasoning; 2) work as Newton did, by performing the whole series of his
original experiments with prisms; 3) deduce as Newton did about the nature of
light and colours; 4) present the results of their activity (including physics
demonstrations) to the general public, in order to test abilities in
communicating what learned and discovered (including video realization
published on YouTube youtube). Such didactic aim is complemented by the purpose
to realize a historically informed activity, given the potential key role of
the History of Physics in promoting science at a deeper level, especially when
no particular training in mathematics or advanced education is required. The
highly favourable reception of the project by the students involved, as well as
that deserved by the uneducated people to the activities demonstrated by the
students in public events, testify for the success of such work."
physics,From Solar Eclipse of 1919 to the Spectacle of Gravitational Lensing,"A century after observing the deflection of light emitted by distant stars
during the solar eclipse of 1919, it is interesting to know the concepts
emerged from the experiment and the theoretical and observational consequences
for modern cosmology and astrophysics. In addition to confirming Einstein's
gravitational theory, its greatest legacy was the construction of a new
research area to cosmos science dubbed gravitational lensing. The formation and
magnification of multiple images (mirages) by the gravitational field of a
compact or extended lens are among the most striking phenomena of nature. This
article presents a pedagogical view of the first genuine gravitational lens
effect, the double quasar QSO 0957 + 561. We also describe the formation of
rings, giant arcs, arclets and multiple Supernova images. It is also surprising
that the Hubble constant and the amount of dark matter in the Universe can be
measured by the same technique. Finally, the lensing of gravitational waves, a
possible but still not yet detected effect, is also briefly discussed."
physics,Alice and the Foucault Pendulum: the land of action-angle variables,"Since the pioneering works of Newton $(1643-1727)$, Mechanics has been
constantly reinventing itself: reformulated in particular by Lagrange
$(1736-1813)$ then Hamilton $(1805-1865)$, it now offers powerful conceptual
and mathematical tools for the exploration of the most complex dynamical
systems, essentially via the action-angle variables formulation and more
generally through the theory of canonical transformations. We give the reader
an overview of these different formulations through the well-known example of
Foucault's pendulum, a device created by Foucault $(1819-1868)$ and first
installed in the Panth\'eon (Paris, France) in 1851 to display the Earth's
rotation. The apparent simplicity of the Foucault pendulum is indeed an open
door to the most contemporary ramifications of Classical Mechanics. We stress
that the action-angle variable formalism is not necessary to understand
Foucault's pendulum. The latter is simply taken as well-known simple dynamical
system used to exemplify modern concepts that are crucial in order to
understand more complicated dynamical systems. The Foucault pendulum installed
in the collegiate church of Sainte-Waudru (Mons, Belgium) will allow us to
numerically estimate the different quantities introduced. A free adaptation of
excerpts from ""Alice's Adventures in Wonderland"" will offer the reader some
poetic breaths."
physics,"Is Magnification Consistent? Why people from amateur astronomers to
  science's worst enemy have some basic physics wrong, and why","This paper is a discussion of the physics of magnification in telescopes.
Special attention is given to the question of whether telescopes magnify stars.
Telescopes do magnify star images, although opinions to the contrary abound."
physics,Method to measure Earth missed by ancient Greeks?,"I describe a simple method to calculate Earth dimensions using only local
measurements and observations. I used modern technology (a digital photo camera
and Google Earth) but the exact same method can be used without any aid, with
naked eye observations and distances measured by walking, and so it was
perfectly accessible to Ancient Greek science."
physics,"The Red Day Star, The Women's Star and Venus: D(L/N)akota, Ojibwe and
  Other Indigenous Star Knowledge","In Ojibwe the Morning Star is called Ikew Anung, which means the Womens Star.
In Lakota the same planet Venus is called Anpetu Luta, the Red Day Star. Bother
cultures have rich and interesting understandings of Venus that relate to other
Indigenous cultures throughout the world. Venus is so often related to the
feminine because native peoples carefully watched the movement of the star and
saw it in the east at sunrise for nine months and then in the west at sunset
for the following nine months. Nine months is exactly the time for human
gestation. Yet, tragically, the native star knowledge is disappearing as elders
pass. The Native Skywatchers project focuses on understanding the Ojibwe and
Dakota importance of this and other celestial connections. Working closely with
a team of culture teachers and language experts we are building community
around the native star knowledge."
physics,Polaris: The Mathematics of Navigation and the Shape of the Earth,"For millenia, sailors have used the empirical rule that the elevation angle
of Polaris, the North Star, as measured by sextant, quadrant or astrolabe, is
approximately equal to latitude. Here, we show using elementary trigonometry
that Empirical Law 1 can be converted from a heuristic to a theorem. A second
ancient empirical law is that the distance in kilometers from the observer to
the North Pole, the geodesic distance measured along the spherical surface of
the planet, is the number of degrees of colatitude multiplied by 111.1
kilometers. Can Empirical Law 2 be similarly rendered rigorous? No; whereas as
the shape of the planet is controlled by trigonometry, the size of our world is
an accident of cosmological history. However, Empirical Law 2, can be
rigorously verified by measurements. The association of 111 km of north-south
distance to one degree of latitude trivially yields the circumference of the
globe as 40,000 km. We also extend these ideas and the parallel ray
approximation to three different ways of modeling a Flat Earth. We show that
photographs from orbit, taken by a very expensive satellite, are unnecessary to
render the Flat Earth untenable; simple mathematics proves Earth a sphere just
as well."
physics,"Statistics of the seasonal cycle of the 1951-2000 surface temperature
  records in Italy","We present an analysis of seasonal cycle of the last 50 years of records of
surface temperature in Italy. We consider two data sets which synthesize the
surface temperature fields of Northern and Southern Italy. Such data sets
consist of records of daily maximum and minimum temperature. We compute the
best estimate of the seasonal cycle of the variables considered by adopting the
cyclograms' technique. We observe that in general the minimum temperature cycle
lags behind the maximum temperature cycle, and that the cycles of the Southern
Italy temperatures records lag behind the corresponding cycles referring to
Northern Italy. All seasonal cycles lag considerably behind the solar cycle.
The amplitude and phase of the seasonal cycles do not show any statistically
significant trend in the time interval considered."
physics,Towards a definition of climate science,"The intrinsic difficulties in building realistic climate models and in
providing complete, reliable and meaningful observational datasets, and the
conceptual impossibility of testing theories against data imply that the usual
Galilean scientific validation criteria do not apply to climate science. The
different epistemology pertaining to climate science implies that its answers
cannot be singular and deterministic; they must be plural and stated in
probabilistic terms. Therefore, in order to extract meaningful estimates of
future climate change from a model, it is necessary to explore the model'
uncertainties. In terms of societal impacts of scientific knowledge, it is
necessary to accept that any political choice in a matter involving complex
systems is made under unavoidable conditions of uncertainty. Nevertheless,
detailed probabilistic results in science can provide a baseline for a sensible
process of decision making."
physics,Environmental Physics: Physical Principles and Applications,"Environmental science almost invariably proposes problems of extreme
complexity, typically characterized by strongly nonlinear evolution dynamics.
The systems under investigation have many degrees of freedom - which makes them
complicated - and feature nonlinear interactions of several different
components taking place on a vast range of time-space scales - which makes them
complex. Such systems evolve under the action of macroscopic driving (typically
the solar heating) and modulating (e.g. the Earth's rotation and gravitation)
agents. The most comprehensive example is the entire climatic system. The
description of the macroscopic dynamics of environmental systems is based on
the systematic use of dominant balances derived on a phenomenological basis in
order to specialize the dynamical equations. Such balances are suitable classes
of approximate solutions of the evolution equations which represent a
reasonably good approximation to the actual observed fields when sufficiently
large spatial or temporal averages are considered. Actually, different balances
have to be considered depending on the time and space scales we are focusing
our interest on. Such an approach reflects the fundamentally
heuristic-inductive nature of the scientific research in environmental
sciences, where the traditional reductionistic scientific attitude is not
always effective. In order to exemplify this procedure, we consider the very
relevant case of the motion of the fluids that permit the existence of life on
the Earth, air and water: the so-called geophysical fluids."
physics,"Does the Danube exist? Versions of reality given by various regional
  climate models and climatological datasets","We present an intercomparison and verification analysis of several regional
climate models (RCMs) nested into the same run of the same Atmospheric Global
Circulation Model (AGCM) regarding their representation of the statistical
properties of the hydrological balance of the Danube river basin for 1961-1990.
We also consider the datasets produced by the driving AGCM, from the ECMWF and
NCEP-NCAR reanalyses. The hydrological balance is computed by integrating the
precipitation and evaporation fields over the area of interest. Large
discrepancies exist among RCMs for the monthly climatology as well as for the
mean and variability of the annual balances, and only few datasets are
consistent with the observed discharge values of the Danube at its Delta, even
if the driving AGCM provides itself an excellent estimate. Since the considered
approach relies on the mass conservation principle and bypasses the details of
the air-land interface modeling, we propose that the atmospheric components of
RCMs still face difficulties in representing the water balance even on a
relatively large scale. Their reliability on smaller river basins may be even
more problematic. Moreover, since for some models the hydrological balance
estimates obtained with the runoff fields do not agree with those obtained via
precipitation and evaporation, some deficiencies of the land models are also
apparent. NCEP-NCAR and ERA-40 reanalyses result to be largely inadequate for
representing the hydrology of the Danube river basin, both for the
reconstruction of the long-term averages and of the seasonal cycle, and cannot
in any sense be used as verification. We suggest that these results should be
carefully considered in the perspective of auditing climate models and
assessing their ability to simulate future climate changes."
physics,Motion Control of a Spinning Disc on Rotating Earth,"This paper considers the motion control of a particle and a spinning disc on
rotating earth. The equations of motion are derived using Lagrangian mechanics.
Trajectory planning is studied as an optimization problem using the method
referred to as Discrete Mechanics and Optimal Control."
physics,"A new diagnostic tool for water, energy and entropy budgets in climate
  models","This work presents a novel diagnostic tool for studying the thermodynamics of
the climate systems with a wide range of applications, from sensitivity studies
to model tuning. It includes a number of modules for assessing the internal
energy budget, the hydrological cycle, the Lorenz Energy Cycle and the material
entropy production, respectively. The routine receives as inputs energy fluxes
at surface and at the Top-of-Atmosphere (TOA), for the computation of energy
budgets at Top-of-Atmosphere (TOA), at the surface, and in the atmosphere as a
residual. Meridional enthalpy transports are also computed from the divergence
of the zonal mean energy budget fluxes; location and intensity of peaks in the
two hemispheres are then provided as outputs. Rainfall, snowfall and latent
heat fluxes are received as inputs for computing the water mass and latent
energy budgets. If a land-sea mask is provided, the required quantities are
separately computed over continents and oceans. The diagnostic tool also
computes the Lorenz Energy Cycle (LEC) and its storage/conversion terms as
annual mean global and hemispheric values. In order to achieve this, one needs
to provide as input three-dimensional daily fields of horizontal wind velocity
and temperature in the troposphere. Two methods have been implemented for the
computation of the material entropy production, one relying on the convergence
of radiative heat fluxes in the atmosphere (indirect method), one combining the
irreversible processes occurring in the climate system, particularly heat
fluxes in the boundary layer, the hydrological cycle and the kinetic energy
dissipation as retrieved from the residuals of the LEC. A version of the
diagnostic tool is included in the Earth System Model eValuation Tool
(ESMValTool) community diagnostics, in order to assess the performances of soon
available CMIP6 model simulations."
physics,"Improving predictive power of physically based rainfall-induced shallow
  landslide models: a probabilistic approach","Distributed models to forecast the spatial and temporal occurrence of
rainfall-induced shallow landslides are based on deterministic laws. These
models extend spatially the static stability models adopted in geotechnical
engineering, and adopt an infinite-slope geometry to balance the resisting and
the driving forces acting on the sliding mass. An infiltration model is used to
determine how rainfall changes pore-water conditions, modulating the local
stability/instability conditions. A problem with the operation of the existing
models lays in the difficulty in obtaining accurate values for the several
variables that describe the material properties of the slopes. The problem is
particularly severe when the models are applied over large areas, for which
sufficient information on the geotechnical and hydrological conditions of the
slopes is not generally available. To help solve the problem, we propose a
probabilistic Monte Carlo approach to the distributed modeling of
rainfall-induced shallow landslides. For the purpose, we have modified the
Transient Rainfall Infiltration and Grid-Based Regional Slope-Stability
Analysis (TRIGRS) code. The new code (TRIGRS-P) adopts a probabilistic approach
to compute, on a cell-by-cell basis, transient pore-pressure changes and
related changes in the factor of safety due to rainfall infiltration.
Infiltration is modeled using analytical solutions of partial differential
equations describing one-dimensional vertical flow in isotropic, homogeneous
materials. Both saturated and unsaturated soil conditions can be considered.
TRIGRS-P copes with the natural variability inherent to the mechanical and
hydrological properties of the slope materials by allowing values of the TRIGRS
model input parameters to be sampled randomly from a given probability
distribution. [..]"
physics,"Rainfall Advection using Velocimetry by Multiresolution Viscous
  Alignment","An algorithm to estimate motion from satellite imagery is presented. Dense
displacement fields are computed from time-separated images of of significant
convective activity using a Bayesian formulation of the motion estimation
problem. Ordinarily this motion estimation problem is ill-posed; there are far
too many degrees of freedom than necessary to represent the motion. Therefore,
some form of regularization becomes necessary and by imposing smoothness and
non-divergence as desirable properties of the estimated displacement vector
field, excellent solutions are obtained. Our approach provides a marked
improvement over other methods in conventional use. In contrast to correlation
based approaches, the displacement fields produced by our method are dense,
spatial consistency of the displacement vector field is implicit, and
higher-order and small-scale deformations can be easily handled. In contrast
with optic-flow algorithms, we can produce solutions at large separations of
mesoscale features between large time-steps or where the deformation is rapidly
evolving."
physics,"Efficient calculation of self magnetic field, self-force, and
  self-inductance for electromagnetic coils. II. Rectangular cross-section","For designing high-field electromagnets, the Lorentz force on coils must be
computed to ensure a support structure is feasible, and the inductance should
be computed to evaluate the stored energy. Also, the magnetic field and its
variation inside the conductor is of interest for computing stress and strain,
and due to superconducting quench limits. For these force, inductance, energy,
and internal field calculations, the coils cannot be naively approximated as
infinitesimally thin filaments due to divergences when the source and
evaluation points coincide, so more computationally demanding calculations are
usually required, resolving the finite cross-section of the conductors. Here,
we present a new alternative method that enables the internal magnetic field
vector, self-force, and self-inductance to be computed rapidly and accurately
within a 1D filament model. The method is applicable to coils for which the
curve center-line can have general noncircular shape, as long as the conductor
width is small compared to the radius of curvature. This paper extends a
previous calculation for circular-cross-section conductors [Hurwitz et al,
arXiv:2310.09313 (2023)] to consider the case of rectangular cross-section. The
reduced model is derived by rigorous analysis of the singularity, regularizing
the filament integrals such that they match the true high-dimensional integrals
at high coil aspect ratio. The new filament model exactly recovers analytic
results for a circular coil, and is shown to accurately reproduce full
finite-cross-section calculations for a non-planar coil of a stellarator
magnetic fusion device. Due to the efficiency of the model here, it is well
suited for use inside design optimization."
physics,"Efficient calculation of the self magnetic field, self-force, and
  self-inductance for electromagnetic coils","The design of electromagnetic coils may require evaluation of several
quantities that are challenging to compute numerically. These quantities
include Lorentz forces, which may be a limiting factor due to stresses; the
internal magnetic field, which is relevant for determining stress as well as a
superconducting coil's proximity to its quench limit; and the inductance, which
determines stored magnetic energy and dynamics. When computing the effect on
one coil due to the current in another, these quantities can often be
approximated quickly by treating the coils as infinitesimally thin. When
computing the effect on a coil due to its own current (e.g., self-force or
self-inductance), evaluation is difficult due to the presence of a singularity;
coils cannot be treated as infinitesimally thin as each quantity diverges at
zero conductor width. Here, we present novel and well-behaved methods for
evaluating these quantities using non-singular integral formulae of reduced
dimensions. These formulae are determined rigorously by dividing the domain of
integration of the magnetic vector potential into two regions, exploiting
appropriate approximations in each region, and expanding in high aspect ratio.
Our formulae show good agreement to full finite-thickness calculations even at
low aspect ratio, both analytically for a torus and numerically for a
non-planar coil of a stellarator fusion device, the Helically Symmetric
eXperiment (HSX). Because the integrands of these formulae develop fine
structure as the minor radius becomes infinitely thin, we also develop a method
of evaluating the self-force and self-inductance with even greater efficiency
by integrating this sharp feature analytically. We demonstrate with this method
that the self-force can be accurately computed for the HSX coil with as few as
12 grid points."
physics,"Asymptotic nonlinear and dispersive pulsatile flow in elastic vessels
  with cylindrical symmetry","The asymptotic derivation of a new family of one-dimensional, weakly
nonlinear and weakly dispersive equations that model the flow of an ideal fluid
in an elastic vessel is presented. Dissipative effects due to the viscous
nature of the fluid are also taken into account. The new models validate by
asymptotic reasoning other non-dispersive systems of equations that are
commonly used, and improve other nonlinear and dispersive mathematical models
derived to describe the blood flow in elastic vessels. The new systems are
studied analytically in terms of their basic characteristic properties such as
the linear dispersion characteristics, symmetries, conservation laws and
solitary waves. Unidirectional model equations are also derived and analysed in
the case of vessels of constant radius. The capacity of the models to be used
in practical problems is being demonstrated by employing a particular system
with favourable properties to study the blood flow in a large artery. Two
different cases are considered: A vessel with constant radius and a tapered
vessel. Significant changes in the flow can be observed in the case of the
tapered vessel."
physics,"Discrepancies in Southern Hemisphere Mid-latitude Atmospheric
  Variability of the NCEP-NCAR and ECMWF Reanalyses","In this study we compare the representation of the southern hemisphere
midlatitude winter variability in the NCEP-NCAR and ERA40 reanalyses. We use
the classical Hayashi spectral technique, recently applied to compare the
description of the atmospheric variability in the northern hemisphere on
different spectral sub-domains. We test the agreement of the two reanalysis
systems in the representation of the atmospheric activity. In the southern
hemisphere, even in the satellite period, the assimilated data are relatively
scarce, predominately over the oceans, and they provide a weaker constraint to
the model dynamics. We find relevant discrepancies in the description of the
variability at different spatial and temporal scales. ERA40 is generally
characterised by a larger variance, especially in the high frequency spectral
region. In the pre-satellite period the discrepancies between the two
reanalyses are large and randomly distributed while after the 1979 the
discrepancies are systematic. Moreover, a sudden jump in the VTPR period
(1973-1978) is observed, mostly in the ERA40 reanalysis. Our results suggest
that today we do not have a well-defined picture of the properties of the
winter mid-latitude variability in the southern hemisphere to be used in the
evaluation of the realism of climate models and demand for an intercomparison
study for the assessment of the self-consistency of the IPCC models in the
representation of the analysed properties."
physics,"Extreme Value Statistics of the Total Energy in an Intermediate
  Complexity Model of the Mid-latitude Atmospheric Jet. Part II: trend
  detection and assessment","A baroclinic model for the atmospheric jet at middle-latitudes is used as
stochastic generator of non-stationary time series of the total energy of the
system. A linear time trend is imposed on the parameter $T_E$, descriptive of
the forced equator-to-pole temperature gradient and responsible for setting the
average baroclinicity in the model. The focus lies on establishing a
theoretically sound framework for the detection and assessment of trend at
extreme values of the generated time series. This problem is dealt with by
fitting time-dependent Generalized Extreme Value (GEV) models to sequences of
yearly maxima of the total energy. A family of GEV models is used in which the
location $\mu$ and scale parameters $\sigma$ depend quadratically and linearly
on time, respectively, while the shape parameter $\xi$ is kept constant. From
this family, a model is selected by using diagnostic graphical tools, such as
probability and quantile plots, and by means of the likelihood ratio test. The
inferred location and scale parameters are found to depend in a rather smooth
way on time and, therefore, on $T_E$. In particular, power-law dependences of
$\mu$ and $\sigma$ on $T_E$ are obtained, in analogy with the results of a
previous work where the same baroclinic model was run with fixed values of
$T_E$ spanning the same range as in this case. It is emphasized under which
conditions the adopted approach is valid."
physics,"Definition of the moist-air exergy norm: a comparison with existing
  ""moist energy norms""","This study presents a new formulation for the norms and scalar products used
in tangent linear or adjoint models to determine forecast errors and
sensitivity to observations and to calculate singular vectors. The new norm is
derived from the concept of moist-air available enthalpy, which is one of the
availability functions referred to as exergy in general thermodynamics. It is
shown that the sum of the kinetic energy and the moist-air available enthalpy
can be used to define a new moist-air squared norm which is quadratic in: 1)
wind components; 2) temperature; 3) surface pressure; and 4) water vapor
content. Preliminary numerical applications are performed to show that the new
weighting factors for temperature and water vapor are significantly different
from those used in observation impact studies, and are in better agreement with
observed analysis increments. These numerical applications confirm that the
weighting factors for water vapor and temperature exhibit a large increase with
height (by several orders of magnitude) and a minimum in the middle
troposphere, respectively."
physics,"Synchronization to big-data: nudging the Navier-Stokes equations for
  data assimilation of turbulent flows","Nudging is an important data assimilation technique where partial field
measurements are used to control the evolution of a dynamical system and/or to
reconstruct the entire phase-space configuration of the supplied flow. Here, we
apply it to the toughest problem in fluid dynamics: three dimensional
homogeneous and isotropic turbulence. By doing numerical experiments we perform
a systematic assessment of how well the technique reconstructs large- and
small-scales features of the flow with respect to the quantity and the
quality/type of data supplied to it. The types of data used are: (i) field
values on a fixed number of spatial locations (Eulerian nudging), (ii) Fourier
coefficients of the fields on a fixed range of wavenumbers (Fourier nudging),
or (iii) field values along a set of moving probes inside the flow (Lagrangian
nudging). We present state-of-the-art quantitative measurements of the
scale-by-scale {\it transition to synchronization} and a detailed discussion of
the probability distribution function of the reconstruction error, by comparing
the nudged field and the {\it truth} point-by-point. Furthermore, we show that
for more complex flow configurations, like the case of anisotropic rotating
turbulence, the presence of cyclonic and anticyclonic structures leads to
unexpectedly better performances of the algorithm. We discuss potential further
applications of nudging to a series of applied flow configurations, including
the problem of field-reconstruction in thermal Rayleigh-B\'enard convection and
in magnetohydrodynamics (MHD), and to the determination of optimal
parametrisation for small-scale turbulent modeling. Our study fixes the
standard requirements for future applications of nudging to complex turbulent
flows."
physics,"Meridional energy transport extremes and the general circulation of
  Northern Hemisphere mid-latitudes: dominant weather regimes and preferred
  zonal wavenumbers","The extratropical meridional energy transport in the atmosphere is
fundamentally intermittent in nature, having extremes large enough to affect
the net seasonal transport. Here, we investigate how these extreme transports
are associated with the dynamics of the atmosphere at multiple spatial scales,
from planetary to synoptic. We use the ERA5 reanalysis data to perform a
wavenumber decomposition of meridional energy transport in the Northern
Hemisphere mid-latitudes during winter and summer. We then relate extreme
transport events to atmospheric circulation anomalies and dominant weather
regimes, identified by clustering 500hPa geopotential height fields. In
general, planetary-scale waves determine the strength and meridional position
of the synoptic-scale baroclinic activity with their phase and amplitude, but
important differences emerge between seasons. During winter, large wavenumbers
($k=2-3$) are key drivers of the meridional energy transport extremes, and
planetary and synoptic-scale transport extremes virtually never co-occur. In
summer, extremes are associated with higher wavenumbers ($k=4-6$), identified
as synoptic-scale motions. We link these waves and the transport extremes to
recent results on exceptionally strong and persistent co-occurring summertime
heat waves across the Northern Hemisphere mid-latitudes. We show that the
weather regime structures associated with these heat wave events are typical
for extremely large poleward energy transport events."
physics,Large Scale Weather Control Using Nuclear Reactors,"It is pointed out that controlled release of thermal energy from fission type
nuclear reactors can be used to alter weather patterns over significantly large
geographical regions. (1) Nuclear heat creates a low pressure region, which can
be used to draw moist air from oceans, onto deserts. (2) Creation of low
pressure zones over oceans using Nuclear heat can lead to Controlled Cyclone
Creation (CCC).(3) Nuclear heat can also be used to melt glaciers and control
water flow in rivers."
physics,"Intercomparison of the northern hemisphere winter mid-latitude
  atmospheric variability of the IPCC models","We compare, for the overlapping time frame 1962-2000, the estimate of the
northern hemisphere (NH) mid-latitude winter atmospheric variability within the
XX century simulations of 17 global climate models (GCMs) included in the
IPCC-4AR with the NCEP and ECMWF reanalyses. We compute the Hayashi spectra of
the 500hPa geopotential height fields and introduce an integral measure of the
variability observed in the NH on different spectral sub-domains. Only two
high-resolution GCMs have a good agreement with reanalyses. Large biases, in
most cases larger than 20%, are found between the wave climatologies of most
GCMs and the reanalyses, with a relative span of around 50%. The travelling
baroclinic waves are usually overestimated, while the planetary waves are
usually underestimated, in agreement with previous studies performed on global
weather forecasting models. When comparing the results of various versions of
similar GCMs, it is clear that in some cases the vertical resolution of the
atmosphere and, somewhat unexpectedly, of the adopted ocean model seem to be
critical in determining the agreement with the reanalyses. The GCMs ensemble is
biased with respect to the reanalyses but is comparable to the best 5 GCMs.
This study suggests serious caveats with respect to the ability of most of the
presently available GCMs in representing the statistics of the global scale
atmospheric dynamics of the present climate and, a fortiori, in the perspective
of modelling climate change."
physics,Significance of a one-degree Celsius increase in global temperature,"The Intergovernmental Panel on Climate Change reports indicate that the
global mean temperature is about one-degree Celsius higher than pre-industrial
levels, that this increase is anthropogenic, and that there is a causal
relationship between this higher temperature and an increase in frequency and
magnitude of extreme weather events. This causal relationship seems at odds
with common sense, and may be difficult to explain to non-experts. Thus to
appreciate the significance of a one-degree increase in global mean
temperature, we perform back-of-the-envelope calculations relying on simple
physics. We estimate the excess thermal energy trapped in the climate system
(oceans, land, atmosphere) from a one-degree Celsius increase in global mean
temperature, and show that it is thousands of times larger than the estimated
energy required to form and maintain a hurricane. Our estimates show that
global warming is forming a very large pool of excess energy that could in
principle power heatwaves, heavy precipitation, droughts, and hurricanes. The
arguments presented here are sufficiently simple to be presented in
introductory physics classes, and can serve as plausibility arguments showing
that even a seemingly small increase in global mean temperature can potentially
lead to extreme weather events."
physics,"X-ray phase contrast imaging of biological specimens with tabletop
  synchrotron radiation","Since their discovery in 1896, x-rays have had a profound impact on science,
medicine and technology. Here we show that the x-rays from a novel tabletop
source of bright coherent synchrotron radiation can be applied to phase
contrast imaging of biological specimens, yielding superior image quality and
avoiding the need for scarce or expensive conventional sources."
physics,"A fully {\it ab initio} potential curve of near-spectroscopic quality
  for the OH^- anion: importance of connected quadruple excitations and scalar
  relativistic effects","A benchmark study has been carried out on the ground-state potential curve of
the hydroxyl anion, OH^{-}, including detailed calibration of both the
1-particle and n-particle basis sets. The CCSD(T) basis set limit overestimates
$\omega_e$ by about 10 cm^{-1}, which is only remedied by inclusion of
connected quadruple excitations in the coupled cluster expansion --- or,
equivalently, the inclusion of the $2\pi$ orbitals in the active space of a
multireference calculation. Upon inclusion of scalar relativistic effects (-3
cm^{-1} on $\omega_e$), a potential curve of spectroscopic quality (sub-cm^{-1}
accuracy) is obtained. Our best computed EA(OH), 1.828 eV, agrees to three
decimal places with the best available experimental value. Our best computed
dissociation energies, D_0(OH^-)=4.7796 eV and D_0(OH)=4.4124 eV, suggest that
the experimental D_0(OH)=4.392 eV may possibly be about 0.02 eV too low."
physics,"Concept to assess the human perception of odour by estimating short-time
  peak concentrations from one-hour mean values. Reply to a comment by Müller
  et al","Biologically relevant exposure to environmental pollutants often shows a
non-linear relationship. For their assessment, as a rule short term
concentrations have to be determined instead of long term mean values. This is
also the case for the perception of odour. Regulatory dispersion models like
AUSTAL2000 calculate long term mean concentration values (one-hour), but
provide no information on the fluctuation from this mean. The ratio between a
short term mean value (relevant for odour perception) and the long term mean
value (calculated by the dispersion model), called the peak-to-mean value, is
usually used to describe these fluctuations. In general, this ratio can be
defined in different ways. M\""uller et al. (2012), in a comment to Schauberger
et al. (2012) which includes a statement that AUSTAL2000 uses a constant factor
of 4, argue that AUSTAL2000 does not apply a peak-to-mean factor and does not
calculate odour exceedance probabilities. Instead it calculates the frequency
of so-called odour-hours by applying the relation between the 90-percentile of
the instantaneous concentration and the hourly mean (Janicke and Janicke,
2007a), not between some peak value and the mean. According to Janicke and
Janicke (2007a), the 90-percentile of the instantaneous concentration can in
practice be estimated with sufficient accuracy from the hourly mean by using a
factor of 4. Having so far replied to M\""uller et al. (2012) we take
additionally the opportunity to elaborate a little more on the peak-to-mean
concept, especially pointing out that a constant factor independent of the
stability of the atmosphere, the distance from and the geometry of the source,
is not appropriate. On the contrary it shows a sophisticated structure which
cannot be described by only one single value."
physics,"Revisting the limits of atmospheric temperature retrieval from
  cosmic-ray measurements","A priori, cosmic-ray measurements offer a unique capability to determine the
vertical profile of atmospheric temperatures directly from ground. However,
despite the increased understanding of the impact of the atmosphere on
cosmic-ray rates, attempts to explore the technological potential of the latter
for atmospheric physics remain very limited. In this paper we examine the
intrinsic limits of the process of cosmic-ray data inversion for atmospheric
temperature retrieval, by combining a detection station at ground with another
one placed at an optimal depth, and making full use of the angular information.
With that aim, the temperature-induced variations in c. r. rates have been
simulated resorting to the theoretical temperature coefficients $W_T(h, \theta,
E_{th})$ and the temperature profiles obtained from the ERA5 atmospheric
reanalysis. Muon absorption and Poisson statistics have been included to
increase realism. The resulting c.r. sample has been used as input for the
inverse problem and the obtained temperatures compared to the input temperature
data. Relative to early simulation works, performed without using angular
information and relying on underground temperature coefficients from a
sub-optimal depth, our analysis shows a strong improvement in temperature
predictability for all atmospheric layers up to 50 hPa, nearing a factor 2
error reduction. Furthermore, the temperature predictability on 6 h-intervals
stays well within the range 0.8-2.2 K. Most remarkably, we show that it can be
achieved with small-area m$^2$-scale muon hodoscopes, amenable nowadays to a
large variety of technologies. For mid-latitude locations, the optimal depth of
the underground station is around 20 m."
physics,Optomechanical accelerometers for geodesy,"We present a novel optomechanical inertial sensor for low frequency
applications and corresponding acceleration measurements. This sensor has a
resonant frequency of 4.7Hz, a mechanical quality factor of 476k, a test mass
of 2.6 gram, and a projected noise floor of approximately 5E-11 m s-2. per
root-Hz at 1Hz. Such performance, together with its small size, low weight,
reduced power consumption, and low susceptibility to environmental variables
such as magnetic field or drag conditions makes it an attractive technology for
future geodesy missions. In this paper, we present an experimental
demonstration of low-frequency ground seismic noise detection by direct
comparison with a commercial seismometer, anda data analysis algorithms for the
identification, characterization, and correction of several noise sources."
physics,The ELFIN Mission,"The Electron Loss and Fields Investigation with a Spatio-Temporal
Ambiguity-Resolving option (ELFIN-STAR, or simply: ELFIN) mission comprises two
identical 3-Unit (3U) CubeSats on a polar (~93deg inclination), nearly
circular, low-Earth (~450 km altitude) orbit. Launched on September 15, 2018,
ELFIN is expected to have a >2.5 year lifetime. Its primary science objective
is to resolve the mechanism of storm-time relativistic electron precipitation,
for which electromagnetic ion cyclotron (EMIC) waves are a prime candidate.
From its ionospheric vantage point, ELFIN uses its unique pitch-angle-resolving
capability to determine whether measured relativistic electron pitch-angle and
energy spectra within the loss cone bear the characteristic signatures of
scattering by EMIC waves or whether such scattering may be due to other
processes. Pairing identical ELFIN satellites with slowly-variable along-track
separation allows disambiguation of spatial and temporal evolution of the
precipitation over minutes-to-tens-of-minutes timescales, faster than the orbit
period of a single low-altitude satellite (~90min). Each satellite carries an
energetic particle detector for electrons (EPDE) that measures 50keV to 5MeV
electrons with deltaE/E<40% and a fluxgate magnetometer (FGM) on a ~72cm boom
that measures magnetic field waves (e.g., EMIC waves) in the range from DC to
5Hz Nyquist (nominally) with <0.3nT/sqrt(Hz) noise at 1Hz. The spinning
satellites (T_spin~3s) are equipped with magnetorquers that permit spin-up/down
and reorientation maneuvers. The spin axis is placed normal to the orbit plane,
allowing full pitch-angle resolution twice per spin. An energetic particle
detector for ions (EPDI) measures 250keV-5MeV ions, addressing secondary
science. Funded initially by CalSpace and the University Nanosat Program, ELFIN
was selected for flight with joint support from NSF and NASA between 2014 and
2018."
physics,A Review of Laser-Plasma Ion Acceleration,"An overview of research on laser-plasma based acceleration of ions is given.
The experimental state of the art is summarized and recent progress is
discussed. The basic acceleration processes are briefly reviewed with an
outlook on hybrid mechanisms and novel concepts. Finally, we put focus on the
development of engineered targets for enhanced acceleration and of all-optical
methods for beam post-acceleration and control."
physics,Terahertz streaking of few-femtosecond relativistic electron beams,"Streaking of photoelectrons with optical lasers has been widely used for
temporal characterization of attosecond extreme ultraviolet pulses. Recently,
this technique has been adapted to characterize femtosecond x-ray pulses in
free-electron lasers with the streaking imprinted by farinfrared and Terahertz
(THz) pulses. Here, we report successful implementation of THz streaking for
time-stamping of an ultrashort relativistic electron beam of which the energy
is several orders of magnitude higher than photoelectrons. Such ability is
especially important for MeV ultrafast electron diffraction (UED) applications
where electron beams with a few femtosecond pulse width may be obtained with
longitudinal compression while the arrival time may fluctuate at a much larger
time scale. Using this laser-driven THz streaking technique, the arrival time
of an ultrashort electron beam with 6 fs (rms) pulse width has been determined
with 1.5 fs (rms) accuracy. Furthermore, we have proposed and demonstrated a
non-invasive method for correction of the timing jitter with femtosecond
accuracy through measurement of the compressed beam energy, which may allow one
to advance UED towards sub-10 fs frontier far beyond the ~100 fs (rms) jitter."
physics,"Non-invasive time-sorting in radio-frequency compressed ultrafast
  electron diffraction","We demonstrate a non-invasive time-sorting method for ultrafast electron
diffraction (UED) experiments with radio-frequency (rf) compressed electron
beams. We show that electron beam energy and arrival time at the sample after
rf compression are strongly correlated such that the arrival time jitter may be
corrected through measurement of the beam energy. The method requires minimal
change to the infrastructure of most of the UED machines and is applicable to
both keV and MeV UED. In our experiment with ~3 MeV beam, the timing jitter
after rf compression is corrected with 35 fs root-mean-square (rms) accuracy,
limited by the 3x10^-4 energy stability. For keV UED with high energy
stability, sub-10 fs accuracy in time-sorting should be readily achievable.
This time-sorting technique allows us to retrieve the 2.5 THz oscillation
related to coherent A1g phonon in laser excited Bismuth film and extends the
temporal resolution of UED to a regime far beyond the 100-200 fs rms jitter
limitation."
physics,Exploring atmospheric radon with airborne gamma-ray spectroscopy,"$^{222}$Rn is a noble radioactive gas produced along the $^{238}$U decay
chain, which is present in the majority of soils and rocks. As $^{222}$Rn is
the most relevant source of natural background radiation, understanding its
distribution in the environment is of great concern for investigating the
health impacts of low-level radioactivity and for supporting regulation of
human exposure to ionizing radiation in modern society. At the same time,
$^{222}$Rn is a widespread atmospheric tracer whose spatial distribution is
generally used as a proxy for climate and pollution studies. Airborne gamma-ray
spectroscopy (AGRS) always treated $^{222}$Rn as a source of background since
it affects the indirect estimate of equivalent $^{238}$U concentration. In this
work the AGRS method is used for the first time for quantifying the presence of
$^{222}$Rn in the atmosphere and assessing its vertical profile. High
statistics radiometric data acquired during an offshore survey are fitted as a
superposition of a constant component due to the experimental setup background
radioactivity plus a height dependent contribution due to cosmic radiation and
atmospheric $^{222}$Rn. The refined statistical analysis provides not only a
conclusive evidence of AGRS $^{222}$Rn detection but also a (0.96 $\pm$ 0.07)
Bq/m$^{3}$ $^{222}$Rn concentration and a (1318 $\pm$ 22) m atmospheric layer
depth fully compatible with literature data."
physics,"Airborne gamma-ray spectroscopy for modeling cosmic radiation and
  effective dose in the lower atmosphere","In this paper we present the results of a $\sim$5 hour airborne gamma-ray
survey carried out over the Tyrrhenian sea in which the height range (77-3066)
m has been investigated. Gamma-ray spectroscopy measurements have been
performed by using the AGRS_16L detector, a module of four 4L NaI(Tl) crystals.
The experimental setup was mounted on the Radgyro, a prototype aircraft
designed for multisensorial acquisitions in the field of proximal remote
sensing. By acquiring high-statistics spectra over the sea (i.e. in the absence
of signals having geological origin) and by spanning a wide spectrum of
altitudes it has been possible to split the measured count rate into a constant
aircraft component and a cosmic component exponentially increasing with
increasing height. The monitoring of the count rate having pure cosmic origin
in the >3 MeV energy region allowed to infer the background count rates in the
$^{40}$K, $^{214}$Bi and $^{208}$Tl photopeaks, which need to be subtracted in
processing airborne gamma-ray data in order to estimate the potassium, uranium
and thorium abundances in the ground. Moreover, a calibration procedure has
been carried out by implementing the CARI-6P and EXPACS dosimetry tools,
according to which the annual cosmic effective dose to human population has
been linearly related to the measured cosmic count rates."
physics,"Revealing the Mechanism of Low-Energy Electron Yield Enhancement from
  Sensitizing Nanoparticles","We provide a physical explanation for enhancement of the low-energy electron
production by sensitizing nanoparticles due to irradiation by fast ions. It is
demonstrated that a significant increase in the number of emitted electrons
arises from the collective electron excitations in the nanoparticle. We predict
a new mechanism of the yield enhancement due to the plasmon excitations and
quantitatively estimate its contribution to the electron production. Revealing
the nanoscale mechanism of the electron yield enhancement, we provide an
efficient tool for evaluating the yield of emitted electron from various
sensitizers. It is shown that the number of low-energy electrons generated by
the gold and platinum nanoparticles of a given size exceeds that produced by
the equivalent volume of water and by other metallic (e.g., gadolinium)
nanoparticles by an order of magnitude. This observation emphasizes the
sensitization effect of the noble metal nanoparticles and endorses their
application in novel technologies of cancer therapy with ionizing radiation."
physics,"Transport of secondary electrons through coatings of ion-irradiated
  metallic nanoparticles","The transport of low-energy electrons through the coating of a
radiosensitizing metallic nanoparticle under fast ion irradiation is analyzed
theoretically and numerically. As a case study, we consider a poly(ethylene
glycol)-coated gold nanoparticle of diameter 1.6~nm excited by a carbon ion in
the Bragg peak region in water as well as by more energetic carbon ions. The
diffusion equation for low-energy electrons emitted from a finite-size
spherical source representing the surface of the metal core is solved to obtain
the electron number density as a function of radial distance and time.
Information on the atomistic structure and composition of the coating is
obtained from molecular dynamics simulations performed with the MBN Explorer
software package. Two mechanisms of low-energy electron production by the
metallic core are considered: the relaxation of plasmon excitations and
collective excitations of valence $d$ electrons in individual atoms of gold.
Diffusion coefficients and characteristic lifetimes of electrons propagating in
gold, water, and poly(ethylene glycol) are obtained from relativistic partial
wave analysis and the dielectric formalism, respectively. On this basis, the
number of electrons released through the organic coating into the surrounding
aqueous medium and the number of hydroxyl radicals produced are evaluated. The
largest increase of the radical yield due to low-energy electrons is observed
when the nanoparticle is excited by an ion with energy significantly exceeding
that in the Bragg peak region. It is also shown that the water content of the
coating, especially near the surface of the metal core, is crucial for the
production of hydroxyl radicals."
physics,"Electron production by sensitizing gold nanoparticles irradiated by fast
  ions","The yield of electrons generated by gold nanoparticles due to irradiation by
fast charged projectiles is estimated. The results of calculations are compared
to those obtained for pure water medium. It is demonstrated that a significant
increase in the number of emitted electrons arises from collective electron
excitations in the nanoparticle. The dominating enhancement mechanisms are
related to the formation of (i) plasmons excited in a whole nanoparticle, and
(ii) atomic giant resonances due to excitation of d electrons in individual
atoms. Decay of the collective electron excitations in a nanoparticle embedded
in a biological medium thus represents an important mechanism of the low-energy
electron production. Parameters of the utilized model approach are justified
through the calculation of the photoabsorption spectra of several gold
nanoparticles, performed by means of time-dependent density-functional theory."
physics,Laser induced strong-field ionization gas jet tomography,"We introduce a novel in-situ strong field ionization tomography approach for
characterizing the spatial density distribution of gas jets. We show that for
typical intensities in high harmonic generation experiments, the strong field
ionization mechanism used in our approach provides an improvement in the
resolution close to factor of 2 (resolving about 8 times smaller voxel volume),
when compared to linear/single-photon imaging modalities.
  We find, that while the depth of scan in linear tomography is limited by
resolution loss due to the divergence of the driving laser beam, in the
proposed approach the depth of focus is localized due to the inherent physical
nature of strong-field interaction and discuss implications of these findings.
We explore key aspects of the proposed method and compare it with commonly used
single- and multi-photon imaging mechanisms. The proposed method will be
particularly useful for strong field and attosecond science experiments."
physics,"Pore Network and Medial Axis simultaneous extraction through Maximal
  Ball Algorithm","Network Extraction algorithms from X-ray microcomputed tomography have become
a routine method to obtain pore connectivity and pore morphology information
from porous media. The main approaches for this extraction are either based on
Max Ball Algorithm or Medial Axis Extraction. The first is a robust method to
separate the pore space into pore and throats, which provides the pore and
throat sizes distributions directly. The second simplifies the medium by
thinning the volume into a one voxel wide centerline that preserves the
volume's topological information. Since each method has drastically different
implementations, it is not usual to use both to characterize the porous
structure. This work presents a method to extract a simplified centerline of
porous materials by adding few more steps to the well-established Max Ball
algorithm. Results for sandstones and carbonate rock samples show that this
Medial-Axis network can be used for single phase flow simulations, as well as
preserves the mediums morphology."
physics,"Kinetic corrections from analytic non-Maxwellian distribution functions
  in magnetized plasmas","In magnetized plasma physics, almost all developed analytic theories assume a
Maxwellian distribution function (MDF) and in some cases small deviations are
described using the perturbation theory. The deviations with respect to the
Maxwellian equilibrium, called kinetic effects, are required to be taken into
account specially for fusion reactor plasmas. Generally, because the
perturbation theory is not consistent with observed steady-state
non-Maxwellians, these kinetic effects are numerically evaluated by very
CPU-expensive codes, avoiding the analytic complexity of velocity phase space
integrals. We develop here a new method based on analytic non-Maxwellian
distribution functions constructed from non-orthogonal basis sets in order to
(i) use as few parameters as possible, (ii) increase the efficiency to model
numerical and experimental non-Maxwellians, (iii) help to understand unsolved
problems such as diagnostics discrepancies from the physical interpretation of
the parameters, and (iv) obtain analytic corrections due to kinetic effects
given by a small number of terms and removing the numerical error of the
evaluation of velocity phase space integrals. This work does not attempt to
derive new physical effects even if it could be possible to discover one from
the better understandings of some unsolved problems, but here we focus on the
analytic prediction of kinetic corrections from analytic non-Maxwellians. As
applications, examples of analytic kinetic corrections are shown for the
secondary electron emission, the Langmuir probe characteristic curve, and the
entropy. This is done by using three analytic representations of the
distribution function: the Kappa (KDF), the bi-modal or a new interpreted
non-Maxwellian (INMDF) distribution function. [...]"
physics,"Fluctuations and large deviations of Reynolds stresses in zonal jet
  dynamics","The Reynolds stress, or equivalently the average of the momentum flux, is key
to understanding the statistical properties of turbulent flows. Both typical
and rare fluctuations of the time averaged momentum flux are needed to fully
characterize the slow flow evolution. The fluctuations are described by a large
deviation rate function that may be calculated either from numerical
simulation, or from theory. We show that, for parameter regimes in which a
quasilinear approximation is accurate, the rate function can be found by
solving a matrix Riccati equation. Using this tool we compute for the first
time the large deviation rate function for the Reynolds stress of a turbulent
flow. We study a barotropic flow on a rotating sphere, and show that the
fluctuations are highly non-Gaussian. This work opens up new perspectives for
the study of rare transitions between attractors in turbulent flows."
physics,Crater Property in Two-Particle Bound States: When and Why,"Crater has shown that, for two particles (with masses $m_1$ and $m_2$) in a
Coulombic bound state, the charge distribution is equal to the sum of the two
charge distributions obtained by taking $m_1\to\infty$ and $m_2\to\infty$
respectively, while keeping the same Coulombic potential. We provide a simple
scaling criterion to determine whether an arbitrary Hamiltonian possesses this
property. In particular we show that, for a Coulombic system, fine structure
corrections preserve this Crater property while two-particle relativistic
corrections and/or hyperfine corrections may destroy it."
physics,"Parallel J-W Monte Carlo Simulations of Thermal Phase Changes in
  Finite-size Systems","The thermodynamic properties of 59 TeF6 clusters that undergo
temperature-driven phase transitions have been calculated with a canonical
J-walking Monte Carlo technique. A parallel code for simulations has been
developed and optimized on SUN3500 and CRAY-T3E computers. The Lindemann
criterion shows that the clusters transform from liquid to solid and then from
one solid structure to another in the temperature region 60-130 K."
physics,"Charge Dependence of Temperature-Driven Phase Transitions of Molecular
  Nanoclusters: Molecular Dynamics Simulation","Phase transitions (liquid-solid, solid-solid) triggered by temperature
changes are studied in free nanosized clusters of TeF_6 (SF_6) with different
negative charges assigned to the fluorine atoms. Molecular dynamics simulations
at constant energy show that the charge increase from q_F=0.1 e to q_F=0.25 e
shifts the melting temperature towards higher values and some of the metastable
solid states disappear. The increased repulsive interaction maintains the order
in molecular systems at higher temperatures."
physics,A Pseudospectral Method for Optimal Control of Open Quantum Systems,"In this paper, we present a unified computational method based on
pseudospectral approximations for the design of optimal pulse sequences in open
quantum systems. The proposed method transforms the problem of optimal pulse
design, which is formulated as a continuous time optimal control problem, to a
finite dimensional constrained nonlinear programming problem. This resulting
optimization problem can then be solved using existing numerical optimization
suites. We apply the Legendre pseudospectral method to a series of optimal
control problems on open quantum systems that arise in Nuclear Magnetic
Resonance (NMR) spectroscopy in liquids. These problems have been well studied
in previous literature and analytical optimal controls have been found. We find
an excellent agreement between the maximum transfer efficiency produced by our
computational method and the analytical expressions. Moreover, our method
permits us to extend the analysis and address practical concerns, including
smoothing discontinuous controls as well as deriving minimum energy controls.
The method is not restricted to the systems studied in this article but is
universal to every open quantum system whose performance is limited by
dissipation."
physics,Rules for Minimal Atomic Multipole Expansion of Molecular Fields,"A non-empirical minimal atomic multipole expansion (MAME) defines atomic
charges or higher multipoles that reproduce electrostatic potential outside
molecules. MAME eliminates problems associated with redundancy and with
statistical sampling, and produces atomic multipoles in line with chemical
intuition."
physics,"Analysis and Optimization of Resonance Energies and Widths Using Complex
  Absorbing Potentials","Complex absorbing potentials (CAPs) are artificial potentials added to
electronic Hamiltonians to make the wavefunction of metastable electronic
states square-integrable. This makes the electronic structure problem of
electronic resonances comparable to that of electronic bound states, thus
reducing the complexity of the problem. CAPs depend on two types of parameters:
the coupling parameter $\eta$ and a set of spatial parameters which define the
onset of the CAP. It has been a common practice over the years to minimize the
CAP perturbation on the physical electronic Hamiltonian by running an
$\eta-$trajectory, whereby one fixes the spatial parameters and varies $\eta$.
The optimal $\eta$ is chosen according to the minimum log-velocity criterion.
But the effectiveness of an $\eta-$trajectory strongly depends on the values of
the fixed spatial parameters.
  In this work, we propose a more general criterion, called the
$\xi-$criterion, which allows one to minimize any CAP parameter, including the
CAP spatial parameters. Indeed, we show that fixing $\eta$ and varying the
spatial parameters according to a scheme (i.e., running a spatial trajectory)
is a more efficient and reliable way of minimizing the CAP perturbations (which
is assessed using the $\xi-$criterion). We illustrate the method by determining
the resonance energy and width of the temporary anion of dinitrogen, at the
Hartree-Fock and EOM-EA-CCSD levels, using two different types of CAPs: the
box- and the smooth Voronoi-CAPs."
physics,"United Nations Basic Space Science Initiative: 2011 Status Report on the
  International Space Weather Initiative","The UNBSSI is a long-term effort for the development of astronomy and space
science through regional and international cooperation in this field on a
worldwide basis. A series of workshops on BSS was held from 1991 to 2004 (India
1991, Costa Rica and Colombia 1992, Nigeria 1993, Egypt 1994, Sri Lanka 1995,
Germany 1996, Honduras 1997, Jordan 1999, France 2000, Mauritius 2001,
Argentina 2002, and China 2004; http://www.seas.columbia.edu/~ah297/un-esa/)
and addressed the status of astronomy in Asia and the Pacific, Latin America
and the Caribbean, Africa, and Western Asia. One major recommendation that
emanated from these workshops was the establishment of astronomical facilities
in developing nations for research and education programmes at the university
level. Such workshops on BSS emphasized the particular importance of
astrophysical data systems and the virtual observatory concept for the
development of astronomy on a worldwide basis. Pursuant to resolutions of the
United Nations Committee on the Peaceful Uses of Outer Space (UNCOPUOS) and its
Scientific and Technical Subcommittee, since 2005, these workshops focused on
the International Heliophysical Year 2007 (UAE 2005, India 2006, Japan 2007,
Bulgaria 2008, Ro Korea 2009;
http://www.unoosa.org/oosa/SAP/bss/ihy2007/index.html). Starting in 2010, the
workshops focus on the International Space Weather Initiative (ISWI) as
recommended in a three-year-work plan as part of the deliberations of UNCOPUOS
(http://www.stil.bas.bg/ISWI/). Workshops on the ISWI have been scheduled to be
hosted by Egypt in 2010 for Western Asia, Nigeria in 2011 for Africa, and
Ecuador in 2012 for Latin America and the Caribbean. Currently, 14 IHY/ISWI
instrument arrays with > 600 instruments are operational in 95 countries."
physics,The theory of relativity and the Pythagorean theorem,"It is shown that the most important effects of special and general theory of
relativity can be understood in a simple and straightforward way. The system of
units in which the speed of light $c$ is the unit of velocity allows to cast
all formulas in a very simple form.The Pythagorean theorem graphically relates
energy, momentum and mass. The paper is addressed to those who teach and
popularize the theory of relativity."
physics,Kermit's What-Happens-Next-Machine Reloaded,"If Kermit's What-Happens-Next-Machine had functioned, you would not have seen
much, because it would have gone too quickly. In this article it is shown that
putting up and solving the equations of motion of a seemingly simple mechanical
apparatus presents a challenging problem. The simulation can, however, be quite
instructive and also entertaining."
physics,"The falling raindrop, revisited","I reconsider the problem of a raindrop falling through mist, collecting mass,
and generalize it to allow an arbitrary power-law form for the accretion rate.
I show that the coupled differential equations can be solved by the simple
trick of temporarily eliminating time (t) in favor of the raindrop's mass (m)
as the independent variable"
physics,Using the Sound Card as a Timer,"Experiments in mechanics can often be timed by the sounds they produce. In
such cases, digital audio recordings provide a simple way of measuring time
intervals with an accuracy comparable to that of photogate timers. We
illustrate this with an experiment in the physics of sports: to measure the
speed of a hard-kicked soccer ball."
physics,The Moving Center of Mass of a Leaking Bob,"The evaluation of variation in oscillation time period of a simple pendulum
as its mass varies proves a rich source of discussion in a physics class-room,
overcoming erroneous notions carried forward by students as to what constitutes
a pendulum's length due to picking up only the results of approximations and
ignoring the rigorous definition. The discussion also presents a exercise for
evaluating center of mass of geometrical shapes and system of bodies. In all,
the pedagogical value of the problem is worth both theoretical and experimental
efforts. This article discusses the theoretical considerations."
physics,"Solving the brachistochrone and other variational problems with soap
  films","We show a method to solve the problem of the brachistochrone as well as other
variational problems with the help of the soap films that are formed between
two suitable surfaces. We also show the interesting connection between some
variational problems of dynamics, statics, optics, and elasticity."
physics,"The weight of a falling chain, revisited","A vertically hanging chain is released from rest and falls due to gravity on
a scale pan. We discuss the various experimental and theoretical aspects of
this classic problem. Careful time-resolved force measurements allow us to
determine the differences between the idealized and its implementation in the
laboratory problem. We observe that, in spite of the upward force exerted by
the pan on the chain, the free end at the top falls faster than a freely
falling body. Because a real chain exhibits a finite minimum radius of
curvature, the contact at the bottom results in a tensional force which pulls
the falling part downward."
physics,Relativity on Rotated Graph Paper,"We present visual calculations in special relativity using spacetime diagrams
drawn on graph paper that has been rotated by 45 degrees. The rotated lines
represent lightlike directions in Minkowski spacetime, and the boxes in the
grid (called ""light-clock diamonds"") represent units of measurement modeled on
the ticks of an inertial observer's lightclock. We show that many quantitative
results can be read off a spacetime diagram by counting boxes, using a minimal
amount of algebra. We use the Doppler Effect, in the spirit of the Bondi
k-calculus, to motivate the method."
physics,A Jumping Cylinder on an Incline,"The problem of a cylinder of mass m and radius r, with its center of mass out
of the cylinder axis, rolling on an incline that makes an angle with respect to
the horizontal is analyzed. The equation of motion is partially solved to
obtain the site where the cylinder loses contact with the incline (jumps).
Several simplifications are made: the analyzed system consists of an
homogeneous disc with a one dimensional straight line of mass parallel to the
disc axis at a distance y < r of the center of the cylinder. To compare our
results with experimental data, we use a Styrofoam cylinder to which a long
brass rod was imbibed parallel to the disc axis at a distance y < r from it, so
the center of mass lies at a distance d from the center of the cylinder. Then
the disc rolls without slipping on a long wooden ramp inclined at 15, 30 and 45
degrees with respect to the horizontal. To determine the jumping site, the
motion was recorded with a high-speed video camera (Casio EX ZR100) at 200 and
480 frames per second. The experimental results agree well with the theoretical
predictions."
physics,Modeling a falling slinky,"A slinky is an example of a tension spring: in an unstretched state a slinky
is collapsed, with turns touching, and a finite tension is required to separate
the turns from this state. If a slinky is suspended from its top and stretched
under gravity and then released, the bottom of the slinky does not begin to
fall until the top section of the slinky, which collapses turn by turn from the
top, collides with the bottom. The total collapse time t_c (typically ~0.3 s
for real slinkies) corresponds to the time required for a wave front to
propagate down the slinky to communicate the release of the top end. We present
a modification to an existing model for a falling tension spring (Calkin 1993)
and apply it to data from filmed drops of two real slinkies. The modification
of the model is the inclusion of a finite time for collapse of the turns of the
slinky behind the collapse front propagating down the slinky during the fall.
The new finite-collapse time model achieves a good qualitative fit to the
observed positions of the top of the real slinkies during the measured drops.
The spring constant k for each slinky is taken to be a free parameter in the
model. The best-fit model values for k for each slinky are approximately
consistent with values obtained from measured periods of oscillation of the
slinkies."
physics,Radial Forcing and Edgar Allan Poe's Lengthening Pendulum,"Inspired by Edgar Allan Poe's The Pit and the Pendulum, we investigate a
radially driven, lengthening pendulum. We first show that increasing the length
of an undriven pendulum at a uniform rate does not amplify the oscillations in
a manner consistent with the behavior of the scythe in Poe's story. We discuss
parametric amplification and the transfer of energy (through the parameter of
the pendulum's length) to the oscillating part of the system. In this manner
radial driving may easily and intuitively be understood, and the fundamental
concept applied in many other areas. We propose and show by a numerical model
that appropriately timed radial forcing can increase the oscillation amplitude
in a manner consistent with Poe's story. Our analysis contributes a
computational exploration of the complex harmonic motion that can result from
radially driving a pendulum, and sheds light on a mechanism by which
oscillations can be amplified parametrically. These insights should prove
especially valuable in the undergraduate physics classroom, where
investigations into pendulums and oscillations are commonplace."
physics,Analytic expression for pull-or-jerk experiment,"This work focuses on a theoretical analysis of a well-known inertia
demonstration, which uses a weight suspended by a string with an extra string
that hangs below the weight. The point in question is which string, the upper
or lower, will break when pulling down on the bottom edge of the lower string
at a constant pulling speed. An analytic solution for the equation of motion
allows us to identify the critical value of the pulling speed, beyond which the
string breaking varies from one to the other. The analysis also provides us a
phase diagram that illustrates the interplay between the pulling speed and the
string's elasticity in the pull-or-jerk experiment."
physics,Simplifying the vacuum bazooka,"This paper provides a simplified explanation of the vacuum bazooka through
diagrams and builds a theoretical model only using concepts found in
introductory mechanics. Our theory suggests that the velocity of the projectile
is proportional to the hyperbolic tangent of time, and experimental
measurements support this claim. We also find that the vacuum bazooka could be
used to demonstrate the concept of terminal velocity in a classroom setting."
physics,"The physical leaky tank car problem, revisited","An exhaustive analysis of the leaky tank car problem is presented, pointing
out its intriguing physical properties, which well serve to students and
teachers for illustrating standard Newtonian mechanics in a highly non-standard
fashion. Calculus (at a leading undergraduate level) is effectively required
only to examine some details concerning the solution of the equation of motion
and interesting limiting cases. Instead we let any student to appreciate all
the physical content of the problem, within a proper simple model and its
generalization, ranging from the motion of the leaky tank car to that of the
water flowing from the car with their peculiarities. Generalizations of the
problem to more than one draining hole (even with different sizes), as well as
to ""two-dimensional"" geometries, reveal further intriguing results, culminating
into a no-rotation theorem and its corollaries, thus rendering unique the
problem at hand for allowing students to fully recognize the power of physical
analysis."
physics,A computer controlled pendulum with position readout,"We have designed, built and operated a physical pendulum which allows one to
demonstrate experimentally the behaviour of the pendulum under any equation of
motion for such a device for any initial conditions. All parameters in the
equation of motion can be defined by the user. The potential of the apparatus
reaches from demonstrating simple undamped harmonic oscillations to complex
chaotic behaviour of the pendulum. The position data of the pendulum as well as
derived kinematical quantities like velocity and acceleration can be stored for
later offline analysis."
physics,"Direct quantitative measurements of Doppler effects for sound sources
  with gravitational acceleration","We explain simple laboratory experiments for making quantitative measurements
of the Doppler effect from sources with acceleration. We analyze the spectra
and clarify the conditions for the Doppler effect to be experimentally
measurable, which turn out to be non-trivial when acceleration is involved. The
experiments use sources with gravitational acceleration, in free fall and in
motion as a pendulum, so that the results can be checked against fundamental
physics principles. The experiments can be easily set up from ``off the shelf''
components only. The experiments are suitable for a wide range of students,
including undergraduates not majoring in science or engineering."
physics,"Illustrations of Equivalent Methods to Reproduce Vehicle and Occupant
  Dynamics as a Pedagogical Tool","When explaining to a lay audience the magnitude of forces or accelerations
imparted to vehicles or experienced by vehicle occupants during a motor vehicle
collision, it is often helpful to recast the critical results in terms of other
physical systems or impact configurations which will reproduce the equivalent
dynamics of the subject accident to serve as a conceptual aid for the audience.
In this article, we present the basis for such equivalents and explicitly
demonstrate, using two physics simulation software packages, that such
equivalents are based on nothing more than the application of the laws of
physics."
physics,"Simulating pump-probe photo-electron and absorption spectroscopy on the
  attosecond time-scale with time-dependent density-functional theory","Molecular absorption and photo-electron spectra can be efficiently predicted
with real-time time-dependent density-functional theory (TDDFT). We show here
how these techniques can be easily extended to study time-resolved pump-probe
experiments in which a system response (absorption or electron emission) to a
probe pulse, is measured in an excited state. This simulation tool helps to
interpret the fast evolving attosecond time-resolved spectroscopic experiments,
where the electronic motion must be followed at its natural time-scale. We show
how the extra degrees of freedom (pump pulse duration, intensity, frequency,
and time-delay), which are absent in a conventional steady state experiment,
provide additional information about electronic structure and dynamics that
improve a system characterization. As an extension of this approach,
time-dependent 2D spectroscopies can also be simulated, in principle, for
large-scale structures and extended systems."
physics,"On the Generation of Multiply Charged Argon Ions in Nanosecond Laser
  Field Ionization of Argon","Zhang and coworkers have recently reported results of experiments involving
irradiation of argon clusters doped with bromofluorene chromophores by
nanosecond-long pulses of 532 nm laser light. Multiply-charged ions of atomic
argon (charge states, n, up to 7) and carbon (charge states up to 4) are
observed which are sought to be rationalised using an evaporation model. The
distinguishing facet of exploding clusters being progenitors of energetic ions
and electrons constitutes the key driver for contemporary research in
laser-cluster interactions; it is, therefore, important to point out
inconsistencies that are intrinsic to the model of Zhang and coworkers. In
light of similar reports already in the literature, we show that their model is
of limited utility in describing the dynamics that govern how fast,
multiply-charged atomic ions result from laser irradiation of gas-phase
clusters. We posit that it is plasma behaviour that underpins cluster heating
and cluster explosion dynamics."
physics,Radiation Pressure Dominate Regime of Relativistic Ion Acceleration,"The electromagnetic radiation pressure becomes dominant in the interaction of
the ultra-intense electromagnetic wave with a solid material, thus the wave
energy can be transformed efficiently into the energy of ions representing the
material and the high density ultra-short relativistic ion beam is generated.
This regime can be seen even with present-day technology, when an exawatt laser
will be built. As an application, we suggest the laser-driven heavy ion
collider."
physics,"Numerical stability analysis of the Pseudo-Spectral Analytical
  Time-Domain PIC algorithm","The pseudo-spectral analytical time-domain (PSATD) particle-in-cell (PIC)
algorithm solves the vacuum Maxwell's equations exactly, has no Courant
time-step limit (as conventionally defined), and offers substantial flexibility
in plasma and particle beam simulations. It is, however, not free of the usual
numerical instabilities, including the numerical Cherenkov instability, when
applied to relativistic beam simulations. This paper derives and solves the
numerical dispersion relation for the PSATD algorithm and compares the results
with corresponding behavior of the more conventional pseudo-spectral
time-domain (PSTD) and finite difference time-domain (FDTD) algorithms. In
general, PSATD offers superior stability properties over a reasonable range of
time steps. More importantly, one version of the PSATD algorithm, when combined
with digital filtering, is almost completely free of the numerical Cherenkov
instability for time steps (scaled to the speed of light) comparable to or
smaller than the axial cell size."
physics,"Airflows inside passenger cars and implications for airborne disease
  transmission","Transmission of highly infectious respiratory diseases, including SARS-CoV-2
are facilitated by the transport of tiny droplets and aerosols (harboring
viruses, bacteria, etc.) that are breathed out by individuals and can remain
suspended in air for extended periods of time in confined environments. A
passenger car cabin represents one such situation in which there exists an
elevated risk of pathogen transmission. Here we present results from numerical
simulations of the potential routes of airborne transmission within a model car
geometry, for a variety of ventilation configurations representing different
combinations of open and closed windows. We estimate relative concentrations
and residence times of a non-interacting, passive scalar -- a proxy for
infectious pathogenic particles -- that are advected and diffused by the
turbulent airflows inside the cabin. Our findings reveal that creating an
airflow pattern that travels across the cabin, entering and existing farthest
from the occupants can potentially reduce the transmission."
physics,Contrast inversion in neutral atom microscopy using atomic cluster beams,"This work explores the possibility of atomic cluster beams as a probe for
neutral atom microscopy (NAM) measurements. Using a beam of Kr clusters with
mean size $\sim$ 10$^4$ atoms/cluster we demonstrate that topographical
contrast can be obtained, similar to that in the case of monoatomic beams.
Further, using atomically thin films of MoS$_2$ grown on SiO$_2$/Si substrate
we show that NAM imaging using Kr clusters is also possible in domains where
topographical contrast is not expected. Surprisingly, these images show an
inverted contrast pattern when compared to the case of monoatomic beams. We
attempt to understand these observations on the basis of angular distributions
resulting from cluster-surface scattering. Finally, we discuss the implications
of these results towards achieving a high lateral resolution neutral atom
microscope using atomic cluster beams."
physics,Smoothing of the slowly extracted coasting beam from a synchrotron,"Slow extraction of beam from synchrotrons or storage rings as required by
many fixed target experiments is performed by controlled excitation and feeding
of a structural lattice resonance. Due to the sensitive nature of this resonant
extraction process, the temporal structure of the extracted beam is modulated
by the minuscule current fluctuations present on the quadrupole magnet power
supplies. Such a modulation lead to pile-ups in detectors and a significant
reduction in accumulated event statistics. This contribution proposes and
experimentally demonstrates that by an introduction of further modulation on
quadrupole currents with a specific amplitude and frequency, the inherent power
supply fluctuations are mitigated leading to a smoothening of the beam temporal
structure. The slow extraction beam dynamics associated with this method are
explained along with the operational results."
physics,"Contributions of Albert Einstein to Earth Sciences: A review in
  Commemoration of the World Year of Physics","The World Year of Physics (2005) is an international celebration to
commemorate the one hundredth anniversary of Einstein's ""Annus Mirabilis"". The
United Nations has officially declared 2005 the International Year of Physics.
However, the impact of Einstein's ideas was not restricted to physics. Among
numerous other disciplines, Einstein also made significant and specific
contributions to Earth Sciences. His geosciences-related letters, comments, and
scientific articles, are dispersed, not easily accesible and are poorly known.
The present review attempts to integrate them, as a tribute to Einstein in
commemoration of this centenary. These contributions can be classified into
three basic areas: geodynamics, geological (planetary) catastrophism and
fluvial geomorphology."
physics,Hierarchical Eclipses,"The obscuration of a celestial body that covers another one in the background
will be called a ``hierarchical eclipse''. The most obvious case is that a star
or a planet will be hidden from sight by the moon during a lunar eclipse. Four
objects of the solar system will line up then. We investigate this phenomenon
with respect to the region of visibility and periodicity. There exists a
parallax field constraining the chances for observation. A historic account
from the Middle Ages is preserved that we analyse from different viewing
angles. Furthermore, we provide a list of events from 0 to 4000 AD. From this,
it is apparent that Jupiter is most often involved in such spectacles because
its orbit inclination is small. High-inclination orbits reduce the probability
to have a coincidence of an occultation of that object with a lunar eclipse."
physics,Emergence of large scale structure in planetary turbulence,"Planetary and magnetohydrodynamic drift-wave turbulence is observed to
self-organize into large scale structures such as zonal jets and coherent
vortices. In this Letter we present a non-equilibrium statistical theory, the
Stochastic Structural Stability theory (SSST), that can make predictions for
the formation and finite amplitude equilibration of non-zonal and zonal
structures (lattice and stripe patterns) in homogeneous turbulence. This theory
reveals that the emergence of large scale structure is the result of an
instability of the interaction between the coherent flow and the associated
turbulent field. Comparison of the theory with nonlinear simulations of a
barotropic flow in a beta-plane channel with turbulence sustained by isotropic
random stirring, demonstrates that SSST predicts the threshold parameters at
which the coherent structures emerge as well as the characteristics of the
emerging structures (scale, amplitude, phase speed). It is shown that non-zonal
structures (lattice states or zonons) emerge at lower energy input rates of the
stirring compared to zonal flows (stripe states) and their emergence affects
the dynamics of jet formation."
physics,Zonal flow reversals in two-dimensional Rayleigh-Bénard convection,"We analyse the nonlinear dynamics of the large scale flow in
Rayleigh-B\'enard convection in a two-dimensional, rectangular geometry of
aspect ratio $\Gamma$. We impose periodic and free-slip boundary conditions in
the streamwise and spanwise directions, respectively. As Rayleigh number Ra
increases, a large scale zonal flow dominates the dynamics of a moderate
Prandtl number fluid. At high Ra, in the turbulent regime, transitions are seen
in the probability density function (PDF) of the largest scale mode. For
$\Gamma = 2$, the PDF first transitions from a Gaussian to a trimodal
behaviour, signifying the emergence of reversals of the zonal flow where the
flow fluctuates between three distinct turbulent states: two states in which
the zonal flow travels in opposite directions and one state with no zonal mean
flow. Further increase in Ra leads to a transition from a trimodal to a
unimodal PDF which demonstrates the disappearance of the zonal flow reversals.
On the other hand, for $\Gamma = 1$ the zonal flow reversals are characterised
by a bimodal PDF of the largest scale mode, where the flow fluctuates only
between two distinct turbulent states with zonal flow travelling in opposite
directions."
physics,"Standing shock prevents propagation of sparks in supersonic explosive
  flows","Volcanic jet flows in explosive eruptions emit radio frequency signatures,
indicative of their fluid dynamic and electrostatic conditions. The emissions
originate from sparks supported by an electric field built up by the ejected
charged volcanic particles. When shock-defined, low-pressure regions confine
the sparks, the signatures may be limited to high-frequency content
corresponding to the early components of the avalanche-streamer-leader
hierarchy. Here, we image sparks and a standing shock together in a transient
supersonic jet of micro-diamonds entrained in argon. Fluid dynamic and kinetic
simulations of the experiment demonstrate that the observed sparks originate
upstream of the standing shock. The sparks are initiated in the rarefaction
region, and cut off at the shock, which would limit their radio frequency
emissions to a tell-tale high-frequency regime. We show that sparks transmit an
impression of the explosive flow, and open the way for novel instrumentation to
diagnose currently inaccessible explosive phenomena."
physics,ZMP-SAPT: DFT-SAPT using ab initio Densities,"Symmetry Adapted Perturbation Theory (SAPT) has become an important tool when
predicting and analyzing intermolecular interactions. Unfortunately, DFT-SAPT,
which uses Density Functional Theory (DFT) for the underlying monomers, has
some arbitrariness concerning the exchange-correlation potential and the
exchange-correlation kernel involved. By using ab initio Brueckner Doubles
densities and constructing Kohn-Sham orbitals via the Zhao-Morrison-Parr (ZMP)
method, we are able to lift the dependence of DFT-SAPT on DFT
exchange-correlation potential models in first order. This way, we can compute
the monomers at the Coupled-Cluster level of theory and utilize SAPT for the
intermolecular interaction energy. The resulting ZMP-SAPT approach is tested
for small dimer systems involving rare gas atoms, cations, and anions and shown
to compare well with the Tang-Toennies model and coupled cluster results."
physics,"Electron Acceleration and Radiation Generation from Relativistic
  Laser-Plasma Interactions at High Repetition-Rate","This dissertation explores the interaction between high-intensity lasers and
plasmas to accelerate electrons and produce radiation via experimental and
computational efforts. The laser pulses used in this dissertation have
ultrashort duration (< 100 fs), near-infrared to mid-infrared wavelength (0.8
$\mu$m, 2 $\mu$m, or 3.9 $\mu$m), millijoules of energy, and high repetition
rates (480 Hz or 20 Hz). The plasma sources applied are from solid-density
targets (overdense) or gaseous targets (underdense). With the
high-repetition-rate capability, statistical methods are employed to optimize
certain aspect of the experiments and to interpret the physics."
physics,"Technoeconomic Analysis of Thermal Energy Grid Storage Using Graphite
  and Tin","Energy storage is needed to enable dispatchable renewable energy supply and
thereby full decarbonization of the grid. However, this can only occur with
drastic cost reductions compared to current battery technology, with predicted
targets for the cost per unit energy (CPE) below $20/kWh. Notably, for full
decarbonization, long duration storage up to 100 hrs will be needed at such low
costs, and prior analyses have shown that in such high renewable penetration
scenarios, CPE is more critical than other parameters such as round trip
efficiency or cost per unit power when comparing the costs of different
technologies. Here, we introduce an electricity storage concept that stores
electricity as sensible heat in graphite storage blocks and uses multi-junction
thermophotovoltaics (TPV) as a heat engine to convert it back to electricity on
demand. This design is an outgrowth of the system proposed by Amy et al. in
2019, which has been modified here to use a solid graphite medium and molten
tin as a heat transfer fluid rather than silicon as both. The reason for this
is two-fold: (1) the CPE of graphite is almost 10X lower than that of silicon,
which derives from the lower cost per unit mass (i.e., $0.5/kg vs. $1.5/kg) and
the higher heat capacity per unit mass (2000 J/kg-K vs. 950 J/kg-K); and (2)
the melting point tin and solubility of tin in graphite are much lower than
that of silicon, which lessens the number of issues that have to overcome along
the research and development pathway. The usage of graphite also eliminates the
need for a second tank, but the main disadvantage of using a solid medium is
that one cannot easily provide a steady discharge rate, as the power output
from the storage will change with time, as the graphite cools during discharge.
Thus, the objective of this work is to examine how these changes in the system
design effect the overall technoeconomics."
physics,"Diamond-based Detection Systems for Accurate Pulsed X-rays Diagnostics
  in Radiotherapy","The widespread diffusion of precision radiotherapy techniques, geared toward
the release of larger dose gradients in shorter time frames, is leading to new
challenges in dosimetry. Accurate dose measurements are essential to check for
beam anomalies and inaccuracies to ensure treatment efficacy and patient safety
during radiotherapy. This work describes the main features of a diamond
dosimeter coupled to an extremely compact front-end electronics. The detection
system was tested under the X-ray pulses generated by a medical LINAC for both
the 6 MV and the 18 MV accelerating voltages. Located in the LINAC's bunker, it
eliminates the need for a long cable connection between the detector and the
electronics, detrimental for the system response speed. Signal acquisition was
performed synchronously with the impinging X-ray pulses with a sampling period
as low as 20 us, allowing for a real-time beam monitoring. The dosimeter
demonstrated a very good stability despite the high value of the absorbed dose
during the performed experiments (about 100 Gy). The measured dose-per-pulse
values of 278 uGy and 556 uGy at 6 MV and 18 MV, respectively, are in excellent
agreement with the nominal values expected for the LINAC apparatus used for the
tests. In addition to single-pulse measurements, fundamental for dynamic
radiotherapy, the proposed system also allows for the calculation of both the
total collected charge and the photocurrent generated by the detector. In this
regards, despite the compactness, it demonstrates its effectiveness as a tool
for source diagnostics in terms of both beam intensity and emission timing."
physics,Understanding the working of a B-dot probe,"Magnetic pickup loops or B-dot probes are one of the oldest known sensors of
time-varying magnetic fields. The operating principle is based on Faraday's law
of electromagnetic induction. However, obtaining accurate measurements of
time-varying magnetic fields using these kinds of probes is a challenging task.
A B-dot probe and its associated circuit are prone to electrical oscillations.
As a result, the measured signal may not faithfully represent the magnetic
field sampled by the B-dot probe. In this paper, we have studied the transient
response of a B-dot probe and its associated circuit to a time-varying magnetic
field. Methods of removing the oscillations pertaining to the detector
structure are described. After removing the source of the oscillatory signal,
we have shown that the time-integrated induced emf measured by the digitiser is
linearly proportional to the magnetic field sampled by the B-dot probe, thus
verifying the faithfulness of the measured signal."
physics,Benford's Law: Textbook Exercises and Multiple-choice Testbanks,"Benford's Law describes the finding that the distribution of leading (or
leftmost) digits of innumerable datasets follows a well-defined logarithmic
trend, rather than an intuitive uniformity. In practice this means that the
most common leading digit is 1, with an expected frequency of 30.1%, and the
least common is 9, with an expected frequency of 4.6%. The history and
development of Benford's Law is inexorably linked to physics, yet there has
been a dearth of physics-related Benford datasets reported in the literature.
Currently, the most common application of Benford's Law is in detecting number
invention and tampering such as found in accounting-, tax-, and voter-fraud. We
demonstrate that answers to end-of-chapter exercises in physics and chemistry
textbooks conform to Benford's Law. Subsequently, we investigate whether this
fact can be used to gain advantage over random guessing in multiple-choice
tests, and find that while testbank answers in introductory physics closely
conform to Benford's Law, the testbank is nonetheless secure against such a
Benford's attack for banal reasons."
physics,Can spontaneous symmetry breaking occur in potential with one minima?,"Spontaneous symmetry breaking occurs when the symmetry that a physical system
possesses, is not preserved for the ground state of the system. Although the
procedure of symmetry breaking is quite clear from the mathematical point of
view, the physical interpretation of the phenomenon is worth to be better
understood. In this note we present a simple and instructive example of the
symmetry breaking in a mechanical system. It demonstrates that the spontaneous
symmetry breaking can occur for the spatially extended solutions in a potential
characterised by a single minimum."
physics,"Computational Physics and Reality: Looking for Some Overlap at the
  Blacksmith Shop","The paper describes two general problems encountered in computational
assignments at the introductory level. First, novice students often treat
computer code as almost magic incantations, and like novices in many fields,
have trouble creating new algorithms or procedures to solve novel problems.
Second, the nature of computational studies often means that the results
generated are interpreted via theoretically devised quantities, which may not
meet a student's internal standards for proof when compared to an experimental
measurement.
  The paper then offers a lab/programming assignment, used in a calculus-based
physics course, which was devised to address these problems. In the assignment,
students created a computational model of the heat flow involved in heating an
iron rod in a blacksmith's forge. After creating the simulation, students
attended a blacksmithing seminar and had a chance to work with iron and take
data on its heating in a coke-fueled forge. On their return to campus, students
revised their computational models in light of their experimental data."
physics,How far can Tarzan jump?,"The tree-based rope swing is a popular recreation facility, often installed
in outdoor areas, giving pleasure to thrill-seekers. In the setting, one drops
down from a high platform, hanging from a rope, then swings at a great speed
like ""Tarzan"", and finally jumps ahead to land on the ground. The question now
arises: How far can Tarzan jump by the swing? In this article, I present an
introductory analysis of the Tarzan swing mechanics, a big pendulum-like swing
with Tarzan himself attached as weight. The analysis enables determination of
how farther forward Tarzan can jump using a given swing apparatus. The
discussion is based on elementary mechanics and, therefore, expected to provide
rich opportunities for investigations using analytic and numerical methods."
physics,"Steady State of a Dissipative Flow-Controlled System and the Maximum
  Entropy Production Principle","A theory to predict the steady state position of a dissipative,
flow-controlled system, as defined by a control volume, is developed based on
the Maximum Entropy (MaxEnt) principle of Jaynes, involving minimisation of a
generalised free energy-like potential. The analysis provides a theoretical
justification of a local, conditional form of the Maximum Entropy Production
(MEP) principle, which successfully predicts the observable properties of many
such systems. The analysis reveals a very different manifestation of the second
law of thermodynamics in steady state flow systems, which {provides a driving
force for} the formation of complex systems, including life."
physics,"Laser-induced alignment and orientation of quantum-state-selected large
  molecules","A strong inhomogeneous static electric field is used to spatially disperse a
supersonic beam of polar molecules, according to their quantum state. We show
that the molecules residing in the lowest-lying rotational states can be
selected and used as targets for further experiments. As an illustration, we
demonstrate an unprecedented degree of laser-induced 1D alignment
$(<\cos^2\theta_{2D}>=0.97)$ and strong orientation of state-selected
iodobenzene molecules. This method should enable experiments on pure samples of
polar molecules in their rotational ground state, offering new opportunities in
molecular science."
physics,"Cryogenic micro-calorimeters for mass spectrometric identification of
  neutral molecules and molecular fragments","We have systematically investigated the energy resolution of a magnetic
micro-calorimeter (MMC) for atomic and molecular projectiles at impact energies
ranging from $E\approx13$ to 150 keV. For atoms we obtained absolute energy
resolutions down to $\Delta E \approx 120$ eV and relative energy resolutions
down to $\Delta E/E\approx10^{-3}$. We also studied in detail the MMC
energy-response function to molecular projectiles of up to mass 56 u. We have
demonstrated the capability of identifying neutral fragmentation products of
these molecules by calorimetric mass spectrometry. We have modeled the MMC
energy-response function for molecular projectiles and conclude that
backscattering is the dominant source of the energy spread at the impact
energies investigated. We have successfully demonstrated the use of a detector
absorber coating to suppress such spreads. We briefly outline the use of MMC
detectors in experiments on gas-phase collision reactions with neutral
products. Our findings are of general interest for mass spectrometric
techniques, particularly for those desiring to make neutral-particle mass
measurements."
physics,3D printed beam splitter for polar neutral molecules,"We describe a macroscopic beam splitter for polar neutral molecules. A
complex electrode structure is required for the beam splitter which would be
very difficult to produce with traditional manufacturing methods. Instead, we
make use of a nascent manufacturing technique: 3D printing of a plastic piece,
followed by electroplating. This fabrication method opens a plethora of avenues
for research, since 3D printing imposes practically no limitations on possible
shapes, and the plating produces chemically robust, conductive construction
elements with an almost free choice of surface material; it has the added
advantage of dramatically reduced production cost and time. Our beam splitter
is an electrostatic hexapole guide that smoothly transforms into two bent
quadrupoles. We demonstrate the correct functioning of this device by
separating a supersonic molecular beam of ND3 into two correlated fractions. It
is shown that this device can be used to implement experiments with
differential detection wherein one of the fractions serves as a probe and the
other as a reference. Reverse operation would allow to merging of two beams of
neutral polar molecules."
physics,"Strong permanent magnet gradient deflector for Stern-Gerlach-type
  experiments on molecular beams","We describe the design, assembly, and testing of a magnet intended to deflect
beams of paramagnetic nanoclusters, molecules, and atoms. It is energized by
high-grade permanent neodymium magnets. This offers a convenient option in
terms of cost, portability, and scalability of the construction, while
providing field and gradient values (1.1 T, 330 T/m) which are fully comparable
with commonly used electromagnet deflectors."
physics,"Experimental validation of a three-dimensional heat transfer model
  within the scala tympani with application to magnetic cochlear implant
  surgery","Magnetic guidance of cochlear implants is a promising technique to reduce the
risk of physical trauma during surgery. In this approach, a magnet attached to
the tip of the implant electrode array is guided within the scala tympani using
a magnetic field. After surgery, the magnet must be detached from the implant
electrode array via localized heating and removed from the scala tympani which
may cause thermal trauma. Objectives: The objective of this work is to
experimentally validate a three-dimensional (3D) heat transfer model of the
scala tympani which will enable accurate predictions of the maximum safe input
power to avoid localized hyperthermia when detaching the magnet from the
implant electrode array. Methods: Experiments are designed using a rigorous
scale analysis and performed by measuring transient temperatures in a
3D-printed scala tympani phantom subjected to a sudden change in its thermal
environment and localized heating via a small heat source. Results: The
measured and predicted temperatures are in good agreement with an error less
than 6$\%$. Conclusions: The validated 3D heat transfer model of the scala
tympani is finally applied to evaluate the maximum safe input power to avoid
localized hyperthermia when detaching the magnet. For the most conservative
case where all boundaries except the insertion opening are adiabatic, the power
required to release the magnet attached to the implant electrode array by 1
mm$^3$ of paraffin is approximately half of the predicted maximum safe input
power. Significance: This work will enable the design of a thermally safe
magnetic cochlear implant surgery procedure."
physics,"An Overview of NRL's NAUTILUS: A Combination SIMS-AMS for Spatially
  Resolved Trace Isotope Analysis","We present a description of the capabilities and performance of the NAval
Ultra-Trace Isotope Laboratory's Universal Spectrometer (NAUTILUS) at the U.S.
Naval Research Laboratory. The NAUTILUS combines secondary ion mass
spectrometry (SIMS) and single-stage accelerator mass spectrometry (SSAMS) into
a single unified instrument for spatially resolved trace element and isotope
analysis. The NAUTILUS instrument is essentially a fully functional SIMS
instrument with an additional molecule-filtering detector, the SSAMS. The
combination of these two techniques mitigates the drawbacks of each and enables
new measurement paradigms for SIMS-like microanalysis. Highlighted capabilities
include molecule-free raster ion imaging for direct spatially resolved analysis
of heterogeneous materials with or without perturbed isotopic compositions. The
NAUTILUS' sensitivity to trace elements is at least 10x better than commercial
SIMS instruments due to near-zero background conditions. We describe the design
and construction of the NAUTILUS, and its performance applied to topics in
nuclear materials analysis, cosmochemistry, and geochemistry."
physics,Faster Than Light ?,"In this paper we present a pedestrian review of the theoretical fact that all
relativistic wave equations possess solutions of arbitrary velocities $0 \leq v
< \infty$. We discuss some experimental evidences of $v \geq c$ transmission of
electromagnetic field configurations and the importance of these facts with
regard to the principle of relativity."
physics,The Thermodynamic Arrow: Puzzles and Pseudo-puzzles,"For more than a century, physics has known of a puzzling conflict between the
T-asymmetry of thermodynamic phenomena and the T-symmetry of the underlying
microphysics on which these phenomena depend. This paper provides a guide to
the current status of this puzzle, distinguishing the central issue from
various issues with which it may be confused. It is shown that there are two
competing conceptions of what is needed to resolve the puzzle of the
thermodynamic asymmetry, which differ with respect to the number of distinct
T-asymmetries they take to be manifest in the physical world. On the preferable
one-asymmetry conception, the remaining puzzle concerns the ordered
distribution of matter in the early universe. The puzzle of the thermodynamic
arrow thus becomes a puzzle for cosmology."
physics,On Symmetry and Conserved Quantities in Classical Mechanics,"This paper expounds the relations between continuous symmetries and conserved
quantities, i.e. Noether's ``first theorem'', in both the Lagrangian and
Hamiltonian frameworks for classical mechanics. This illustrates one of
mechanics' grand themes: exploiting a symmetry so as to reduce the number of
variables needed to treat a problem.
  I emphasise that, for both frameworks, the theorem is underpinned by the idea
of cyclic coordinates; and that the Hamiltonian theorem is more powerful. The
Lagrangian theorem's main ``ingredient'', apart from cyclic coordinates, is the
rectification of vector fields afforded by the local existence and uniqueness
of solutions to ordinary differential equations. For the Hamiltonian theorem,
the main extra ingredients are the asymmetry of the Poisson bracket, and the
fact that a vector field generates canonical transformations iff it is
Hamiltonian."
physics,What Brown saw and you can too,"A discussion is given of Robert Brown's original observations of particles
ejected by pollen of the plant \textit{Clarkia pulchella} undergoing what is
now called Brownian motion. We consider the nature of those particles, and how
he misinterpreted the Airy disc of the smallest particles to be universal
organic building blocks. Relevant qualitative and quantitative investigations
with a modern microscope and with a ""homemade"" single lens microscope similar
to Brown's, are presented."
physics,On the ideal gas law,"The air density on earth decays as a function of altitude $z$ approximately
according to an $\exp(-w\,z/\theta)$-law, where $w$ denotes the weight of a
nitrogen molecule and $\theta=\kB T$ where $k_B$ is a constant and $T$ the
thermodynamic temperature. To derive this law one usually invokes the Boltzmann
factor, itself derived from statistical considerations. We show that this
(barometric) law may be derived solely from the democritian concept of
corpuscles moving in vacuum. We employ a principle of simplicity, namely that
this law is \emph{independent} of the law of corpuscle motion. This view-point
puts aside restrictive assumptions that are source of confusion. Similar
observations apply to the ideal-gas law. In the absence of gravity, when a
cylinder terminated by a piston, containing a single corpuscle and with height
$h$ has temperature $\theta$, the average force that the corpuscle exerts on
the piston is: $\ave{F}=\theta/h$. This law is valid at any temperature, except
at very low temperatures when quantum effects are significant and at very high
temperatures because the corpuscle may then split into smaller parts. It is
usually derived under the assumption that the temperature is proportional to
the corpuscle kinetic energy, or else, from a form of the quantum theory. In
contradistinction, we show that it follows solely from the postulate this it is
independent of the law of corpuscle motion. On the physical side we employ only
the concept of potential energy. A consistent picture is offered leading to the
barometric law when $w\,h\gg\theta$, and to the usual ideal-gas law when
$w\,h\ll\theta$. The mathematics is elementary. The present paper should
accordingly facilitate the understanding of the physical meaning of the
barometric and ideal-gas laws."
physics,Self-oscillation,"Physicists are very familiar with forced and parametric resonance, but
usually not with self-oscillation, a property of certain dynamical systems that
gives rise to a great variety of vibrations, both useful and destructive. In a
self-oscillator, the driving force is controlled by the oscillation itself so
that it acts in phase with the velocity, causing a negative damping that feeds
energy into the vibration: no external rate needs to be adjusted to the
resonant frequency. The famous collapse of the Tacoma Narrows bridge in 1940,
often attributed by introductory physics texts to forced resonance, was
actually a self-oscillation, as was the swaying of the London Millennium
Footbridge in 2000. Clocks are self-oscillators, as are bowed and wind musical
instruments. The heart is a ""relaxation oscillator,"" i.e., a non-sinusoidal
self-oscillator whose period is determined by sudden, nonlinear switching at
thresholds. We review the general criterion that determines whether a linear
system can self-oscillate. We then describe the limiting cycles of the simplest
nonlinear self-oscillators, as well as the ability of two or more coupled
self-oscillators to become spontaneously synchronized (""entrained""). We
characterize the operation of motors as self-oscillation and prove a theorem
about their limit efficiency, of which Carnot's theorem for heat engines
appears as a special case. We briefly discuss how self-oscillation applies to
servomechanisms, Cepheid variable stars, lasers, and the macroeconomic business
cycle, among other applications. Our emphasis throughout is on the energetics
of self-oscillation, often neglected by the literature on nonlinear dynamical
systems."
physics,Maxwell's Demon and its Fallacies Demystified,"A demonic being, introduced by Maxwell, to miraculously create thermal
non-equilibrium and violate the Second law of thermodynamics, has been among
the most intriguing and elusive wishful concepts for over 150 years. Maxwell
and his followers focused on 'effortless gating' a molecule at a time, but
overlooked simultaneous interference of other chaotic molecules, while the
demon exorcists tried to justify impossible processes with misplaced
'compensations' by work of measurements and gate operation, and information
storage and memory erasure with entropy generation. The illusive and persistent
Maxwell's demon fallacies by its advocates, as well as its exorcists, are
scrutinized and resolved here. Based on holistic, phenomenological reasoning,
it is deduced here that a Maxwell's demon operation, against natural forces and
without due work effort to suppress interference of competing thermal particles
while one is selectively gated, is not possible at any scale, since it would be
against the physics of the chaotic thermal motion, the latter without
consistent molecular directional preference for selective timing to be
possible. Maxwell's demon would have miraculous useful effects, but also some
catastrophic consequences."
physics,Maxwell's Demon must remain sebservient to Clausius's statement,"Using classical thermodynamics, we argue that Maxwell's demon loses its
battle against Clausius as any temperature difference or other thermodynamic
forces it creates is immediately compensated by spontaneous counterbalancing
flows that bring about equilibration by slower particles in principle. Being
constrained by these spontaneously generated equilibration processes in which
he actively but unwittingly participates, the demon is incapable of destroying
equilibrium and violating the second law. In fact, our investigation shows that
he is unintentionally designed to support it, and does not alter the
temperature."
physics,"The $a^3Σ^+$ state of KCs revisited: hyperfine structure analysis
  and potential refinement","Laser-induced fluorescence spectra of the
$c^3\Sigma^+(v_{c},J_{c}=N_{c})\rightarrow a^3\Sigma^+(v_{a},N_{a} = J_{c} \pm
1)$ transitions excited from the ground $X^1\Sigma^+$ state of
$^{39}$K$^{133}$Cs molecule were recorded with Fourier-transform spectrometer
IFS125-HR (Bruker) at the highest achievable spectral resolution of 0.0063
cm${}^{-1}$. Systematic study of the hyperfine structure (HFS) of the
$a^3\Sigma^+$ state for levels with $v_{a} \in [0, 27]$ and $N_{a} \in [24,
90]$ shows that the splitting monotonically increases with $v_{a}$. The
spectroscopic study was supported by ab initio calculations of the magnetic
hyperfine interaction in $X^1\Sigma^+$ and $a^3\Sigma^+$ states. The discovered
variation of the electronic matrix elements with the internuclear distance $R$
is in a good agreement with the observed $v_{a}$-dependencies of the HFS.
Overall set of available experimental data on the $a^3\Sigma^+$ state was used
to improve the potential energy curve particularly near a bottom, providing the
refined dissociation energy $D_e$=267.21(1) cm${}^{-1}$. The ab initio HFS
matrix elements, combined with the empirical $X^1\Sigma^+$ and $a^3\Sigma^+$
PECs in the framework of the invented coupled-channel deperturbation model,
reproduce the experimental term values of both ground states within 0.003
cm${}^{-1}$ accuracy up to their common dissociation limit."
physics,"Population Trap in X-ray-induced Ultrafast Nonadiabatic Dynamics of
  Tropone Probed at the O(1\textit{s}) pre-edge","Nonadiabatic transition (NAT) drives a variety of x-ray-induced
photochemistry and photophysics used in nature and various fields. To clarify
the x-ray-induced NAT dynamics, we performed nonadiabatic molecular dynamics
simulations on electronically excited tropone (Tr) dications created by the
carbon $KLL$ normal Auger decay. The Tr$^{2+}$ undergoes the NAT cascade via
10-10$^2$ states with time constants of 200-400 fs. We observed population
traps in the highly excited states in 100 fs during the NAT cascade. The
fingerprint of this population trap can be extracted from C($1s$) edge pump
O($1s$) pre-edge probe femtosecond transient x-ray absorption spectra measured
by the O($1s$) Auger electron yield method (TR-AEYS) using intense narrow band
femtosecond x-ray free electron laser pulses. Our coupled ionization rate
equation model demonstrates that selective and saturable C($1s$)
core-ionization of Tr realizes background-free measurement. These results
indicate that the importance of NAT in x-ray photochemistry and photophysics in
large molecules. The real-time tracking of the NAT dynamics using TR-AEYS shall
be a powerful approach for deeper insight."
physics,Study of Proton Transfer Reaction Dynamics in Pyrrole 2-Carboxyldehyde,"Photophysical and photochemical dynamics of ground state and excited state
proton transfer reaction is reported for Pyrrole 2-Carboxyldehyde (PCL). Steady
state absorption and emission measurements are conducted in PCL. The
theoretical investigation is done by using different quantum mechanical methods
(e.g. Hartree Fock, DFT, MP2, CCSD etc.). The reaction pathway and two
dimensional potential energy surfaces are computed in various level of theory.
A transition state is also reported in gas phase and reaction filed
calculation. It is established that PCL forms different emitting species in
different media. A large Stokes shifted emission band, which is attributed to
species undergoing excited state intramolecular proton transfer, is observed in
hydrocarbon solvent. Intermolecular proton transfer is observed in hydroxylic
polar solvent. Experimental observations yield all possible signatures of
intramolecular and intermolecular proton transfer in excited state of PCL. The
origins of these signatures have been explained successfully using
corresponding quantum mechanical theories."
physics,"Ab initio study of electronic states and radiative properties of the AcF
  molecule","Relativistic coupled-cluster calculations of the ionization potential,
dissociation energy, and excited electronic states under 35,000 cm$^{-1}$ are
presented for the actinium monofluoride (AcF) molecule. The ionization
potential is calculated to be IP$_e=48,866$ cm$^{-1}$, and the ground state is
confirmed to be a closed-shell singlet and thus strongly sensitive to the
$\mathcal{T}$,$\mathcal{P}$-violating nuclear Schiff moment of the Ac nucleus.
Radiative properties and transition dipole moments from the ground state are
identified for several excited states, achieving an uncertainty of $\sim$450
cm$^{-1}$ for the excitation energies. For higher-lying states that are not
directly accessible from the ground state, possible two-step excitation
pathways are proposed. The calculated branching ratios and Franck-Condon
factors are used to investigate the suitability of AcF for direct laser
cooling. The lifetime of the metastable $(1)^3\Delta_1$ state, which can be
used in experimental searches of the electric dipole moment of the electron, is
estimated to be of order 1 ms."
physics,Optical cycling in charged complexes with Ra-N bonds,"The extension of laser cooling and trapping methods to polyatomic molecular
ions, including those with Ra--N bonds, would have advanced scientific
applications such as quantum sensors for fundamental physics, high resolution
spectroscopy, and testing predictions of the Standard Model. The essential
prerequisite for laser coolability is that molecule is able to scatter hundreds
of photons without changing its initial rovibronic state. Thus laser-cooled
molecules exhibit a probability of population leak out of the multitude of
working vibronic levels (``optical leak'') typically less than 10$^{-2}$. This
probability is highly sensitive to small variations of electronic density in
the vicinity of its optical cycling center. In the present work we employed the
Fock space relativistic coupled cluster approach to obtain information on
electronic states and potential energy surfaces of RaNCH$^+$, RaNH$_3^+$ and
RaNCCH$_3^+$ molecular ions. Laser coolability of these species was estimated
through evaluating Frank-Condon factors, and the peculiarities of
unpaired-electron distributions were analyzed to assess coolability from the
point of view of the molecular electronic structure. RaNH$_3^+$ and
RaNCCH$_3^+$ are the first symmetric top molecular ions found to be promising
candidates for direct laser cooling."
physics,Simulation of the liquid targets for molybdenum-99 production,"The efficiency of $^{99}$Mo nuclei trapping by clinoptilolite particles using
Monte Carlo simulation was studied. The simulation showed the carrier particle
traps almost all of the incident $^{99}$Mo nuclei for the photon energies 12-18
MeV. The ratio of the $^{99}$Mo nuclei reaching the carrier to the total number
of $^{99}$Mo nuclei escaping the nanoparticle is below 1.5% in for the photon
energies 12-18 MeV. High specific activity of produced $^{99}$Mo nuclide
requires optimization of the clinoptilolite carrier particles concentration in
the suspension."
physics,A mathematical aid decision tool for RT planning,"It is possible to find the optimized radiation dose per session for a
radiotherapy (RT) treatment, using a population dynamics model. This has
already been done in a previous work for a protocol with 30 sessions and a
fixed dose per session. Extending this model to other protocols, with a
variable number of sessions, we could change the radiation dosage while keeping
the success probability of treatment at its maximum value. This could help the
RT oncology service managers to plan the sequence of patients and treatments
adapting it to the facilities of the oncology service. Besides, if tumor
surrounding tissue is not able to afford a high dosage, it could be useful to
extend the treatment to a higher number of low dose radiation sessions, keeping
an optimal treatment."
physics,"Medical Implications of Space Radiation Exposure Due to Low Altitude
  Polar Orbits","Space radiation research has progressed rapidly in recent years, but there
remain large uncertainties in predicting and extrapolating biological responses
to humans. Exposure to cosmic radiation and Solar Particle Events may pose a
critical health risk to future spaceflight crews and can have a serious impact
to all biomedical aspects of space exploration. The relatively minimal
shielding of the cancelled 1960's Manned Orbiting Laboratory program's space
vehicle and the high inclination polar orbits would have left the crew
susceptible to high exposures of cosmic radiation and high dose-rate SPEs that
are mostly unpredictable in frequency and intensity. In this study, we have
modeled the nominal and off-nominal radiation environment that a MOL-like
spacecraft vehicle would be exposed to during a 30-day mission using high
performance, multi-core computers. Projected doses from a historically large
SPE (e.g. the August 1972 solar event) have been analyzed in the context of the
MOL orbit profile, providing an opportunity to study its impact to crew health
and subsequent contingencies.It is reasonable to presume that future
commercial, government, and military spaceflight missions in low-Earth orbit
will have vehicles with similar shielding and orbital profiles. Studying the
impact of cosmic radiation to the mission's operational integrity and the
health of MOL crewmembers provides an excellent surrogate and case-study for
future commercial and military spaceflight missions."
physics,"Ultrahigh Light Intensification by a Counter-Propagating Breaking Plasma
  Wave - Relativistic Flying Parabolic Mirror","A method to generate ultrahigh intense electromagnetic fields is suggested,
based on the laser pulse compression, carrier frequency upshift and focusing by
a counter-propagating breaking plasma wave, relativistic flying parabolic
mirror. This method allows us to achieve the quantum electrodynamics critical
field (Schwinger limit) with present day laser systems."
physics,Self-pinching of a relativistic electron bunch in a drift tube,"Electron bunches with charge densities $\rho$ of the order of $10^2$ to
$10^3$ [nC/cm$^3$], energies between $20.$ and $100.$ [MeV], peak current
$>100$ [A], bunch lengths between 0.3 and 1.8 [cm], and bunch charge of 2.0 to
$20.$ [nC] are relevant to the design of Free Electron Lasers and future linear
colliders. In this paper we present the results of numerical simulations
performed with a particle in a cell (pic) code of an electron bunch in a drift
tube. The electron bunch has cylindrical symmetry with the $z$-axis oriented in
the direction of motion. The charge density distribution is constant in the
radial and Gaussian in the longitudinal direction, respectively. The electron
bunch experiences both a radial pinch in the middle of the pulse, corresponding
to the peak electron density, and a significant growth of the correlated
emittance. This behavior is explained, and an approximate scaling law is
identified. Comparisons of the results from the pic and PARMELA codes are
presented."
physics,"Gamma-Ray Bursts and the Earth: Exploration of Atmospheric, Biological,
  Climatic and Biogeochemical Effects","Gamma-Ray Bursts (GRBs) are likely to have made a number of significant
impacts on the Earth during the last billion years. We have used a
two-dimensional atmospheric model to investigate the effects on the Earth's
atmosphere of GRBs delivering a range of fluences, at various latitudes, at the
equinoxes and solstices, and at different times of day. We have estimated DNA
damage levels caused by increased solar UVB radiation, reduction in solar
visible light due to $\mathrm{NO_2}$ opacity, and deposition of nitrates
through rainout of $\mathrm{HNO_3}$. For the ``typical'' nearest burst in the
last billion years, we find globally averaged ozone depletion up to 38%.
Localized depletion reaches as much as 74%. Significant global depletion (at
least 10%) persists up to about 7 years after the burst. Our results depend
strongly on time of year and latitude over which the burst occurs. We find DNA
damage of up to 16 times the normal annual global average, well above lethal
levels for simple life forms such as phytoplankton. The greatest damage occurs
at low to mid latitudes. We find reductions in visible sunlight of a few
percent, primarily in the polar regions. Nitrate deposition similar to or
slightly greater than that currently caused by lightning is also observed,
lasting several years. We discuss how these results support the hypothesis that
the Late Ordovician mass extinction may have been initiated by a GRB."
physics,"COWS all tHE way Down (COWSHED) I: Could cow based planetoids support
  methane atmospheres?","More often than not a lunch time conversation will veer off into bizarre and
uncharted territories. In rare instances these frontiers of conversation can
lead to deep insights about the Universe we inhabit. This paper details the
fruits of one such conversation. In this paper we will answer the question: How
many cows do you need to form a planetoid entirely comprised of cows, which
will support a methane atmoosphere produced by the planetary herd? We will not
only present the necessary assumptions and theory underpinning the
cow-culations, but also present a thorough (and rather robust) discussion of
the viability of, and implications for accomplishing, such a feat."
physics,Rogue waters,"In this essay we give an overview on the problem of rogue or freak wave
formation in the ocean. The matter of the phenomenon is a sporadic occurrence
of unexpectedly high waves on the sea surface. These waves cause serious danger
for sailing and sea use. A number of huge wave accidents resulted in damages,
ship losses and people injuries and deaths are known. Now marine researchers do
believe that these waves belong to a specific kind of sea waves, not taken into
account by conventional models for sea wind waves. This paper addresses to the
nature of the rogue wave problem from the general viewpoint based on the wave
process ideas. We start introducing some primitive elements of sea wave physics
with the purpose to pave the way for the further discussion. We discuss linear
physical mechanisms which are responsible for high wave formation, at first.
Then, we proceed with description of different sea conditions, starting from
the open deep sea, and approaching the sea cost. Nonlinear effects which are
able to cause rogue waves are emphasised. In conclusion we briefly discuss the
generality of the physical mechanisms suggested for the rogue wave explanation;
they are valid for rogue wave phenomena in other media such as solid matters,
superconductors, plasmas and nonlinear optics"
physics,"The Energetic Implications of the Time Discretisation in Implementations
  of the A.L.E. Equations","A class of A.L.E. time discretisations which inherit key energetic properties
(nonlinear dissipation in the absence of forcing and long-term stability under
conditions of time dependent loading), irrespective of the time increment
employed, is established in this work. These properties are intrinsic to real
flows and the conventional Navier-Stokes equations.
  A description of an incompressible, Newtonian fluid, which reconciles the
differences between the various schools of A.L.E. thought in the literature is
derived for the purposes of this investigation. The issue of whether these
equations automatically inherit the afore mentioned energetic properties must
first be resolved. In this way natural notions of nonlinear, exponential-type
dissipation in the absence of forcing and long-term stability under conditions
of time dependent loading are also formulated.
  The findings of this analysis have profound consequences for the use of
certain classes of finite difference schemes in the context of deforming
references. It is significant that many algorithms presently in use do not
automatically inherit the fundamental qualitative features of the dynamics.
  The main conclusions are drawn on in the simulation of a driven cavity flow,
a driven cavity flow with various, included rigid bodies, a die-swell problem,
and a Stokes second order wave. The improved, second order accuracy of a new
scheme for the linearised approximation of the convective term is proved for
the purposes of these simulations. A somewhat novel method to generate finite
element meshes automatically about included rigid bodies, and which involves
finite element mappings, is also described."
physics,"Forces at the Sea Bed using a Finite Element Solution of the Mild Slope
  Wave Equation","An algorithm to compute forces at the sea bed from a finite element solution
to the mild slope wave equation is devised in this work. The algorithm is best
considered as consisting of two logical parts: The first is concerned with the
computation of the derivatives to a finite element solution, given the
associated mesh; the second is a bi-quadratic least squares fit which serves to
model the sea bed locally in the vicinity of a node. The force at the sea bed
can be quantified in terms of either lift and drag, the likes of Stokes'
formula or traction. While the latter quantity is the most desireable, the
direct computation of tractions at the sea bed is controversial in the context
of the mild slope wave equation as a result of the irrotationality implied by
the use of potentials. This work ultimately envisages a ``Monte Carlo''
approach using wave induced forces to elucidate presently known heavy mineral
placer deposits and, consequently, to predict the existance of other deposits
which remain as yet undiscovered."
physics,Numerical Verification of the Weak Turbulent Model for Swell Evolution,"The purpose of this article is numerical verification of the theory of weak
turbulence. We performed numerical simulation of an ensemble of nonlinearly
interacting free gravity waves (swell) by two different methods: solution of
primordial dynamical equations describing potential flow of the ideal fluid
with a free surface and, solution of the kinetic Hasselmann equation,
describing the wave ensemble in the framework of the theory of weak turbulence.
  In both cases we observed effects predicted by this theory: frequency
downshift, angular spreading and formation of Zakharov-Filonenko spectrum
$I_{\omega} \sim \omega^{-4}$. To achieve quantitative coincidence of the
results obtained by different methods, one has to supply the Hasselmann kinetic
equation by an empirical dissipation term $S_{diss}$ modeling the coherent
effects of white-capping. Using of the standard dissipation terms from
operational wave predicting model ({\it WAM}) leads to significant improvement
on short times, but not resolve the discrepancy completely, leaving the
question about optimal choice of $S_{diss}$ open. In a long run {\it WAM}
dissipative terms overestimate dissipation essentially."
physics,Effects of anisotropy in geostrophic turbulence,"The Boussinesq model of convection in a flat layer with heating from below is
considered. We analyze the effects of anisotropy caused by rapid rotation in
physical and wave spaces and demonstrate the suppression of energy transfer by
rotation. We also examine the structure of the wave triangle in nonlinear
interaction. The range of parameters is adapted to the models of convection in
the geodynamo."
physics,CIP/multi-moment finite volume method with arbitrary order of accuracy,"This paper presents a general formulation of the CIP/multi-moment finite
volume method (CIP/MM FVM) for arbitrary order of accuracy. Reconstruction up
to arbitrary order can be built on single cell by adding extra derivative
moments at the cell boundary. The volume integrated average (VIA) is updated
via a flux-form finite volume formulation, whereas the point-based derivative
moments are computed as local derivative Riemann problems by either direct
interpolation or approximate Riemann solvers."
physics,A well-balanced meshless tsunami propagation and inundation model,"We present a novel meshless tsunami propagation and inundation model. We
discretize the nonlinear shallow-water equations using a well-balanced scheme
relying on radial basis function based finite differences. The inundation model
relies on radial basis function generated extrapolation from the wet points
closest to the wet-dry interface into the dry region. Numerical results against
standard one- and two-dimensional benchmarks are presented."
physics,"Discrete-element model for the interaction between ocean waves and sea
  ice","We present a discrete element method (DEM) model to simulate the mechanical
behavior of sea ice in response to ocean waves. The interaction of ocean waves
and sea ice can potentially lead to the fracture and fragmentation of sea ice
depending on the wave amplitude and period. The fracture behavior of sea ice is
explicitly modeled by a DEM method, where sea ice is modeled by densely packed
spherical particles with finite size. These particles are bonded together at
their contact points through mechanical bonds that can sustain both tensile and
compressive forces and moments. Fracturing can be naturally represented by the
sequential breaking of mechanical bonds. For a given amplitude and period of
incident ocean wave, the model provides information for the spatial
distribution and time evolution of stress and micro-fractures and the fragment
size distribution. We demonstrate that the fraction of broken bonds, ,
increases with increasing wave amplitude. In contrast, the ice fragment size l
decreases with increasing amplitude. This information is important for the
understanding of breakup of individual ice floes and floe fragment size."
physics,"Non-equilibrium three-dimensional boundary layers at moderate Reynolds
  numbers","Non-equilibrium wall turbulence with mean-flow three-dimensionality is
ubiquitous in geophysical and engineering flows. Under these conditions,
turbulence may experience a counter-intuitive depletion of the turbulent
stresses, which has important implications for modelling and control. Yet,
current turbulence theories have been established mainly for statistically
two-dimensional equilibrium flows and are unable to predict the reduction in
the Reynolds stress magnitude. In the present work, we propose a multiscale
model which explains the response of non-equilibrium wall-bounded turbulence
under the imposition of three-dimensional strain. The analysis is performed via
direct numerical simulation of transient three-dimensional turbulent channels
subjected to a sudden lateral pressure gradient at friction Reynolds numbers up
to 1,000. We show that the flow regimes and scaling properties of the Reynolds
stress are consistent with a model comprising momentum-carrying eddies with
sizes and time scales proportional to their distance to the wall. We further
demonstrate that the reduction in Reynolds stress follows a spatially and
temporally self-similar evolution caused by the relative horizontal
displacement between the core of the momentum-carrying eddies and the flow
layer underneath. Inspection of the flow energetics reveals that this mechanism
is associated with lower levels of pressure-strain correlation which ultimately
inhibits the generation of Reynolds stress. Finally, we assess the ability of
the state-of-the-art wall-modelled large-eddy simulation to predict
non-equilibrium, three-dimensional flows."
physics,"Flooding simulation due to Hurricane Florence in North Carolina with HEC
  RAS","Flooding due to Hurricane Florence led to billions of dollars in damage and
nearly a hundred deaths in North Carolina. These damages and fatalities can be
avoided with proper prevention and preparation. Modelling such flooding events
can provide insight and precaution based on principles of fluid dynamics and
GIS technology. Using topography and other geographic data from USGS, HEC-RAS
can solve the Shallow Water Equations over flooding areas to assist the study
of inundation patterns. Simulation results from HEC-RAS agree with observations
from NOAA in the flooding area studied. Modeled results from specific locations
affected by Hurricane Florence near Neuse River, NC are compared with
observations. While overall pattern of inundation is agreeable between model
results and observations, there are also differences at very specific
locations. Higher resolution topography data and precipitation data over the
flooding area may improve the simulation result and reduce the differences."
physics,Incipient Motion Criteria for a Rigid Sediment Grain on a Rigid Surface,"Criteria for the incipient motion of a rigid body initially resting on a
rigid surface are formulated from first principles in this work. A modified
Coulomb friction model and an associated distribution of reaction forces are
proposed. There exists a surprisingly large category of general motions,
however, which subscribe to a more conventional analysis; an analysis made
possible by identifying so-called ``significant reaction surfaces''. In this
way a model which caters for the majority of combined translations and
rotations is devised. Some introductry results demonstrate the accuracy with
which fluids can be numerically modelled for the purposes of entrainment. This
work is an extension of previous work by the same author."
physics,"Twisting Rolls. An Heuristic Model and 3D Numerical Simulations of
  Vortex Patterns","We connect an appropriate feedback loop to a model of 2D vertical eddy of
airflow which unfolds a wide range of vorticity behavior. Computational fluid
dynamics of the twisted roll display a class of long lifespan 3D vortices. On
the one hand, the infinitely stable columnar vortex simulated describes
waterspouts and tornadoes with extended lifetime. On the other hand, a light
modification of the retroaction exhibits strong similarities to tropical
cyclones. Moreover, we investigate the outcome of the twisting process
vertically shifted. This modelisation leads to the simulation of simultaneous
vortices associated to this other class of 3D vortices with short lifespan. Our
heuristic dynamical systems lay the foundations of a comprehensive modelisation
of vortices since it joins theory and numerical simulations."
physics,"Destabilization of the thermohaline circulation by transient
  perturbations to the hydrological cycle","We reconsider the problem of the stability of the thermohaline circulation as
described by a two-dimensional Boussinesq model with mixed boundary conditions.
We determine how the stability properties of the system depend on the intensity
of the hydrological cycle. We define a two-dimensional parameters' space
descriptive of the hydrology of the system and determine, by considering
suitable quasi-static perturbations, a bounded region where multiple equilibria
of the system are realized. We then focus on how the response of the system to
finite-amplitude surface freshwater forcings depends on their rate of increase.
We show that it is possible to define a robust separation between slow and fast
regimes of forcing. Such separation is obtained by singling out an estimate of
the critical growth rate for the anomalous forcing, which can be related to the
characteristic advective time scale of the system."
physics,"Tsunami generation by dynamic displacement of sea bed due to dip-slip
  faulting","In classical tsunami-generation techniques, one neglects the dynamic sea bed
displacement resulting from fracturing of a seismic fault. The present study
takes into account these dynamic effects. Earth's crust is assumed to be a
Kelvin-Voigt material. The seismic source is assumed to be a dislocation in a
viscoelastic medium. The fluid motion is described by the classical nonlinear
shallow water equations (NSWE) with time-dependent bathymetry. The
viscoelastodynamic equations are solved by a finite-element method and the NSWE
by a finite-volume scheme. A comparison between static and dynamic
tsunami-generation approaches is performed. The results of the numerical
computations show differences between the two approaches and the dynamic
effects could explain the complicated shapes of tsunami wave trains."
physics,"Stochastic Parameterization: Towards a new view of Weather and Climate
  Models","The last decade has seen the success of stochastic parameterizations in
short-term, medium-range and seasonal forecasts: operational weather centers
now routinely use stochastic parameterization schemes to better represent model
inadequacy and improve the quantification of forecast uncertainty. Developed
initially for numerical weather prediction, the inclusion of stochastic
parameterizations not only provides better estimates of uncertainty, but it is
also extremely promising for reducing longstanding climate biases and relevant
for determining the climate response to external forcing. This article
highlights recent developments from different research groups which show that
the stochastic representation of unresolved processes in the atmosphere,
oceans, land surface and cryosphere of comprehensive weather and climate models
(a) gives rise to more reliable probabilistic forecasts of weather and climate
and (b) reduces systematic model bias. We make a case that the use of
mathematically stringent methods for the derivation of stochastic dynamic
equations will lead to substantial improvements in our ability to accurately
simulate weather and climate at all scales. Recent work in mathematics,
statistical mechanics and turbulence is reviewed, its relevance for the climate
problem demonstrated, and future research directions outlined."
physics,"Experimental and numerical study of the propagation of focused wave
  groups in the nearshore zone","The propagation of focused wave groups in intermediate water depth and the
shoaling zone is experimentally and numerically considered in this paper. The
experiments are carried out in a two-dimensional wave flume and wave trains
derived from Pierson-Moskowitz and JONSWAP spectrum are generated. The peak
frequency does not change during the wave train propagation for
Pierson-Moskowitz waves; however, a downshift of this peak is observed for
JONSWAP waves. An energy partitioning is performed in order to track the
spatial evolution of energy. Four energy regions are defined for each spectrum
type. A nonlinear energy transfer between different spectral regions as the
wave train propagates is demonstrated and quantified. Numerical simulations are
conducted using a modified Boussinesq model for long waves in shallow waters of
varying depth. Experimental results are in satisfactory agreement with
numerical predictions, especially in the case of wave trains derived from
JONSWAP spectrum."
physics,Planetary dynamos,"The theory of planetary dynamos and its applications to observed phenomena of
planetary magnetism are outlined. It is generally accepted that convection
flows driven by thermal or compositional buoyancy are the most likely source
for the sustenance of global planetary magnetic fields. While the existence of
dynamos in electrically conducting fluid planetary cores provides constraints
on properties of the latter, the lack of knowledge about time dependences of
the magnetic fields and about their toroidal components together with the
restricted parameter regions accessible to theory have prevented so far a full
understanding of the phenomena of planetary magnetism."
physics,"Parameter dependences of convection driven dynamos in rotating spherical
  fluid shells","For the understanding of planetary and stellar dynamos an overview of the
major parameter dependences of convection driven dynamos in rotating spherical
fluid shells is desirable. Although the computationally accessible parameter
space is limited, earlier work is extended with emphasis on higher Prandtl
numbers and uniform heat flux condition at the outer boundary. The transition
from dynamos dominated by non-axisymmetric components of the magnetic field to
those dominated by the axisymmetric components depends on the magnetic Prandtl
number as well as on the ordinary Prandtl number for higher values of the
rotation parameter $\tau$. The dependence of the transition on the latter
parameter is also discussed. A variety of oscillating dynamos is presented and
interpreted in terms of dynamo waves, standing oscillation or modified
relaxation oscillations."
physics,"Shot noise-mitigated secondary electron imaging with ion count-aided
  microscopy","Modern science is dependent on imaging on the nanoscale, often achieved
through processes that detect secondary electrons created by a highly focused
incident charged particle beam. Scanning electron microscopy is employed in
applications such as critical-dimension metrology and inspection for
semiconductor devices, materials characterization in geology, and examination
of biological samples. With its applicability to non-conducting materials (not
requiring sample coating before imaging), helium ion microscopy (HIM) is
especially useful in the high-resolution imaging of biological samples such as
animal organs, tumor cells, and viruses. However, multiple types of measurement
noise limit the ultimate trade-off between image quality and the incident
particle dose, which can preclude useful imaging of dose-sensitive samples.
Existing methods to improve image quality do not fundamentally mitigate the
noise sources. Furthermore, barriers to assigning a physically meaningful scale
make these modalities qualitative. Here we introduce ion count-aided microscopy
(ICAM), which is a quantitative imaging technique that uses statistically
principled estimation of the secondary electron yield. With a readily
implemented change in data collection, ICAM nearly eliminates the influence of
source shot noise -- the random variation in the number of incident ions in a
fixed time duration. In HIM, we demonstrate 3x dose reduction; based on a good
match between these empirical results and theoretical performance predictions,
the dose reduction factor is larger when the secondary electron yield is
higher. ICAM thus facilitates imaging of fragile samples and may make imaging
with heavier particles more attractive."
physics,MHD Turbulence: Scaling Laws and Astrophysical Implications,"Turbulence is the most common state of astrophysical flows. In typical
astrophysical fluids, turbulence is accompanied by strong magnetic fields,
which has a large impact on the dynamics of the turbulent cascade. Recently,
there has been a significant breakthrough on the theory of magnetohydrodynamic
(MHD) turbulence. For the first time we have a scaling model that is supported
by both observations and numerical simulations. We review recent progress in
studies of both incompressible and compressible turbulence. We compare
Iroshnikov-Kraichnan and Goldreich-Sridhar models, and discuss scalings of
Alfv\'en, slow, and fast waves. We also discuss the completely new regime of
MHD turbulence that happens below the scale at which hydrodynamic turbulent
motions are damped by viscosity. In the case of the partially ionized diffuse
interstellar gas the viscosity is due to neutrals and truncates the turbulent
cascade at $\sim$parsec scales. We show that below this scale magnetic
fluctuations with a shallow spectrum persist and discuss the possibility of a
resumption of the MHD cascade after ions and neutrals decouple. We discuss the
implications of this new insight into MHD turbulence for cosmic ray transport,
grain dynamics, etc., and how to test theoretical predictions against
observations."
physics,"Photodetachment and Test-Particle Simulation Constraints on Negative
  Ions in Solar System Plasmas","Negative ions have been detected in abundance in recent years by spacecraft
across the solar system. These detections were, however, made by instruments
not designed for this purpose and, as such, significant uncertainties remain
regarding the prevalence of these unexpected plasma components. In this
article, the phenomenon of photodetachment is examined and experimentally and
theoretically derived cross-sections are used to calculate photodetachment
rates for a range of atomic and molecular negative ions subjected to the solar
photon spectrum. These rates are applied to negative ions outflowing from
Europa, Enceladus, Titan, Dione and Rhea and their trajectories are traced to
constrain source production rates and the extent to which negative ions are
able to pervade the surrounding space environments. Predictions are also made
for further negative ion populations in the outer solar system with Triton used
as an illustrative example. This study demonstrates how, at increased
heliocentric distances, negative ions can form stable ambient plasma
populations and can be exploited by future missions to the outer solar system."
physics,A magnetic falling-sphere viscometer,"We present a falling-sphere viscometer with a magnetized sphere and fluxgate
magnetometers continuously measuring the magnetic field produced at the sensor
positions by the falling sphere. With a fluid volume of 15 ml and within a few
seconds, we directly measure dynamical viscosities in a range between 200 cP
and 3000 cP with a precision of 3\%."
physics,The Gibbs Paradox,"The Gibbs Paradox is essentially a set of open questions as to how sameness
of gases or fluids (or masses, more generally) are to be treated in
thermodynamics and statistical mechanics. They have a variety of answers, some
restricted to quantum theory (there is no classical solution), some to
classical theory (the quantum case is different). The solution offered here
applies to both in equal measure, and is based on the concept of particle
indistinguishability (in the classical case, Gibbs' notion of 'generic phase').
Correctly understood, it is the elimination of sequence position as a labelling
device, where sequences enter at the level of the tensor (or Cartesian) product
of one-particle state spaces. In both cases it amounts to passing to the
quotient space under permutations. 'Distinguishability', in the sense in which
it is usually used in classical statistical mechanics, is a mathematically
convenient, but physically muddled, fiction."
physics,Bayesian reasoning in cosmology,"We discuss epistemological and methodological aspects of the Bayesian
approach in astrophysics and cosmology. The introduction to the Bayesian
framework is given for a further discussion concerning the Bayesian inference
in physics. The interplay between the modern cosmology, Bayesian statistics,
and philosophy of science is presented. We consider paradoxes of confirmation,
like Goodman's paradox, appearing in the Bayesian theory of confirmation. As in
Goodman's paradox the Bayesian inference is susceptible to some epistemic
limitations in the logic of induction. However Goodman's paradox applied to
cosmological hypotheses seems to be resolved due to the evolutionary character
of cosmology and accumulation new empirical evidences. We argue that the
Bayesian framework is useful in the context of falsificability of quantum
cosmological models, as well as contemporary dark energy and dark matter
problem."
physics,Trouble with Physics?,"This is a review of Lee Smolin's ""The Trouble with Physics"". The main gist of
the review is that the physics of the past three decades has been rich with new
discoveries in a large number of domains. The Standard Model, while providing a
successful framework for the electroweak and strong interactions still needs to
be developed further to fully account fot the mass of strong interaction data
collected over the decades. A multitude of new phenomena have been discovered
however, or predicted theoretically, in the physics of very low temperatures
(e.g. fractional Hall effect, Bose-Einstein condensation) and quantum
macroscopic effects (liquid crystals, high temperature superconductivity), some
of which remain to be fully explained. Therefore if there is any ""Trouble with
Physics"", as implied by the author of this book, it mainly concerns speculative
work on Superstring theory, which may or may not turn out to agree with the
results of observation. The subject as a whole does not appear to be in
trouble."
physics,"Einstein, Sciascia, Majorana, Amaldi, e il Rapporto tra Intellettuali e
  Potere (Einstein, Sciascia, Majorana, Amaldi, and the Relationship of
  Intellectuals with the Power)","In Europe (e.g., in Italy), and in the States, the opinion is widely
spreading that the negative consequences of modern progress are the fault of
""Science"". A lively debate on this topic took place among the famous writer
Leonardo Sciascia and Italian physicists like Edoardo Amaldi and Emilio Segre',
when Sciascia wrote his known book about the disappearance of Ettore Majorana,
a book that presented Majorana (a very reserved theoretical physicist) as an
example of the scientist that keeps his discoveries secret when afraid of
possible evil applications. We wish to contribute now to such a question, since
many special meetings did recently return to it, while celebrating the
centenary of Majorana's birth (2006), or 30 years (2005) from Sciascia's book
publication. It appeared natural to us to start with the figure of Einstein,
who, even if extremely peaceable, supported the atomic bomb construction by his
letter to Roosvelt. We discuss first the significance of part of Einsteins's
scientific work (which flourished in particular one century ago): We seize this
opportunity for presenting a derivation of the ""twins paradox"", so simple that
it has been taught to Senior High School last-year students or University
undergraduate students; all the present work, more in general, is addressed
mainly to them. In the second part of this paper, we analyse the general
meaning of Einstein's contributions to philosophy and pedagogy. The third part
is entirely devoted to our main subject, i.e., to discussing the
""Responsibility of the Intellectuals"". The reader interested chiefly in this
last part, can find it re-expounded in a self-contained way in the Appendix.
More information in the Contents of this article."
physics,Phenomenological Quantum Gravity,"If the history of science has taught us anything, it's that persistence and
creativity makes the once impossible possible. It has long been thought
experimental tests of quantum gravity are impossible. But during the last
decade, several different approaches have been proposed that allow us to test,
if not the fundamental theory of quantum gravity itself, so at least
characteristic features this theory can have. For the first time we can probe
experimentally domains in which quantum physics and gravity cohabit, in spite
of our failure so far to make a convincing marriage of them on a theoretical
level."
physics,Absorption of infra-red radiation by atmospheric molecular cluster-ions,"Protonated water clusters are a common species of atmospheric molecular
cluster-ion, produced by cosmic rays throughout the troposphere and
stratosphere. Under clear-sky conditions or periods of increased atmospheric
ionisation, such as solar proton events, the IR absorption by atmospheric ions
may affect climate through the radiative balance. Fourier Transform Infrared
Spectrometry in a long path cell, of path length 545m, has been used to detect
IR absorption by corona-generated positive molecular cluster-ions. The column
concentration of ions in the laboratory spectroscopy experiment was estimated
to be ~10^13 m-2; the column concentration of protonated atmospheric ions
estimated using a simple model is ~10^14 m-2. Two regions of absorption, at
12.3 and 9.1 um are associated with enhanced ion concentrations. After
filtering of the measured spectra to compensate for spurious signals from
neutral water vapour and residual carbon dioxide, the strongest absorption
region is at 9.5 to 8.8 um (1050 to 1140 cm-1) with a fractional change in
transmissivity of 0.03 plus/minus 0.015, and the absorption at 12.5 to 12.1 um
(800 to 825 cm-1) is 0.015 plus/minus 0.008."
physics,"Double strand breaks in DNA resulting from double-electron-emission
  events","A mechanism of double strand breaking (DSB) in DNA due to the action of two
electrons is considered. These are the electrons produced in the vicinity of
DNA molecules due to ionization of water molecules with a consecutive emission
of two electrons, making such a mechanism possible. This effect qualitatively
solves a puzzle of large yields of DSBs following irradiation of DNA molecules.
The transport of secondary electrons, including the additional electrons, is
studied in relation to the assessment of radiation damage due to incident ions.
This work is a stage in the inclusion of Auger mechanism and like effects into
the multiscale approach to ion-beam cancer therapy."
physics,"From ab initio quantum chemistry to molecular dynamics: The delicate
  case of hydrogen bonding in ammonia","The ammonia dimer (NH3)2 has been investigated using high--level ab initio
quantum chemistry methods and density functional theory (DFT). The structure
and energetics of important isomers is obtained to unprecedented accuracy
without resorting to experiment. The global minimum of eclipsed C_s symmetry is
characterized by a significantly bent hydrogen bond which deviates from
linearity by about 20 degrees. In addition, the so-called cyclic C_{2h}
structure is extremely close in energy on an overall flat potential energy
surface. It is demonstrated that none of the currently available (GGA,
meta--GGA, and hybrid) density functionals satisfactorily describe the
structure and relative energies of this nonlinear hydrogen bond. We present a
novel density functional, HCTH/407+, designed to describe this sort of hydrogen
bond quantitatively on the level of the dimer, contrary to e.g. the widely used
BLYP functional. This improved functional is employed in Car-Parrinello ab
initio molecular dynamics simulations of liquid ammonia to judge its
performance in describing the associated liquid. Both the HCTH/407+ and BLYP
functionals describe the properties of the liquid well as judged by analysis of
radial distribution functions, hydrogen bonding structure and dynamics,
translational diffusion, and orientational relaxation processes. It is
demonstrated that the solvation shell of the ammonia molecule in the liquid
phase is dominated by steric packing effects and not so much by directional
hydrogen bonding interactions. In addition, the propensity of ammonia molecules
to form bifurcated and multifurcated hydrogen bonds in the liquid phase is
found to be negligibly small."
physics,"Extended lifetime of respiratory droplets in a turbulent vapour puff and
  its implications on airborne disease transmission","To quantify the fate of respiratory droplets under different ambient relative
humidities, direct numerical simulations of a typical respiratory event are
performed. We found that, because small droplets (with initial diameter of
10um) are swept by turbulent eddies in the expelled humid puff, their lifetime
gets extended by a factor of more than 30 times as compared to what is
suggested by the classical picture by William F. Wells, for 50% relative
humidity. With increasing ambient relative humidity the extension of the
lifetimes of the small droplets further increases and goes up to around 150
times for 90% relative humidity, implying more than two meters advection range
of the respiratory droplets within one second. Employing Lagrangian statistics,
we demonstrate that the turbulent humid respiratory puff engulfs the small
droplets, leading to many orders of magnitude increase in their lifetimes,
implying that they can be transported much further during the respiratory
events than the large ones. Our findings provide the starting points for larger
parameter studies and may be instructive for developing strategies on
optimizing ventilation and indoor humidity control. Such strategies are key in
mitigating the COVID-19 pandemic in the present autumn and upcoming winter."
physics,"Label-free intratissue activity imaging of alveolar organoids with
  dynamic optical coherence tomography","An organoid is a three-dimensional (3D) in vitro cell culture emulating human
organs. We applied 3D dynamic optical coherence tomography (DOCT) to visualize
the intratissue and intracellular activities of human induced pluripotent stem
cells (hiPSCs)-derived alveolar organoids in normal and fibrosis models. 3D
DOCT data were acquired with an 840-nm spectral domain optical coherence
tomography with axial and lateral resolutions of 3.8 {\mu}m (in tissue) and 4.9
{\mu}m, respectively. The DOCT images were obtained by the
logarithmic-intensity-variance (LIV) algorithm, which is sensitive to the
signal fluctuation magnitude. The LIV images revealed cystic structures
surrounded by high-LIV borders and mesh-like structures with low LIV. The
former may be alveoli with a highly dynamics epithelium, while the latter may
be fibroblasts. The LIV images also demonstrated the abnormal repair of the
alveolar epithelium."
physics,Incoherent x-ray scattering in single molecule imaging,"Imaging of the structure of single proteins or other biomolecules with atomic
resolution would be enormously beneficial to structural biology. X-ray
free-electron lasers generate highly intense and ultrashort x-ray pulses,
providing a route towards imaging of single molecules with atomic resolution.
The information on molecular structure is encoded in the coherent x-ray
scattering signal. In contrast to crystallography there are no Bragg
reflections in single molecule imaging, which means the coherent scattering is
not enhanced. Consequently, a background signal from incoherent scattering
deteriorates the quality of the coherent scattering signal. This background
signal cannot be easily eliminated because the spectrum of incoherently
scattered photons cannot be resolved by usual scattering detectors. We present
an ab initio study of incoherent x-ray scattering from individual carbon atoms,
including the electronic radiation damage caused by a highly intense x-ray
pulse. We find that the coherent scattering pattern suffers from a significant
incoherent background signal at high resolution. For high x-ray fluence the
background signal becomes even dominating. Finally, based on the atomic
scattering patterns, we present an estimation for the average photon count in
single molecule imaging at high resolution. By varying the photon energy from
3.5 keV to 15 keV, we find that imaging at higher photon energies may improve
the coherent scattering signal quality."
physics,Sailing Towards the Stars Close to the Speed of Light,"The authors describe the general motion of radiation-pushed sails accelerated
near the speed of light with directed energy propulsion. Practical applications
of the model are also given, including the interstellar flyby mission to the
Alpha Centauri star system envisioned by the Breakthrough Starshot program. Any
misalignment between the driving light beam and the direction of the sail's
motion is naturally swept away during acceleration toward relativistic speed,
yet leads to a deviation of about 80 A.U. in the case of an initial
misalignment of 1 arc sec for a sail accelerated up to 0.2c toward Alpha
Centauri. Then, the huge proper acceleration felt by the probes (of order 2500
g), the tremendous energy cost (of about 13 kt per probe) for poor efficiency
(of about 3 \%), the trip duration (between 22 and 33 years), the temperature
at thermodynamic equilibrium (about 1500 K), and the time dilation aboard
(about 160-days difference) are all presented and their variation with the
sail's reflectivity is discussed. We also present an application to single
trips within the Solar System using double-stage light sails. A spaceship of
mass 24 tons can start from Earth and stop at Mars in about seven months with a
peak velocity of 30 km/s but at the price of a huge energy cost of about
$5.3\times 10^4$ GWh due to extremely low efficiency of the directed energy
system, around $10^{-4}$ in this low-velocity case."
physics,The Sun Diver: Combining solar sails with the Oberth effect,"A highly reflective sail provides a way to propel a spacecraft out of the
solar system using solar radiation pressure. The closer the spacecraft is to
the Sun when it starts its outward journey, the larger the radiation pressure
and so the larger the final velocity. For a spacecraft starting on the Earth's
orbit, closer proximity can be achieved via a retrograde impulse from a rocket
engine. The sail is then deployed at the closest approach to the Sun. Employing
the so-called Oberth effect, a second, prograde, impulse at closest approach
will raise the final velocity further. Here I investigate how a fixed total
impulse ({\Delta}v) can best be distributed in this procedure to maximize the
sail's velocity at infinity. Once {\Delta}v exceeds a threshold that depends on
the lightness number of the sail (a measure of its sun-induced acceleration),
the best strategy is to use all of the {\Delta}v in the retrograde impulse to
dive as close as possible to the Sun. Below the threshold the best strategy is
to use all of the {\Delta}v in the prograde impulse and thus not to dive at
all. Although larger velocities can be achieved with multi-stage impulsive
transfers, this study shows some interesting and perhaps counter-intuitive
consequences of combining impulses with solar sails."
physics,Solar sail with superconducting circular current-carrying wire,"Background: A solar sail presents a large sheet of low areal density membrane
and is the most elegant propellant-less propulsion system for the future
exploration of the Solar System and beyond. By today the study on sail membrane
deployment strategies has attracted considerable attention.
  Goal: In this work we present an idea of the deployment and stretching of the
circular solar sail. We consider the superconducting current loop attached to
the thin membrane %to develop a new (method) approach of deployment of a solar
sail and and predict that a superconducting current loop can deploy and stretch
the circular solar sail membrane.
  Method: In the framework of a strict mathematical approach based on the
classical electrodynamics and theory of elasticity the magnetic field induced
by the superconducting current loop and elastic properties of a circular solar
sail membrane and wire loop are analyzed. The formulas for the wire and sail
membrane stresses and strains caused by the current in the superconducting wire
are derived.
  Results: The obtained analytical expressions can be applied to a wide range
of solar sail sizes. Numerical calculations for the sail of radius of 5 m to
150 m made of CP1 membrane of the thickness of 3.5 $\mu m$ attached to
Bi$-$2212 superconducting wire with the cross-section radius of 0.5 mm to 10 mm
are presented. Calculations are performed for the engineering current densities
of 100 A/mm$^{2}$ to 1000 A/mm$^{2}$.
  Conclusion: Our calculations demonstrate the feasibility of the proposed idea
for the solar sail deployment for the future exploration of the deep space by
means of the light pressure propellant."
physics,Optimal Pacing for Running 400 m and 800 m Track Races,"Physicists seeking to understand complex biological systems often find it
rewarding to create simple ""toy models"" that reproduce system behavior. Here a
toy model is used to understand a puzzling phenomenon from the sport of track
and field. Races are almost always won, and records set, in 400 m and 800 m
running events by people who run the first half of the race faster than the
second half, which is not true of shorter races, nor of longer. There is
general agreement that performance in the 400 m and 800 m is limited somehow by
the amount of anaerobic metabolism that can be tolerated in the working muscles
in the legs. A toy model of anaerobic metabolism is presented, from which an
optimal pacing strategy is analytically calculated via the Euler-Lagrange
equation. This optimal strategy is then modified to account for the fact that
the runner starts the race from rest; this modification is shown to result in
the best possible outcome by use of an elementary variational technique that
supplements what is found in undergraduate textbooks. The toy model reproduces
the pacing strategies of elite 400 m and 800 m runners better than existing
models do. The toy model also gives some insight into training strategies that
improve performance."
physics,"Ultrafast pulse duration measurement method of near-infrared pulses for
  a broad range of wavelengths using two-photon absorption in a liquid and
  fluorescent dye solution","A novel characterization method to measure the pulse duration of ultrafast
near-IR pulses is introduced, which uses simple tabletop optics, is relatively
inexpensive, and is expected to work in a broad wavelength range. Our
diagnostic tool quantitatively characterizes the laser pulse duration of any
near-IR wavelength assuming a Gaussian pulse shape with a linear chirp. We
negatively prechirp near-IR pulses with a home-built broadband pulse compressor
(BPC) and send this prechirped beam through a cell filled with a low-molar
solution of a fluorescent dye in a liquid. After two-photon absorption, this
dye fluoresces in the visible, and we record this visible signal as a function
of the propagation distance in the liquid cell. We calibrate the group velocity
dispersion (GVD) of our home-built BPC device against the known GVD of the
compressor of our 800 nm laser and confirm this value using geometric
considerations. Now knowing the GVD of BPC and the recorded visible signal for
various amounts of negative chirp, let us extract the smallest pulse duration
of the near-IR pulse from this visible signal. As a useful corollary, our
analysis also enables the direct measurement of the GVD for liquids and the
indirect measurement of the absorption coefficient for liquids in the near-IR
range, in contrast to indirect GVD measurements that rely on methods such as
the double derivative of the refractive index."
physics,"The ""teapot in a city"": a paradigm shift in urban climate modeling","Urban areas are a high-stake target of climate change mitigation and
adaptation measures. To understand, predict and improve the energy performance
of cities, the scientific community develops numerical models that describe how
they interact with the atmosphere through heat and moisture exchanges at all
scales. In this review, we present recent advances that are at the origin of
last decade's revolution in computer graphics, and recent breakthroughs in
statistical physics that extend well established path-integral formulations to
non-linear coupled models. We argue that this rare conjunction of scientific
advances in mathematics, physics, computer and engineering sciences opens
promising avenues for urban climate modeling and illustrate this with coupled
heat transfer simulations in complex urban geometries under complex atmospheric
conditions. We highlight the potential of these approaches beyond urban climate
modeling, for the necessary appropriation of the issues at the heart of the
energy transition by societies."
physics,"Dispersive shallow water wave modelling. Part III: Model derivation on a
  globally spherical geometry","The present article is the third part of a series of papers devoted to the
shallow water wave modelling. In this part, we investigate the derivation of
some long wave models on a deformed sphere. We propose first a suitable for our
purposes formulation of the full Euler equations on a sphere. Then, by applying
the depth-averaging procedure we derive first a new fully nonlinear weakly
dispersive base model. After this step, we show how to obtain some weakly
nonlinear models on the sphere in the so-called Boussinesq regime. We have to
say that the proposed base model contains an additional velocity variable which
has to be specified by a closure relation. Physically, it represents a
dispersive correction to the velocity vector. So, the main outcome of our
article should be rather considered as a whole family of long wave models."
physics,"Dynamical analysis of the nonlinear growth of the m=n=1 resistive
  internal mode","A dynamical analysis is presented that self-consistently takes into account
the motion of the critical layer, in which the magnetic field reconnects, to
describe how the m=n=1 resistive internal kink mode develops in the nonlinear
regime. The amplitude threshold marking the onset of strong nonlinearities due
to a balance between convective and mode coupling terms is identified. We
predict quantitatively the early nonlinear growth rate of the m=n=1 mode below
this threshold."
physics,"Solar and planetary oscillation control on climate change: hind-cast,
  forecast and a comparison with the CMIP5 GCMs","Global surface temperature records (e.g. HadCRUT4) since 1850 are
characterized by climatic oscillations synchronous with specific solar,
planetary and lunar harmonics superimposed on a background warming modulation.
The latter is related to a long millennial solar oscillation and to changes in
the chemical composition of the atmosphere (e.g. aerosol and greenhouse gases).
However, current general circulation climate models, e.g. the CMIP5 GCMs, to be
used in the AR5 IPCC Report in 2013, fail to reconstruct the observed climatic
oscillations. As an alternate, an empirical model is proposed that uses: (1) a
specific set of decadal, multidecadal, secular and millennial astronomic
harmonics to simulate the observed climatic oscillations; (2) a 0.45
attenuation of the GCM ensemble mean simulations to model the anthropogenic and
volcano forcing effects. The proposed empirical model outperforms the GCMs by
better hind-casting the observed 1850-2012 climatic patterns. It is found that:
(1) about 50-60% of the warming observed since 1850 and since 1970 was induced
by natural oscillations likely resulting from harmonic astronomical forcings
that are not yet included in the GCMs; (2) a 2000-2040 approximately steady
projected temperature; (3) a 2000-2100 projected warming ranging between 0.3
$^{o}C$ and 1.6 $^{o}C$, which is significantly lower than the IPCC GCM
ensemble mean projected warming of 1.1 $^{o}C$ to 4.1 $^{o}C$; ; (4) an
equilibrium climate sensitivity to $CO_{2}$ doubling centered in 1.35 $^{o}C$
and varying between 0.9 $^{o}C$ and 2.0 $^{o}C$."
physics,The True-Twin microcalorimeter: a proof-of-concept experiment,"We present a proof-of-concept experiment to realize microwave primary power
standard with a true-twin microcalorimeter. Double feeding line
microcalorimeters are widely used by National Metrology Institutes. A drawback
concerns the system calibration: traditional processes changes measurement
conditions between system characterization and the measurement stage.
Nevertheless, if the feeding lines are made twin, a measurement scheme that
avoids separate characterization can be applied, equations simplify and time
consumption is halved. Here we demonstrates the feasibility of the idea. The
result of an effective efficiency spectroscopy of a thermoelectric power sensor
is compared with figures obtained with well established methods."
physics,"Perspective: The dusty plasma experiments a learning tool for physics
  graduate students","The plasma is an ionized gas that responses collectively to any external (or
internal) perturbations. Introducing micron-sized solid dust grains into plasma
makes it more interesting. The solid grains acquire large negative charges on
their surface and exhibits collective behavior similar to the ambient plasma
medium. Some remarkable features of the charged dust grain medium (dusty
plasma) allow us to use it as a model system to understand some complex
phenomena at a microscopic level. In this perspective paper, the author
highlights the role of dusty plasma experiments as a learning tool at
undergraduate and post-graduate physics programs. The students could have great
opportunities to understand some basic physical phenomena as well as to learn
many advanced data analysis tools and techniques by performing dusty plasma
experiments. How a single dusty plasma experimental device at a physics
laboratory can help undergraduate and post-graduate students in the learning
process is discussed."
physics,"Strong-field ionization and fragmentation of large, gas-phase clusters
  in the few-cycle domain","Intense 3-cycle pulses (10 fs) of 800 nm laser light are utilized to measure
energy distributions of ions emitted following Coulomb explosion of Ar$_n$
clusters ($n$=400-900) upon their irradiation by peak intensitis of
5$\times$10$^{14}$ W cm$^{-2}$. The 3-cycle pulses do not afford the cluster
sufficient time to undergo Coulomb-driven expansion, resulting in overall
dynamics that appear to be very different to those in the many-pulse regime.
The peak ion energies are much lower than those obtained when 100 fs pulses of
the same intensity are used; they are almost independent of the size of the
cluster (over the range 400-900 atoms). Ion yields are a factor of 20 larger in
the direction that is perpendicular to the laser polarization vector than along
it. This unexpected anisotropy is qualitatively rationalized using molecular
dynamics calculations in terms of shielding by an electronic charge cloud
within the cluster that is spatially asymmetric."
physics,"Ionization and Coulomb explosion of Xenon clusters by intense, few-cycle
  laser pulses","Intense, ultrashort pulses of 800 nm laser light (12 fs, $\sim$4 optical
cycles) of peak intensity 5$\times$10$^{14}$ W cm$^{-2}$ have been used to
irradiate gas-phase Xe$_n$ clusters ($n$=500-25,000) so as to induce multiple
ionization and subsequent Coulomb explosion. Energy distributions of exploding
ions are measured in the few-cycle domain that does not allow sufficient time
for the cluster to undergo Coulomb-driven expansion. This results in overall
dynamics that appear to be significantly different to those in the many-cycle
regime. One manifestation is that the maximum ion energies are measured to be
much lower than those obtained when longer pulses of the same intensity are
used. Ion yields are cluster-size independent but polarization dependent in
that they are significantly larger when the polarization is perpendicular to
the detection axis than along it. This unexpected behavior is qualitatively
rationalized in terms of a spatially anisotropic shielding effect induced by
the electronic charge cloud within the cluster."
physics,"Research towards high-repetition rate laser-driven X-ray sources for
  imaging applications","Laser wakefield acceleration of electrons represents a basis for several
types of novel X-ray sources based on Thomson scattering or betatron radiation.
The latter provides a high photon flux and a small source size, both being
prerequisites for high-quality X-ray imaging. Furthermore, proof-of-principle
experiments have demonstrated its application for tomographic imaging. So far
this required several hours of acquisition time for a complete tomographic data
set. Based on improvements to the laser system, detectors and reconstruction
algorithms, we were able to reduce this time for a full tomographic scan to 3
minutes. In this paper, we discuss these results and give a prospect to future
imaging systems."
physics,"Experimental demonstration of mice tumor control with a
  laser-accelerated high-energy electron radiotherapy prototype","Radiotherapy using very-high-energy electron (VHEE) beams (50-300 MeV) has
attracted considerable attention due to its advantageous dose deposition
characteristics, enabling deep penetration and the potential for ultra-high
dose rate treatment. One promising approach to compactly delivering these high
energy electron beams in a cost-effective manner is laser wakefield
acceleration (LWFA), which offers ultra-strong accelerating gradients. However,
the transition from this concept to a functional machine intended for tumor
treatment is still being investigated. Here we present the first self-developed
prototype for LWFA-based VHEE radiotherapy, exhibiting high compactness
(occupying less than 5 square meters) and high operational stability (validated
over a period of one month). Subsequently, we employed this device to irradiate
a tumor implanted in a mouse model. Following a dose delivery of $5.8\pm0.2$ Gy
with precise tumor conformity, all irradiated mice exhibited pronounced control
of tumor growth. For comparison, this tumor-control efficacy was similar to
that achieved using commercial X-ray radiotherapy equipment operating at
equivalent doses. These results demonstrate the potential of a compact
laser-driven VHEE system for preclinical studies involving small animal models
and its promising prospects for future clinical translation in cancer therapy."
physics,Momentum transfer to small particles by aloof electron beams,"The force exerted on nanoparticles and atomic clusters by fast passing
electrons like those employed in transmission electron microscopes are
calculated and integrated over time to yield the momentum transferred from the
electrons to the particles. Numerical results are offered for metallic and
dielectric particles of different sizes (0-500 nm in diameter) as well as for
carbon nanoclusters. Results for both linear and angular momentum transfers are
presented. For the electron beam currents commonly employed in electron
microscopes, the time-averaged forces are shown to be comparable in magnitude
to laser-induced forces in optical tweezers. This opens up the possibility to
study optically-trapped particles inside transmission electron microscopes."
physics,The Gravity Tunnel in a Non-Uniform Earth,"How long does it take to fall down a tunnel through the center of the Earth
to the other side? Assuming a uniformly dense Earth, it would take 42 minutes,
but this assumption has not been validated. This paper examines the gravity
tunnel without this restriction, using the internal structure of the Earth as
ascertained by seismic data, and the dynamics are solved numerically. The time
taken to fall along the diameter is found to be 38 rather than 42 minutes. The
time taken to fall along a straight line between any two points is no longer
independent of distance, but interpolates between 42 minutes for short trips
and 38 minutes for long trips. The brachistochrone path (minimizing the fall
time between any two points) is similar to the uniform density solution, but
tends to reach a greater maximum depth and takes less time to traverse.
Although the assumption of uniform density works well in many cases, the
simpler assumption of a constant gravitational field serves as a better
approximation to the true results."
physics,"Improving cold atmospheric pressure plasma efficacy on breast cancer
  cells control-ability and mortality by using vitamin C and static magnetic
  field","Since the last decades, there have been numerous reports about the
interaction of magnetic field (MF) and cold atmospheric plasma (CAP) with the
biological systems, separately. In this manuscript, we have investigated the
combined effect of CAP with the static magnetic field (SMF) as an effective
method for cancer cells treatment. MDA-MB-231 breast cancer cells were cultured
and treated with CAP in different input power and different exposure time in
the presence and absence of the SMF. Vitamin C is used in medium, and cell
viability is investigated in the presence and absence of this antioxidant
compound. The MTT assay has been employed to measure cell survival, and then
T-test and one-way ANOVA are used to assess the significance level of
quantitative data. In order to determine the migration rate of cancer cells,
wound healing assay has been carried out. Results show that presence of the SMF
and vitamin C as well as increasing the input power has a significant role on
the attenuation of the survival and migration rate of the cells. The results of
the present investigation will greatly contribute to improve the CAP efficiency
in cancer therapy through using the SMF and vitamin C as a complement to
conventional CAP therapies."
physics,Ultrafast dephasing in hydrogen-bonded pyridine-water mixtures,"Hydrogen-bonded mixtures with varying concentration are a complicated
networked system that demands a detection technique with both time and
frequency resolutions. Hydrogen-bonded pyridine-water mixtures are studied by a
time-frequency resolved coherent Raman spectroscopic technique. Femtosecond
broadband dual-pulse excitation and delayed picosecond probing provide
sub-picosecond time resolution in the mixtures temporal evolution. For
different pyridine concentrations in water, asymmetric blue versus red shifts
(relative to pure pyridine spectral peaks) were observed by simultaneously
recording both the coherent anti-Stokes and Stokes Raman spectra. Macroscopic
coherence dephasing times for the perturbed pyridine ring modes were observed
in ranges of 0.9 - 2.6 picoseconds for both 18 and 10 cm-1 broad probe pulses.
For high pyridine concentrations in water, an additional spectral broadening
(or escalated dephasing) for a triangular ring vibrational mode was observed.
This can be understood as a result of ultrafast collective emissions from
coherently excited ensemble of pairs of pyridine molecules bound to water
molecules."
physics,"Uncertainty amplification due to density/refractive-index gradients in
  volumetric PTV and BOS experiments","We theoretically analyze the effect of density/refractive-index gradients on
the measurement precision of Volumetric Particle Tracking Velocimetry (V-PTV)
and Background Oriented Schlieren (BOS) experiments by deriving the Cramer-Rao
lower bound (CRLB) for the 2D centroid estimation process. A model is derived
for the diffraction limited image of a particle or dot viewed through a medium
containing density gradients that includes the effect of various experimental
parameters such as the particle depth, viewing direction and f-number. Using
the model we show that non-linearities in the density gradient field lead to
blurring of the particle/dot image. This blurring amplifies the effect of image
noise on the centroid estimation process, leading to an increase in the CRLB
and a decrease in the measurement precision. The ratio of position
uncertainties of a dot in the reference and gradient images is a function of
the ratio of the dot diameters and dot intensities. We term this parameter the
Amplification Ratio (AR), and we propose a methodology for estimating the
position uncertainties in tracking-based BOS measurements. The theoretical
predictions of the particle/dot position estimation variance from the CRLB are
compared to ray tracing simulations with good agreement. The uncertainty
amplification is also demonstrated on experimental BOS images of flow induced
by a spark discharge, where we show that regions of high amplification ratio
correspond to regions of density gradients. This analysis elucidates the
dependence of the position error on density and refractive-index gradient
induced distortion parameters, provides a methodology for accounting its effect
on uncertainty quantification and provides a framework for optimizing
experiment design."
physics,"Singlet oxygen luminescence detection with a fiber-coupled
  superconducting nanowire single-photon detector","Direct monitoring of singlet oxygen (1O2) luminescence is a particularly
challenging infrared photodetection problem. 1O2, an excited state of the
oxygen molecule, is a crucial intermediate in many biological processes. We
employ a low noise superconducting nanowire single-photon detector to record
1O2 luminescence at 1270 nm wavelength from a model photosensitizer (Rose
Bengal) in solution. Narrow band spectral filtering and chemical quenching is
used to verify the 1O2 signal, and lifetime evolution with the addition of
protein is studied. Furthermore, we demonstrate the detection of 1O2
luminescence through a single optical fiber, a marked advance for dose
monitoring in clinical treatments such as photodynamic therapy."
physics,Electric quadrupole transitions in carbon dioxide,"Recent advances in the high sensitivity spectroscopy have made it possible,
in combination with accurate theoretical predictions, to observe for the first
time very weak electric quadrupole transitions in a polar polyatomic molecule
of water. Here we present accurate theoretical predictions of the complete
quadrupole ro-vibrational spectrum of a non-polar molecule CO$_2$, important in
atmospheric and astrophysical applications. Our predictions are validated by
recent cavity enhanced absorption spectroscopy measurements and are used to
assign few weak features in the recent ExoMars ACS MIR spectroscopic
observations of the martian atmosphere. Predicted quadrupole transitions appear
in some of the mid-infrared CO$_2$ and water vapor transparency regions, making
them important for detection and characterization of the minor absorbers in
water- and CO$_2$-rich environments, such as present in the atmospheres of
Earth, Venus and Mars."
physics,Theoretical and Experimental Studies on Steady-state Microbunching,"Particle accelerators as photon sources are advanced tools in studying the
structure and dynamical properties of matter. The present workhorses of these
sources are storage ring-based synchrotron radiation facilities and linear
accelerator-based free-electron lasers, delivering light with high repetition
rate and high peak brilliance (power), respectively. The steady-state
microbunching (SSMB) mechanism was proposed to bridge the gap of these two
kinds of sources to generate high-average-power, high-repetition-rate coherent
radiation in an electron storage ring. Such a novel light source promises new
possibilities for accelerator photon science and industry applications, for
example in ultra-high-energy-resolution angle-resolved photoemission
spectroscopy and extreme ultraviolet lithography. The six orders of magnitude
extrapolation of the electron bunch length in an SSMB storage ring compared to
that of a conventional ring provides tremendous opportunities for accelerator
physics research.
  This dissertation is devoted to the theoretical and experimental
investigations of SSMB, with important results achieved. The work presented can
be summarized as: first, how to realize SSMB; second, what radiation
characteristics can we obtain from the formed SSMB; and third, experimentally
demonstrate the working mechanism of SSMB in a real machine."
physics,"A novel hybrid microdosimeter for radiation field characterization based
  on TEPC detector and LGADs tracker: a feasibility study","In microdosimetry, lineal energies y are calculated from energy depositions
$\epsilon$ inside the microdosimeter divided by the mean chord length, whose
value is based on geometrical assumptions on both the detector and the
radiation field. This work presents an innovative two-stages hybrid detector
(HDM: hybrid detector for microdosimetry) composed by a Tissue Equivalent
Proportional Counter (TEPC) and a silicon tracker made of 4 Low Gain Avalanche
Diode (LGAD). This design provides a direct measurement of energy deposition in
tissue as well as particles tracking with a submillimeter spatial resolution.
The data collected by the detector allow to obtain the real track length
traversed by each particle in the TEPC and thus estimates microdosimetry
spectra without the mean chord length approximation. Using Geant4 toolkit, we
investigated HDM performances in terms of detection and tracking efficiencies
when placed in water and exposed to protons and carbon ions in the therapeutic
energy range. The results indicate that the mean chord length approximation
underestimate particles with short track, which often are characterized by a
high energy deposition and thus can be biologically relevant. Tracking
efficiency depends on the LGAD configurations: 34 strips sensors have a higher
detection efficiency but lower spatial resolution than 71 strips sensors.
Further studies will be performed both with Geant4 and experimentally to
optimize the detector design on the bases of the radiation field of interest.
The main purpose of HDM is to improve the assessment of the radiation
biological effectiveness via microdosimetric measurements, exploiting a new
definition of the lineal energy ($y_{T}$), defined as the energy deposition
$\epsilon$ inside the microdosimeter divided by the real track length of the
particle."
physics,"New Linear Theory of Hydrodynamic Instability of the Hagen-Poiseuille
  Flow","New condition Re>Re_th_min=124 of linear (exponential) instability of the
Hagen-Poisseuille (HP) with respect to extremely small by magnitude
axially-symmetric disturbances of the tangential component of the velocity
field is obtained. For this, disturbances must necessarily have quasi-periodic
longitude variability (not representable as a Fourier series or integral) along
the pipe axis that complies with experimental data and differs from the usually
considered idealized case of pure periodic disturbances for which HP flow is
stable for arbitrary large Reynolds numbers Re. Obtained minimal threshold
Reynolds number is related to the spatial structure of disturbances (having two
radial modes with non-commensurable longitudinal periods) in which irrational
value p=1.58 of the ratio of the two longitudinal periods is close to the value
of the ""golden ratio"" equal to 1.618."
physics,Continuous-Wave Cavity Ring-Down Polarimetry,"We present a new cavity-based polarimetric scheme for highly sensitive and
time-resolved measurements of birefringence and dichroism, linear and circular,
that employs rapidly-pulsed single-frequency CW laser sources and extends
current cavity-based spectropolarimetric techniques. We demonstrate how the use
of a CW laser source allows for gains in spectral resolution, signal intensity
and data acquisition rate compared to traditional pulsed-based cavity ring-down
polarimetry (CRDP). We discuss a particular CW-CRDP modality that is different
from intensity-based cavity-enhanced polarimetric schemes as it relies on the
determination of the polarization-rotation frequency during a ring-down event
generated by large intracavity polarization anisotropies. We present the
principles of CW-CRDP and validate the applicability of this technique for
measurement of the non-resonant Faraday effect in solid SiO$_2$ and CeF$_3$ and
gaseous butane. We give a general analysis of the fundamental sensitivity
limits for CRDP techniques and show how the presented frequency-based
methodology alleviates the requirement for high finesse cavities to achieve
high polarimetric sensitivities, and, thus, allows for the extension of
cavity-based polarimetric schemes into different spectral regimes but most
importantly renders the CW-CRDP methodology particularly suitable for robust
portable polarimetric instrumentations."
physics,Current Distribution on Capacitive Electrode-Electrolyte Interfaces,"The distribution of electric current on an electrode surface in electrolyte
varies with time due to charge accumulation at a capacitive interface, as well
as due to electrode kinetics and concentration polarization in the medium.
Initially, the potential at the electrode-electrolyte interface is uniform,
resulting in a non-uniform current distribution due to the uneven ohmic drop of
the potential in the medium. Over time, however, the non-uniform current
density causes spatially varying rate of the charge accumulation at the
interface, breaking down its equipotentiality. We developed an analytical model
to describe such transition at a capacitive interface when the current is below
the mass-transfer limitation, and demonstrated that the steady distribution of
the current is achieved when the current density is proportional to the
capacitance per unit area, which leads to linear voltage ramp at the electrode.
More specific results regarding the dynamics of this transition are provided
for a disk electrode, along with an experimental validation of the theoretical
result. These findings are important for many electrochemical applications, and
in particular, for proper design of the electro-neural interfaces."
physics,A New Method of Atmospheric Reentry for Space Ships,"In recent years, industry has produced high-temperature fiber and whiskers.
The author examined the atmospheric reentry of the USA Space Shuttles and
proposed the use of high temperature tolerant parachute for atmospheric air
braking. Though it is not large, a light parachute decreases Shuttle speed from
8 km/s to 1 km/s and Shuttle heat flow by 3 - 4 times. The parachute surface is
opened with backside so that it can emit the heat radiation efficiently to
Earth-atmosphere. The temperature of parachute is about 1000 - 1300 C. The
carbon fiber is able to keep its functionality up to a temperature of 1500 -
2000 C. There is no conceivable problem to manufacture the parachute from
carbon fiber. The proposed new method of braking may be applied to the old
Space Shuttles as well as to newer spacecraft designs."
physics,Optimal Solid Space Tower,"Theory and computations are provided for building of optimal (minimum weight)
solid space towers (mast) up to one hundred kilometers in height. These towers
can be used for tourism; scientific observation of space, observation of the
Earth surface, weather and upper atmosphere experiment, and for radio,
television, and communication transmissions. These towers can also be used to
launch spaceships and Earth satellites.
  These macroprojects are not expensive. They require strong hard material
(steel). Towers can be built using present technology. Towers can be used (for
tourism, communication, etc.) during the construction process and provide
self-financing for further construction. The tower design does not require
human work at high altitudes; the tower is separated into sections; all
construction can be done at the Earth surface.
  The transport system for a tower consists of a small engine (used only for
friction compensation) located at the Earth surface.
  Problems involving security, control, repair, and stability of the proposed
towers are addressed in other cited publications."
physics,Upper Bound on Implantable Antennas Considering Ohmic Loss,"A hybrid approach for the computation of performance limitations for
implanted antennas is presented, taking radiation efficiency as the optimized
metric. Ohmic loss in the antenna and surrounding tissue are both considered.
The full-wave interaction of all parts of the system is taken into account. The
method is thoroughly tested on a realistic implanted antenna design that is
treated both experimentally and as a model in a commercial electromagnetic
solver. A great agreement is reported. In addition, the fundamental bounds on
radiation efficiency are compared to the performance of a loop and a dipole
antenna showing the importance of various loss mechanisms during the designs.
The trade-off between tissue loss and antenna ohmic loss indicates critical
points in which the optimal solution drastically changes and in which the real
designs should change their topology."
physics,The Preferred System of Reference Reloaded,"According to Karl Popper assumptions are statements used to construct
theories. During the construction of a theory whether the assumptions are
either true or false turn out to be irrelevant in view of the fact that,
actually, they gain their scientific value when the deductions derived from
them suffice to explain observations. Science is enriched with assumptions of
all kinds and physics is not exempted. Beyond doubt, some assumptions have been
greatly beneficial for physics. They are usually embraced based on the kind of
problems expected to be solved in a given moment of a science. Some have been
quite useful and some others are discarded in a given moment and reconsidered
in a later one. An illustrative example of this is the conception of light;
first, according to Newton, as particle; then, according to Huygens, as wave;
and then, again, according to Einstein, as particle. Likewise, once, according
to Newton, a preferred system of reference (PSR) was assumed; then, according
to Einstein, rejected; and then, here the assumption is reconsidered. It is
claimed that the assumption that there is no PSR can be fundamentally wrong."
physics,"Hamilton, Hamiltonian Mechanics, and Causation","I show how Hamilton's philosophical commitments led him to a causal
interpretation of classical mechanics. I argue that Hamilton's metaphysics of
causation was injected into his dynamics by way of a causal interpretation of
force. I then detail how forces remain indispensable to both Hamilton's
formulation of classical mechanics and what we now call Hamiltonian mechanics
(i.e., the modern formulation). On this point, my efforts primarily consist of
showing that the orthodox interpretation of potential energy is the
interpretation found in Hamilton's work. Hamilton called the potential energy
function the force-function because he believed that it represents forces at
work in the world. Multifarious non-historical arguments for this orthodox
interpretation of potential energy are provided, and matters are concluded by
showing that in classical Hamiltonian mechanics, facts about potential energies
of systems are grounded in facts about forces. Thus, if one can tolerate the
view that forces are causes of motions, then Hamilton provides one with a road
map for transporting causation into one of the most mathematically
sophisticated formulations of classical mechanics, viz., Hamiltonian mechanics."
physics,The Theory of Relativity - Galileo's Child,"We determine the Lorentz transformations and the kinematic content and
dynamical framework of special relativity as purely an extension of Galileo's
thoughts. No reference to light is ever required: The theories of relativity
are logically independent of any properties of light. The thoughts of Galileo
are fully realized in a system of Lorentz transformations with a parameter
1/c^2, some undetermined, universal constant of nature; and are realizable in
no other. Isotropy of space plays a deep and pivotal role in all of this, since
here three-dimensional space appears at first blush, and persists until the
conclusion: Relativity can never correctly be fully developed in just one
spatial dimension."
physics,"Improving the understandability of the next edition of the International
  System of Units (SI) by focusing on its conceptual structure","The International System of Units (SI) is fundamental for the social, and not
only the scientific, role of metrology, and as such its understandability is a
crucial issue. According to the current draft of the new SI Brochure, the next
edition of the SI will be significantly more complex in its conceptual
structure than the previous ones. Identifying a strategy for effectively
communicating its main contents is then a worthwhile endeavor, in order to
increase the acceptance and thus the sustainability of the SI itself. Our
proposal is to focus on the semantic structure of the definitions: this is
instrumental to the awareness campaigns recommended by the General Conference
on Weights and Measures to make the next edition of the SI understandable by a
diverse readership without compromising scientific rigor."
physics,"Group and phase velocities in the free-surface visco-potential flow: new
  kind of boundary layer induced instability","Water wave propagation can be attenuated by various physical mechanisms. One
of the main sources of wave energy dissipation lies in boundary layers. The
present work is entirely devoted to thorough analysis of the dispersion
relation of the novel visco-potential formulation. Namely, in this study we
relax all assumptions of the weak dependence of the wave frequency on time. As
a result, we have to deal with complex integro-differential equations that
describe transient behaviour of the phase and group velocities. Using numerical
computations, we show several snapshots of these important quantities at
different times as functions of the wave number. Good qualitative agreement
with previous study [Dutykh2009] is obtained. Thus, we validate in some sense
approximations made anteriorly. There is an unexpected conclusion of this
study. According to our computations, the bottom boundary layer creates
disintegrating modes in the group velocity. In the same time, the imaginary
part of the phase velocity remains negative for all times. This result can be
interpreted as a new kind of instability which is induced by the bottom
boundary layer effect."
physics,"On the relevance of the dam break problem in the context of nonlinear
  shallow water equations","The classical dam break problem has become the de facto standard in
validating the Nonlinear Shallow Water Equations (NSWE) solvers. Moreover, the
NSWE are widely used for flooding simulations. While applied mathematics
community is essentially focused on developing new numerical schemes, we tried
to examine the validity of the mathematical model under consideration. The main
purpose of this study is to check the pertinence of the NSWE for flooding
processes. From the mathematical point of view, the answer is not obvious since
all derivation procedures assumes the total water depth positivity. We
performed a comparison between the two-fluid Navier-Stokes simulations and the
NSWE solved analytically and numerically. Several conclusions are drawn out and
perspectives for future research are outlined."
physics,New Results on the Thermodynamical Properties of the Climate System,"In this paper we exploit two equivalent formulations of the average rate of
material entropy production in a planetary system to propose an approximate
splitting between contributions due to vertical and eminently horizontal
processes. Our approach is based only upon 2D radiative fields at the surface
and at the top of atmosphere of a general planetary body. Using 2D fields at
the top of atmosphere alone, we derive lower bounds to the rate of material
entropy production and to the intensity of the Lorenz energy cycle. By
introducing a measure of the efficiency of the planetary system with respect to
horizontal thermodynamical processes, we provide insight on a previous
intuition on the possibility of defining a baroclinic heat engine extracting
work from the meridional heat flux. The approximate formula of the material
entropy production is verified and used for studying the global thermodynamic
properties of climate models (CMs) included in the PCMDI/CMIP3 dataset in
pre-industrial climate conditions. It is found that about 90% of the material
entropy production is due to vertical processes such as convection, whereas the
large scale meridional heat transport contributes only about 10%. The total
material entropy production is typically 55 mWK-1m-2, with discrepancies of the
order of 5% and CMs' baroclinic efficiencies are clustered around 0.055. When
looking at the variability and co-variability of the considered thermodynamical
quantities, the agreement among CMs is worse, suggesting that the description
of feedbacks is more uncertain."
physics,When physics meets biology: a less known Feynman,"We discuss a less known aspect of Feynman's multifaceted scientific work,
centered about his interest in molecular biology, which came out around 1959
and lasted for several years. After a quick historical reconstruction about the
birth of molecular biology, we focus on Feynman's work on genetics with Robert
S. Edgar in the laboratory of Max Delbruck, which was later quoted by Francis
Crick and others in relevant papers, as well as in Feynman's lectures given at
the Hughes Aircraft Company on biology, organic chemistry and microbiology,
whose notes taken by the attendee John Neer are available. An intriguing
perspective comes out about one of the most interesting scientists of the XX
century."
physics,High resolution stopwatch for cents,"A very low-cost, easy-to-make stopwatch is presented to support various
experiments in mechanics. The high-resolution stopwatch is based on two
photodetectors connected directly to the microphone input of the sound card. A
dedicated free open-source software has been developed and made available to
download. The efficiency is demonstrated by a free fall experiment."
physics,"Efficient Sound Card Based Experimention At Different Levels Of Natural
  Science Education","Sound cards, which count as standard equipment in today's computers, can be
turned into measurement tools, making experimentation very efficient and cheap.
The chief difficulties to overcome are the lack of proper hardware interfacing
and processing software. Sound-card experimentation becomes really viable only
if we demonstrate how to connect different sensors to the sound card and
provide suitable open-source software to support the experiments. In our talk,
we shall present a few applications of sound cards in measurements: photogates,
stopwatches and an example of temperature measurement and registration. We also
provide the software for these applications."
physics,Bi Event Timer for Physics Lab,"Ubiquitously during experiments one encounters a situation where time lapse
between two events has to measured. For example during the oscillations of a
pendulum or a vibrating reed, the powering of a lamp and achieving of its full
intensity. The powering of a relay and the closure of its contacts etc.
Situations like these call for a time measuring device between two events.
Hence this article describes a general Bi-Event timer that can be used in a
physics lab for ubiquitous time lapse measurements during experiments. These
measurements in turn can be used to interpret other parameters like velocity,
acceleration etc. The timer described here is simple to build and accurate in
performance. The Bi-event occurence can be applied as a signal to the inputs of
the timer either on separate lines or along a single path in series as voltage
pulses."
physics,"An intermediate-level physics laboratory: A system of two coupled
  oscillators with low-cost accelerometers","We describe an intermediate-level physics experiment beyond the first-year,
which uses versatile, low-cost accelerometers (Wiimotes for the Nintendo Wii
gaming system) and scientific-computing software for numerical data analysis.
It is designed to help students to develop better understanding of a system of
coupled oscillators and Fourier transform."
physics,A demonstration device for cosmic rays telescopes,"We describe a hands-on accurate demonstrator for cosmic rays realized by six
high school students, whose main aim is to show the relevance and the
functioning of the principal parts of a cosmic rays telescope (muon detector),
with the help of two large size wooden artifacts. The first one points out how
cosmic rays can be tracked in a muon telescope, while the other one shows the
key avalanche process of electronic ionization that effectively allows muon
detection through a photomultiplier. Incoming cosmic rays are visualized in
terms of laser beams, whose 3D trajectory is highlighted by the turning on of
LEDs on two orthogonal matrices. Instead the avalanche ionization process is
demonstrated through the avalanche falling of glass marbles on an inclined
plane, finally turning on a LED. A pictured poster accompanying the
demonstrator is as well effective in assisting cosmic rays demonstration and
its detection. The success of the demonstrator has been fully proven by general
public during a Science Festival, the corresponding project winning the
Honorable Mention in a dedicated competition."
physics,"Significant and megathrust earthquake predictions by real-time
  monitoring of the genesis processes with Physical Wavelets","Physical Wavelets can offer real-time significant and megathrust earthquake
predictions and disaster prevention warnings up to three months in advance,
saving lives and minimizing damages."
physics,"Tsunami and megathrust earthquake disaster prevention warnings:
  Real-time monitoring of the genesis processes with Physical Wavelets","A megathrust earthquake genesis of 15 months with its tsunami genesis of the
last 3 months provides a real-time disaster prevention warning and hazard
mitigation measures leading up to the events."
physics,An Introductory Course on Quantum Mechanics,"This is a very gentle introductory course on quantum mechanics aimed at the
first years of the undergraduate level. The basic concepts are introduced, with
many applications and illustrations. Contains 12 short chapters of equal
length, ideal for a one term course. The license allows reuse of figures and
text under the Attribution-Noncommercial-ShareAlike conditions."
physics,"Imaging charge-migration in chiral molecules using time-resolved x-ray
  diffraction","Four-dimensional imaging of charge migration is crucial to the understanding
of several ubiquitous processes in nature. The present work focuses on imaging
of charge migration in an oriented epoxypropane: a chiral molecule. A linearly
polarized pulse is used to induce the charge migration, which is imaged by
time-resolved x-ray diffraction. It is found that the total time-resolved
diffraction signals are significantly different for both enantiomers.
Furthermore, a connection between time-resolved x-ray diffraction and the
electronic continuity equation is discussed by analyzing the time-dependent
diffraction signal and the time derivative of the total electron density in the
momentum space."
physics,"High-harmonic generation in liquids with few-cycle pulses: effect of
  laser-pulse duration on the cut-off energy","High-harmonic generation (HHG) in liquids is opening new opportunities for
attosecond light sources and attosecond time-resolved studies of dynamics in
the liquid phase. In gas-phase HHG, few-cycle pulses are routinely used to
create isolated attosecond pulses and to extend the cut-off energy. Here, we
study the properties of HHG in liquids, including water and several alcohols,
by continuously tuning the pulse duration of a mid-infrared driver from the
multi- to the sub-two-cycle regime. Similar to the gas phase, we observe the
transition from discrete odd-order harmonics to continuous extreme-ultraviolet
emission. However, the cut-off energy is shown to be entirely independent of
the pulse duration. This observation is confirmed by ab-initio simulations of
HHG in large clusters. Our results support the notion that the cut-off energy
is a fundamental property of the liquid, independent of the driving-pulse
properties. Combined with the recently reported wavelength-independence of the
cutoff, these results confirm the direct sensitivity of HHG to the mean-free
paths of slow electrons in liquids. Our results additionally imply that
few-cycle mid-infrared laser pulses are suitable drivers for generating
isolated attosecond pulses from liquids."
physics,Charge density model for the interaction of molecules with vortex beams,"The interaction of molecules with the orbital angular momentum of light has
long been argued to benefit structural studies and quantum control of molecular
ensembles. We derive a general description of the light-matter interaction in
terms of the coupling between spherical gradients of the electric field and an
effective molecular charge density that exactly reproduces molecular multipole
moments. Our model can accommodate for an arbitrary complexity of the molecular
structure and is applicable to any electric field, with the exception of
tightly focused beams. Within this framework, we derive the general mechanism
of angular momentum exchange between the spin and orbital angular momenta of
light, molecular rotation and its center-of-mass motion. We demonstrate that
vortex beams strongly enhance certain ro-vibrational transitions that are
considered forbidden in the case of a non-helical light. Finally, we discuss
the experimental requirements for the observation of novel transitions in
state-of-the-art spatially-resolved spectroscopy measurements."
physics,"Polyatomic candidates for cooling of molecules with lasers from simple
  theoretical concepts","A rational approach to identify polyatomic molecules that appear to be
promising candidates for direct Doppler cooling with lasers is outlined.
First-principle calculations for equilibrium structures and Franck--Condon
factors of selected representatives with different point-group symmetries
(including chiral non-symmetric group C$_1$) have been performed and high
potential for laser-cooling of these molecules is indicated."
physics,"Probing the low-energy electron-scattering dynamics in liquids with
  high-harmonic spectroscopy","High-harmonic spectroscopy (HHS) is a nonlinear all-optical technique with
inherent attosecond temporal resolution, which has been applied successfully to
a broad variety of systems in the gas phase and solid state. Here, we extend
HHS to the liquid phase, and uncover the mechanism of high-harmonic generation
(HHG) for this phase of matter. Studying HHG over a broad range of wavelengths
and intensities, we show that the cut-off ($E_c$) is independent of the
wavelength beyond a threshold intensity, and find that $E_c$ is a
characteristic property of the studied liquid. We explain these observations
within an intuitive semi-classical model based on electron trajectories that
are limited by scattering to a characteristic length, which is connected to the
electron mean-free path. Our model is validated against rigorous multi-electron
time-dependent density-functional theory calculations in, both, supercells of
liquid water with periodic boundary conditions, and large clusters of a variety
of liquids. These simulations confirm our interpretation and thereby clarify
the mechanism of HHG in liquids. Our results demonstrate a new, all-optical
access to effective mean-free paths of slow electrons ($\leq$10 eV) in liquids,
in a regime that is inaccessible to accurate calculations, but is critical for
the understanding of radiation damage to living tissue. Our work also
establishes the possibility of resolving sub-femtosecond electron dynamics in
liquids, which offers a novel, all-optical approach to attosecond spectroscopy
of chemical processes in their native liquid environment."
physics,"Observation of atmospheric gravity waves using a Raspberry Pi camera
  module on board the International Space Station","We identified and computed the horizontal wavelengths of atmospheric gravity
waves in clouds using a visible camera installed on a window of the Columbus
module of the International Space Station (ISS) and controlled by a Raspberry
Pi computer. The experiment was designed in the context of the Astro Pi
challenge, a project run by ESA in collaboration with the Raspberry Pi
Foundation, where students are allowed the opportunity to write a code to be
executed at the ISS. A code was developed to maximize the probability of
capturing images of clouds while the ISS is orbiting the Earth. Several
constraints had to be fulfilled such as the experiment duration limit (3 hours)
and the maximum data size (3 gigabytes). After receiving the data from the ISS,
small-scale gravity waves were observed in different regions in the northern
hemisphere with horizontal wavelengths in the range of 1.0 to 4.7 km."
physics,"Immersive Interactive Quantum Mechanics for Teaching and Learning
  Chemistry","The impossibility of experiencing the molecular world with our senses hampers
teaching and understanding chemistry because very abstract concepts (such as
atoms, chemical bonds, molecular structure, reactivity) are required for this
process. Virtual reality, especially when based on explicit physical modeling
(potentially in real time), offers a solution to this dilemma. Chemistry
teaching can make use of advanced technologies such as virtual-reality
frameworks and haptic devices. We show how an immersive learning setting could
be applied to help students understand the core concepts of typical chemical
reactions by offering a much more intuitive approach than traditional learning
settings. Our setting relies on an interactive exploration and manipulation of
a chemical system; this system is simulated in real-time with quantum chemical
methods, and therefore, behaves in a physically meaningful way."
physics,MY LIFE AS TUTOR: Reflections on Two Recent Experiences,"In this final report, I briefly reflect on two parallel teaching experiences
as tutor. Besides, I briefly view such experiences in interaction with my
research work, private life and new teaching position. In harmony with my
conception of teaching, I avoid the standard formal style of reports and try an
interactive dialogue with the reader."
physics,"Teaching ""Symmetry"" in the Introductory Physics Curriculum","Modern physics is largely defined by fundamental symmetry principles and
Noether's Theorem. Yet these are not taught, or rarely mentioned, to beginning
students, thus missing an opportunity to reveal that the subject of physics is
as lively and contemporary as molecular biology, and as beautiful as the arts.
We prescribe a symmetry module to insert into the curriculum, of a week's
length."
physics,"Cinema, Fermi Problems, & General Education","During the past several years the authors have developed a new approach to
the teaching of Physical Science, a general education course typically found in
the curricula of nearly every college and university. This approach, called
`Physics in Films', uses scenes from popular movies to illustrate physical
principles and has excited student interest and improved student performance.
  The analyses of many of the scenes in `Physics in Films' are a direct
application of Fermi calculations -- estimates and approximations designed to
make solutions of complex and seemingly intractable problems understandable to
the student non-specialist. The intent of this paper is to provide instructors
with examples they can use to develop skill in recognizing Fermi problems and
making Fermi calculations in their own courses."
physics,"Cinema Fiction vs Physics Reality: Ghosts, Vampires and Zombies","We examine certain features of popular myths regarding ghosts, vampires and
zombies as they appear in film and folklore. We use physics to illuminate
inconsistencies associated with these myths and to give practical explanation
to certain aspects."
physics,Is Peudoscience the Solution to Science Literacy?,"Brief overview of the `Pseudoscience' flavor of the `Physics in Films'
project at the University of Central Florida."
physics,"A Physics Show Performed by Students for Kids: From Mechanics to
  Elementary Particle Physics","We describe an initiative at the University of Bonn, where the students
develop and perform a 2 hour physics show for school classes and the general
public. The show is entertaining and educational and is aimed at children aged
10 and older. For the physics students this is a unique experience to apply
their knowledge at an early stage and gives them the chance to develop skills
in the public presentation of science, in front of 520 people per show. We have
extended the activity to put on an elementary particle physics show for
teenagers. Furthermore, local high schools have picked up the idea; their
students put on similar shows for fellow students and parents. We would be
interested in hearing about related activities elsewhere."
physics,"Science-Based Comparative Culture: A New Theme of Experiment for
  Freshmen in Tohoku University","In 2004, Tohoku University created a new introductory science experimental
course for freshmen. The course is a compulsory subject for students in all
natural science fields. The course is not designed for a professional
education, but as a liberal education, in which students are trained to become
familiar with nature and to discover natural laws for themselves. We present
here one of 12 themes - ""science and culture: vibration of string instrument
and music"", in which we expect students to study two aspects: 1) the
universality of natural laws and 2) the variety of value judgments from the
evidence."
physics,"Active and Cooperative Learning Paths in the Pigelleto's Summer School
  of Physics","Since 2006, the Pigelleto's Summer School of Physics is an important
appointment for orienting students toward physics. It is organized as a full
immersion school on actual topics in physics or in fields rarely pursued in
high school, i.e. quantum mechanics, new materials, energy resources. The
students, usually forty, are engaged in many activities in laboratory and
forced to become active participants. Furthermore, they are encouraged in
cooperating in small groups in order to present and share the achieved results.
In the last years, the school became a training opportunity for younger
teachers which are involved in programming and realization of selected
activities. The laboratory activities with students are usually supervised by a
young and an expert teacher in order to fix the correct methodology."
physics,First Steps into Physics in the Winery,"Physics is introduced as a basic matter in the curricula of professional
schools (i.e. schools for agriculture, electronic or chemistry experts).
Students meet physics in the early years of their training and then continue in
vocational subjects where many physics' topics can be useful. Rarely, however,
the connection between physics and professional matters is quite explicit.
Students often feel physics as boring and useless, i.e. very far from their
interests. In these schools it is almost always required the physics lab, but
it does not always exist. The physics teachers of a local Agricultural
Technical Institute asked us to realize a learning path in laboratory for their
students, since in their school the physics lab was missing. This institute is
the only public school in the Chianti area specializing in Viticulture and
Enology, and attending a further year post diploma, allows the achievement of
the qualification of Enologist. We report a learning path realized starting
from thermal equilibrium to a full understanding of the measures made with the
Malligand's ebulliometer, used for determining the alcoholic strength (alcohol
concentration by volume) of an alcoholic beverage and water/alcohol solutions
in general. The aim was to make interesting measures of physical quantities,
calorimetry and state transitions connecting them to the functioning of an
instrument that students use in their professional career. The feedback of
students and the interests of their teachers convinced us to go further in this
way. We intend in the next future to involve teachers of physics and vocational
subjects in the design of a physics curriculum spread over two years in which
the main physics topics will be introduced to explain the functioning of tools
and equipment used, normally, in the winery."
physics,Evaluating Astronomy Literacy of the General Public,"A scientifically literate society is important for many different reasons,
some of which include democratic and scientific topics. This study was
performed in order to identify topics in astronomy and science in general that
may not be well understood by the general public. Approximately 1,000 adults at
a popular science museum in Philadelphia, PA completed True-False survey
questions about basic astronomy concepts. The participants were also asked to
provide their age, gender, and highest degree obtained. Although 93 +/- 0.8% of
the participants correctly answered that scientists can calculate the age of
the Earth, only 58 +/- 2% provided the correct response that scientists can
calculate the age of the Universe. Some participants (30 +/- 1%) responded that
scientists have found life on Mars. Females scored an average total score of 78
+/- 2%, whereas males scored an average 85 +/- 1%. Participants with an age of
56 and over had an average score of 78 +/- 4% compared to participants under
the age of 56 that were found to have an average score of 82 +/- 2%. Lastly,
participants' highest degree obtained scaled with number of correct responses,
with graduate level degree earners providing the largest amount of correct
responses and an average score of 86 +/- 2%."
physics,"Exposición Temprana de Nativos Digitales en Ambientes, Metodologías
  y Técnicas de Investigación en la Universidad","Being aware of the motivation problems observed in many scientific oriented
careers, we present two experiences to expose to college students to
environments, methodologies and discovery techniques addressing contemporary
problems. This experiences are developed in two complementary contexts: an
Introductory Physics course, where we motivated to physics students to
participate in research activities, and a multidisciplinary hotbed of research
oriented to advanced undergraduate students of Science and Engineering (that
even produced three poster presentations in international conferences).
Although these are preliminary results and require additional editions to get
statistical significance, we consider they are encouraging results. On both
contexts we observe an increase in the students motivation to orient their
careers with emphasizing on research. In this work, besides the
contextualization support for these experiences, we describe six specific
activities to link our students to research areas, which we believe can be
replicated on similar environments in other educational institutions."
physics,"Measuring the speed of light and the moon distance with an occultation
  of Mars by the Moon: a Citizen Astronomy Campaign","In July 5th 2014 an occultation of Mars by the Moon was visible in South
America. Citizen scientists and professional astronomers in Colombia, Venezuela
and Chile performed a set of simple observations of the phenomenon aimed to
measure the speed of light and lunar distance. This initiative is part of the
so called ""Aristarchus Campaign"", a citizen astronomy project aimed to
reproduce observations and measurements made by astronomers of the past.
Participants in the campaign used simple astronomical instruments (binoculars
or small telescopes) and other electronic gadgets (cell-phones and digital
cameras) to measure occultation times and to take high resolution videos and
pictures. In this paper we describe the results of the Aristarchus Campaign. We
compiled 9 sets of observations from sites separated by distances as large as
2,500 km. We achieve at measuring the speed of light in vacuum and lunar
distance with uncertainties of few percent. The goal of the Aristarchus
Campaigns is not to provide improved values of well-known astronomical and
physical quantities, but to demonstrate how the public could be engaged in
scientific endeavors using simple instrumentation and readily available
technological devices. These initiatives could benefit amateur communities in
developing countries increasing their awareness towards their actual
capabilities for collaboratively obtaining useful astronomical data. This kind
of exercises would prepare them for facing future and more advanced
observational campaigns where their role could be crucial."
physics,Project-based physics labs using low-cost open-source hardware,"We describe a project-based physics lab, which we proposed to third-year
university students. Theses labs are based on new open-source low-cost
equipment (Arduino microcontrollers and compatible sensors). Students are given
complete autonomy: they develop their own experimental setup and study the
physics topic of their choice. The goal of these projects is to let students
discover the reality of experimental physics. Technical specifications of the
acquisition material and case studies are presented for practical
implementation in other universities."
physics,The AstroCamp Project,"This contribution describes the concept, main structure and goals, and some
highlighted outcomes, of the AstroCamp -- an international academic excellence
program in the field of astronomy and physics created in 2012 and organized by
Centro de Astrof\'{\i}sica da Universidade do Porto (CAUP) together with the
Paredes de Coura municipality and several national and international partners."
physics,A project-based course about outreach in a physics curriculum,"We describe an undergraduate course where physics students are asked to
conceive an outreach project of their own. The course alternates between the
project conception and teachings about pedagogy and outreach, and ends in a
public show. We describe its practical implementation and benefits. Through a
student survey and an analysis of their projects, we discuss the merits and
flaws of this ""learning-by-doing"" teaching approach for physics."
physics,The overestimated potential of solar energy to mitigate climate change,"Many aspects of solar energy and policies to tackle the energy transition
have been neglected. Even though the earth is plenty of sun energy, our planet
is not plenty of resources to transform that energy into electricity. This is a
case between many others where an strongly optimistic bias is shadowing the
white elephant in the room."
physics,Teaching relativity at the AstroCamp,"The AstroCamp is an academic excellence program in the field of astronomy and
physics for students in the last 3 years of pre-university education, which
often includes a course (or a significant part thereof) on Relativity. After an
introduction to the principles, goals and structure of the camp, I describe the
approach followed by camp lecturers (myself and others) for teaching Special
and General Relativity, and some lessons learned and feedback from the
students. I also provide some thoughts on the differences between the physics
and mathematics secondary school curricula in Portugal and in other countries,
and on how these curricula could be modernized."
physics,"Opinion | Think Physics, Think Man: Barrier's to Women's Participation
  in Physics Education","An analysis of barriers to women's participation in physics education is
presented. It is expected that in undergraduate physics the most common
situation for a women is that she is cisgender and one of a numerical minority
in the classroom. The effects of other intersectional identities are not
considered. The analysis is based on evidence from the author's lived
experience as a transgender woman who transitioned as an undergraduate and on
evidence from the literature on the effects of gender differences in academic
disciplines. It is expected that the teaching philosophy and practice in
physics classrooms favours men over women and these gender dynamics are
partially responsible for the under-representation of women in physics. These
expectations require further research to be substantiated."
physics,"Evaluation and insights from a sonification-based planetarium show
  intended for improving inclusivity","Audio Universe: Tour of the Solar System is an audio-visual show for
planetariums and flatscreen viewing. It is designed in collaboration with
members of the blind and vision impaired (BVI) community, BVI specialist
teachers and their pupils. It aims to be suitable for audiences with all sight
levels by representing key concepts through sound and using a carefully
constructed narration. We present results from 291 audience evaluations from
online viewers and audience members of several planetarium showings in the UK
and Italy. We find a strong appreciation from BVI and non-BVI audiences, with
~90% scoring 4 or 5 (out of 5) for both how useful and enjoyable the sounds
are. We also present results from surveying planetariums and communication
leaders known to have downloaded the show. We find international success for
special events, for BVI audiences and for those with other special educational
needs and disabilities (SEND; including sensory needs and learning
difficulties). Feedback suggests this is due to its multi-sensory, clearly
narrated, and low sensory load (calm) production. However, we also describe
limitations identified during this evaluation exercise, including the show's
limited incorporation into regular (non-special) planetarium programmes. This
highlights an ongoing challenge of creating a fully inclusive planetarium
experience."
physics,Influence of sedimentary layering on tsunami generation,"The present article is devoted to the influence of sediment layers on the
process of tsunami generation. The main scope here is to demonstrate and
especially quantify the effect of sedimentation on vertical displacements of
the seabed due to an underwater earthquake. The fault is modelled as a
Volterra-type dislocation in an elastic half-space. The elastodynamics
equations are integrated with a finite element method. A comparison between two
cases is performed. The first one corresponds to the classical situation of an
elastic homogeneous and isotropic half-space, which is traditionally used for
the generation of tsunamis. The second test case takes into account the
presence of a sediment layer separating the oceanic column from the hard rock.
Some important differences are revealed. We conjecture that deformations in the
generation region may be amplified by sedimentary deposits, at least for some
parameter values. The mechanism of amplification is studied through careful
numerical simulations."
physics,"A collision-induced satellite in the Lyman Beta profile due to H-H
  collisions","We present a theoretical profile of the Lyman Beta line of atomic hydrogen
perturbed by collisions with neutral hydrogen atoms and protons. We use a
general unified theory in which the electric dipole moment varies during a
collision. A collision-induced satellite appears on Lyman Beta, correlated to
the B''\barB 1Sigma+u - X 1Sigma+g asymptotically forbidden transition of H_2.
As a consequence, the appearance of the line wing between Lyman Alpha and Lyman
Beta is shown to be sensitive to the relative abundance of hydrogen ions and
neutral atoms, and thereby to provide a temperature diagnostic for stellar
atmospheres and laboratory plasmas."
physics,Superintense Laser-driven Ion Beam Analysis,"Ion beam analysis techniques are among the most powerful tools for advanced
material characterization. Despite their growing relevance in a widening number
of fields, most ion beam analysis facilities still rely on the oldest
accelerator technologies, with severe limitations in terms of portability and
flexibility. In this work we thoroughly address the potential of superintense
laser-driven proton sources for this application. We develop a complete
analytical and numerical framework suitable to describe laser-driven ion beam
analysis, exemplifying the approach for Proton Induced X-ray/Gamma-ray
emission, a technique of widespread interest. This allows us to propose a
realistic design for a compact, versatile ion beam analysis facility based on
this novel concept. These results can pave the way for ground-breaking
developments in the field of hadron-based advanced material characterization."
physics,"Review of the high-power vacuum tube microwave sources based on
  Cherenkov radiation","Since the first vacuum tube (X-ray tube) was invented by Wilhelm R\""ontgen in
Germany, after more than one hundred years of development, the average power
density of the vacuum tube microwave source has reached the order of 108
[MW][GHz]2. In the high-power microwave field, the vacuum devices are still the
mainstream microwave sources for applications such as scientific instruments,
communications, radars, magnetic confinement fusion heating, microwave weapons,
etc. The principles of microwave generation by vacuum tube microwave sources
include Cherenkov or Smith-Purcell radiation, transition radiation, and
Bremsstrahlung. In this paper, the vacuum tube microwave sources based on
Cherenkov radiation were reviewed. Among them, the multi-wave Cherenkov
generators can produce 15 GW output power in X-band. Cherenkov radiation vacuum
tubes that can achieve continuous-wave operation include Traveling Wave Tubes
and Magnetrons, with output power up to 1MW. Cherenkov radiation vacuum tubes
that can generate frequencies of the order of 100 GHz and above include
Traveling Wave Tubes, Backward Wave Oscillators, Magnetrons, Surface Wave
Oscillators, Orotrons, etc."
physics,"FEbeam: Cavity and Electron Emission Data Conversion, Processing and
  Analysis. A Freeware Toolkit for RF Injectors","FEbeam is a compact field emission data processing interface with the
capability to analyze the field emission cathode performance in an rf injector
by extracting the field enhancement factor, local field, and effective emission
area from the Fowler-Nordheim equations. It also has the capability of
processing beam imaging micrographs using its sister software, FEpic. The
current version of FEbeam was designed for the Argonne Cathode Teststand (ACT)
of the Argonne Wakefield Accelerator facility switch yard. With slight
modifications, FEbeam can work for any rf field emission injector. This
software is open-source and can be found at https://github.com/schne525/FEbeam"
physics,$^{39}$Ar dating with small samples resolves ocean ventilation,"Ocean ventilation is the integrated effect of various processes that
propagate surface properties to the ocean interior. Its precise understanding
is the prerequisite for addressing essential questions such as oxygen supply,
the storage of anthropogenic carbon and the heat budget of the ocean. Currently
employed observational methods to infer ventilation utilise transient tracers,
i.e. tritium, SF$_6$, CFCs and the radioisotope $^{14}$C. However, their dating
ranges are not suitable to resolve the dynamics of the deep ocean. The noble
gas isotope $^{39}$Ar with a half-life of 269 years fills this gap. Its broad
application has previously been hindered by its very low abundance, requiring
at least 1000 litres of water for dating. Here we report on successful
$^{39}$Ar dating with only 5 litres of water based on the atom-optical
technique Atom Trap Trace Analysis. Our data reveal previously not quantifiable
ventilation patterns in the Eastern Tropical North Atlantic, where we find that
advection is more important for the ventilation of the intermediate depth range
than previously assumed. This result implies faster ventilation than estimated
in other studies and thus a significantly higher anthropogenic CO$_2$-storage.
The demonstrated analytical capabilities now allow for a global collection of
$^{39}$Ar data, which will have significant impact on our understanding of
ocean ventilation."
physics,"Extraction of Cs-137 by alcohol-water solvents from plants containing
  cardiac glycosides","As a result of nuclear power plant accidents, large areas receive radioactive
inputs of Cs-137. This cesium accumulates in herbs growing in such territories.
The problem is whether the herbs contaminated by radiocesium may be used as a
raw material for medicine. The answer depends on the amount of Cs-137
transfered from the contaminated raw material to the medicine. We have
presented new results of the transfer of Cs-137 from contaminated Digitalis
grandiflora Mill. and Convallaria majalis L. to medicine. We found that the
extraction of Cs-137 depends strongly on the hydrophilicity of the solvent. For
example 96.5%(vol.) ethyl alcohol extracts less Cs-137 (11.6%) than 40%(vol.)
ethyl alcohol or pure water (66.2%). The solubility of the cardiac glycosides
is inverse to the solubility of cesium, which may be of use in the
technological processes for manufacturing ecologically pure herbal medicine."
physics,"Towards a Computational Framework for Modeling the Impact of Aortic
  Coarctations upon Left Ventricular Load","Computational fluid dynamics (CFD) models of blood flow in the left ventricle
(LV) and aorta are important tools for analyzing the mechanistic links between
myocardial deformation and flow patterns. Typically, the use of image-based
kinematic CFD models prevails in applications such as predicting the acute
response to interventions which alter LV afterload conditions. However, such
models are limited in their ability to analyze any impacts upon LV load or key
biomarkers known to be implicated in driving remodeling processes as LV
function is not accounted for in a mechanistic sense.
  This study addresses these limitations by reporting on progress made towards
a novel electro-mechano-fluidic (EMF) model that represents the entire physics
of LV electromechanics (EM) based on first principles. A biophysically detailed
finite element (FE) model of LV EM was coupled with a FE-based CFD solver for
moving domains using an arbitrary Eulerian-Lagrangian (ALE) formulation. Two
clinical cases of patients suffering from aortic coarctations (CoA) were built
and parameterized based on clinical data under pre-treatment conditions. For
one patient case simulations under post-treatment conditions after geometric
repair of CoA by a virtual stenting procedure were compared against
pre-treatment results. Numerical stability of the approach was demonstrated by
analyzing mesh quality and solver performance under the significantly large
deformations of the LV blood pool. Further, computational tractability and
compatibility with clinical time scales were investigated by performing strong
scaling benchmarks up to 1536 compute cores. The overall cost of the entire
workflow for building, fitting and executing EMF simulations was comparable to
those reported for image-based kinematic models, suggesting that EMF models
show potential of evolving into a viable clinical research tool."
physics,"A three-dimensional thermal model of the human cochlea for magnetic
  cochlear implant surgery","In traditional cochlear implant surgery, physical trauma may occur during
electrode array insertion. Magnetic guidance of the electrode array has been
proposed to mitigate this medical complication. After insertion, the guiding
magnet attached to the tip of the electrode array must be detached via a
heating process and removed. This heating process may, however, cause thermal
trauma within the cochlea. In this study, a validated three-dimensional finite
element heat transfer model of the human cochlea is applied to perform an
intracochlear thermal analysis necessary to ensure the safety of the magnet
removal phase. Specifically, the maximum safe input power density to detach the
magnet is determined as a function of the boundary conditions, heating
duration, cochlea size, implant electrode array radius and insertion depth,
magnet size, and cochlear fluid. A dimensional analysis and numerical
simulations reveal that the maximum safe input power density increases with
increasing cochlea size and the radius of the electrode array, whereas it
decreases with increasing electrode array insertion depth and magnet size. The
best cochlear fluids from the thermal perspective are perilymph and a soap
solution. Even for the worst case scenario in which the cochlear walls are
assumed to be adiabatic except at the round window, the maximum safe input
power density is larger than that required to melt 1 $\rm{mm^3}$ of paraffin
bonding the magnet to the implant electrode array. By combining the outcome of
this work with other aspects of the design of the magnetic insertion process,
namely the magnetic guidance procedure and medical requirements, it will be
possible to implement a thermally safe patient-specific surgical procedure."
physics,"Differential tissue sparing of FLASH ultra high dose rates: an {\it
  in-silico} study","Purpose: To propose a theory for the differential tissue sparing of FLASH
ultra high dose rates (UHDR) through inter-track reaction-diffusion mechanism.
Methods: We calculate the time-evolution of particle track-structures using a
system of coupled reaction-diffusion equations on a random network designed for
molecular transport in porous and disordered media. The network is
representative of the intra- and inter-cellular diffusion channels in tissues.
Spatial cellular heterogeneities over the scale of track spacing have been
constructed by incorporating random fluctuations in the connectivity among
network sites. Results: We demonstrate the occurrence of phase separation among
the tracks as the complexity in intra- and inter-cellular structural increases.
At the weak limit of disorder, such as in water and normal tissue, neighboring
tracks melt into each other and form a percolated network of nonreactive
species. In contrast, at the strong limit of disorder, tracks evolve
individually like isolated islands with negligible inter-track overlap. Thus,
the spatio-temporal correlation among the chemical domains decreases as the
inter-cellular complexity of the tissue increases (e.g. from normal tissue to
fractal-type malignant tissue). Conclusions: The differential sparing of FLASH
UHDR in normal and tumor tissue may be explained by differences in inter- and
intra-cellular structural complexities between the tissue types. The structural
complexities of cancerous cells prevent clustering and chemical interaction of
tracks, whereas this interaction prevails and thus leads to sparing in normal
tissue."
physics,"Quasi-monoenergetic Laser-Plasma Positron Accelerator using
  Particle-Shower Plasma-Wave interactions","An all-optical centimeter-scale laser-plasma positron accelerator is modeled
to produce quasi-monoenergetic beams with tunable ultra-relativistic energies.
A new principle elucidated here describes the trapping of divergent positrons
that are part of a laser-driven electromagnetic shower with a large energy
spread and their acceleration into a quasi-monoenergetic positron beam in a
laser-driven plasma wave. Proof of this principle using analysis and
Particle-In-Cell simulations demonstrates that, under limits defined here,
existing lasers can accelerate hundreds of MeV pC quasi-monoenergetic positron
bunches. By providing an affordable alternative to kilometer-scale
radio-frequency accelerators, this compact positron accelerator opens up new
avenues of research."
physics,"Laser Driving Highly Collimated $γ$-ray Pulses for the Generation
  of $μ^-μ^+$ and $e^-e^+$ Pairs in $γ-γ$ Collider","A scheme to generate highly collimated $\gamma$-ray pulse is proposed for the
production of muon and electron pairs in $\gamma-\gamma$ collider. The
$\gamma$-ray pulse, with high conversion efficiency, can be produced as the
result of electron phase-locked acceleration in longitudinal electric field
through the interaction between an ultra-intense laser pulse and a narrow tube
target. Numerical simulation shows that 18\% energy of a 10-PW laser pulse is
transferred into the forward $\gamma$-rays in a divergence angle less than $
3^\circ$. The $\gamma$-ray pulse is applied in $\gamma-\gamma$ collider, in
which muon pairs can be produced and electron pairs can be enhanced by more
than 3 orders of magnitude. This scheme, which could be realized with the
coming 10PW class laser pulses, would allow the observation of a
$\gamma-\gamma$ collider for electron and muon pairs in laboratory."
physics,"A compact, all-optical positron production and collection scheme","In this paper we discuss a compact, laser-plasma-based scheme for the
generation of positron beams suitable to be implemented in an all-optical
setup. A laser-plasma-accelerated electron beam hits a solid target producing
electron-positron pairs via bremsstrahlung. The back of the target serves as a
plasma mirror to in-couple a laser pulse into a plasma stage located right
after the mirror where the laser drives a plasma wave (or wakefield). By
properly choosing the delay between the laser and the electron beam the
positrons produced in the target can be trapped in the wakefield, where they
are focused and accelerated during the transport, resulting in a collimated
beam. This approach minimizes the ballistic propagation time and enhances the
trapping efficiency. The system can be used as an injector of positron beams
and has potential applications in the development of a future, compact,
plasma-based electron-positron linear collider."
physics,Dirac and Majorana Constructs,"The present work is a brief review of the recent development in the
relativistic quantum mechanics in the $(1/2)\oplus (0,1/2)$ representation
space. It can be useful for graduate students in particle physics and quantum
field theory."
physics,Neutrinos,"The general status of neutrino physics are given. The history of the
neutrino, starting from Pauli and Fermi, is presented. The phenomenological V-A
theory of the weak interaction and the unified theory of the weak and
electromagnetic interactions, the so-called Standard Model, are discussed. The
problems of of neutrino masses, neutrino mixing, and neutrino oscillations are
discussed in some details."
physics,"Recent developments in comprehensive analytical instruments for the
  culture heritage objects-A review","This paper introduces the necessity and significance of the investigation of
cultural heritage objects. The multi-technique method is useful for the study
of cultural heritage objects, but a comprehensive analytical instrument is a
better choice since it can guarantee that different types of information are
always obtained from the same analytical point on the surface of cultural
heritage objects, which may be crucial for some situations. Thus, the X-ray
fluorescence (XRF)/X-ray diffraction (XRD) and X-ray fluorescence (XRF)/Raman
spectroscopy (RS) comprehensive analytical instruments are more and more widely
used to study cultural heritage objects. The two types of comprehensive
analytical instruments are discussed in detail and the XRF/XRD instruments are
further classified into different types on the basis of structure, type and
number of detectors. A new comprehensive analytical instrument prototype that
can perform XRF, XRD and RS measurements simultaneously has been successfully
developed by our team and the preliminary application has shown the analysis
performance and application potential. This overview contributes to better
understand the research progress and development tendency of comprehensive
analytical instruments for the study of cultural heritage objects. The new
comprehensive instruments will make researchers obtain more valuable
information on cultural heritage objects and further promote the study on
cultural heritage objects."
physics,Majorana and the path-integral approach to Quantum Mechanics,"We give, for the first time, the English translation of a manuscript by
Ettore Majorana, which probably corresponds to the text for a seminar delivered
at the University of Naples in 1938, where he lectured on Theoretical Physics.
Some passages reveal a physical interpretation of the Quantum Mechanics which
anticipates of several years the Feynman approach in terms of path integrals,
independently of the underlying mathematical formulation."
physics,"Dielectric Detection of Single Nanoparticles Using a Microwave Resonator
  Integrated with a Nanopore","The characterization of individual nanoparticles in a liquid constitutes a
critical challenge for environmental, material, and biological sciences. To
detect nanoparticles, electronic approaches are especially desirable owing to
their compactness and lower costs. Indeed, for single-molecule and
single-nanoparticle detection, resistive pulse sensing has advanced
significantly during the last two decades. While resistive pulse sensing was
widely used to obtain the geometric size information, impedimetric measurements
to obtain dielectric signatures of nanoparticles have scarcely been reported.
To explore this orthogonal sensing modality, we developed an impedimetric
sensor based on a microwave resonator with a nanoscale sensing gap surrounding
a nanopore. The approach of single nanoparticles near the sensing region and
their translocation through the nanopore induced sudden changes in the
impedance of the structure. The impedance changes in turn were picked up by the
phase response of the microwave resonator. We worked with 100 nm and 50 nm
polystyrene nanoparticles to observe single-particle events. Our current
implementation was limited by the non-uniform electric field at the sensing
region. The work provides a complementary sensing modality for nanoparticle
characterization where the dielectric response, rather than the ionic current,
determines the signal."
physics,"Calibration of a superconducting gravimeter with an absolute atom
  gravimeter","We present a 27-days long common view measurement of an absolute cold atom
gravimeter (CAG) and a relative iGrav superconducting gravimeter, which we use
to calibrate the iGrav scale factor. This allowed us to push the CAG long-term
stability down to the level of 0.5~nm.s$^{-2}$. We investigate the impact of
the duration of the measurement on the uncertainty in the determination of the
correlation factor and show that it is limited to about 3\textperthousand~by
the coloured noise of our cold atom gravimeter. A 3-days long measurement
session with an additional FG5X absolute gravimeter allows us to directly
compare the calibration results obtained with two different absolute meters.
Based on our analysis, we expect that with an improvement of its long term
stability, the CAG will allow to calibrate the iGrav scale factor to better
than the per mille level (1$\sigma$ level of confidence) after only one-day of
concurrent measurements for maximum tidal amplitudes."
physics,Thermodynamic Efficiency and Entropy Production in the Climate System,"We present a new outlook on the climate system thermodynamics, studying some
of its macroscopic properties in terms of the 1st and 2nd laws of
thermodynamics. We review and clarify the notion of efficiency of the climate
system by constructing formally an equivalent Carnot engine with efficiency
eta, and show how the Lorenz energy cycle can be framed in a macro-scale
thermodynamic context. Then, by exploiting the 2nd law, we prove that the lower
bound to the entropy production is eta times the integrated absolute value of
the internal entropy fluctuations. An exergetic interpretation is also
proposed. Finally, the controversial maximum entropy production principle is
re-interpreted as requiring the joint optimization of heat transport and
mechanical work production. These results provide new tools for climate change
analysis and for climate models' validation."
physics,Thermodynamics of Climate Change: Generalized Sensitivities,"Using a recently developed formalism, we present an in-depth analysis of how
the thermodynamics of the climate system varies with CO2 concentration by
performing experiments with a simplified yet Earth-like climate model. We find
that, in addition to the globally averaged surface temperature, the intensity
of the Lorenz energy cycle, the Carnot efficiency, the entropy production and
the degree of irreversibility of the system are linear with the logarithm of
the CO2 concentration. The generalized sensitivities proposed here suggest that
the climate system becomes less efficient, more irreversible, and features
higher entropy production as it becomes warmer."
physics,Local Runup Amplification By Resonant Wave Interactions,"Until now the analysis of long wave runup on a plane beach has been focused
on finding its maximum value, failing to capture the existence of resonant
regimes. One-dimensional numerical simulations in the framework of the
Nonlinear Shallow Water Equations (NSWE) are used to investigate the Boundary
Value Problem (BVP) for plane and non-trivial beaches. Monochromatic waves, as
well as virtual wave-gage recordings from real tsunami simulations, are used as
forcing conditions to the BVP. Resonant phenomena between the incident
wavelength and the beach slope are found to occur, which result in enhanced
runup of non-leading waves. The evolution of energy reveals the existence of a
quasi-periodic state for the case of sinusoidal waves, the energy level of
which, as well as the time required to reach that state, depend on the incident
wavelength for a given beach slope. Dispersion is found to slightly reduce the
value of maximum runup, but not to change the overall picture. Runup
amplification occurs for both leading elevation and depression waves."
physics,From Baking a Cake to Solving the Schrodinger Equation,"The primary emphasis of this study has been to explain how modifying a cake
recipe by changing either the dimensions of the cake or the amount of cake
batter alters the baking time. Restricting our consideration to the genoise,
one of the basic cakes of classic French cuisine, we have obtained a
semi-empirical formula for its baking time as a function of oven temperature,
initial temperature of the cake batter, and dimensions of the unbaked cake. The
formula, which is based on the Diffusion equation, has three adjustable
parameters whose values are estimated from data obtained by baking genoises in
cylindrical pans of various diameters. The resulting formula for the baking
time exhibits the scaling behavior typical of diffusion processes, i.e. the
baking time is proportional to the (characteristic length scale)^2 of the cake.
It also takes account of evaporation of moisture at the top surface of the
cake, which appears to be a dominant factor affecting the baking time of a
cake. In solving this problem we have obtained solutions of the Diffusion
equation which are interpreted naturally and straightforwardly in the context
of heat transfer; however, when interpreted in the context of the Schrodinger
equation, they are somewhat peculiar. The solutions describe a system whose
mass assumes different values in two different regions of space. Furthermore,
the solutions exhibit characteristics similar to the evanescent modes
associated with light waves propagating in a wave guide. When we consider the
Schrodinger equation as a non-relativistic limit of the Klein-Gordon equation
so that it includes a mass term, these are no longer solutions."
physics,"On the locus formed by the maximum heights of projectile motion with air
  resistance","We present an analysis on the geometrical place formed by the set of maxima
of the trajectories of a projectile launched in a media with linear drag. Such
a place, the locus of apexes, is written in term of the Lambert $W$ function in
polar coordinates, confirming the special role played by this function in the
problem. In order to characterize the locus, a study of its curvature is
presented in two parameterizations, in terms of the launch angle and in the
polar one. The angles of maximum curvature are compared with other important
angles in the projectile problem. As an addendum, we find that the synchronous
curve in this problem is a circle as in the drag-free case."
physics,"Certain Interesting Properties of Action and Its Application Towards
  Achieving Greater Organization in Complex Systems","The Principle of Least Action has evolved and established itself as the most
basic law of physics. This allows us to see how this fundamental law of nature
determines the development of the system towards states with less action, i.e.,
organized states. A system undergoing a natural process is formulated as a game
that tends to organize the system in the least possible time. Also, other
concepts of game theory are related to their profound physical counterparts.
Although no fundamentally new findings are provided, it is quite interesting to
see certain important properties of a complex system and their far-reaching
consequences."
physics,Rotorcraft RPM on Mars,"The Ingenuity helicopter test flights on Mars in April 2021 marked the first
time a powered aircraft has flown on another world. Students who have access to
model helicopters and drones may wonder, how well could those hover on the Red
Planet? The answer can be found in this journal [The Physics Teacher], using
appropriate scaling of the surface gravity and atmospheric density to Martian
values."
physics,Investigating viscous damping using a webcam,"We describe an experiment involving a mass oscillating in a viscous fluid and
analyze viscous damping of harmonic motion. The mechanical oscillator is
tracked using a simple webcam and an image processing algorithm records the
position of the geometrical center as a function of time. Interesting
information can be extracted from the displacement-time graphs, in particular
for the underdamped case. For example, we use these oscillations to determine
the viscosity of the fluid. Our mean value of 1.08 \pm 0.07 mPa s for distilled
water is in good agreement with the accepted value at 20\circC. This experiment
has been successfully employed in the freshman lab setting."
physics,A bottle of tea as a universal Helmholtz resonator,"Resonance is an ubiquitous phenomenon present in many systems. In particular,
air resonance in cavities was studied by Hermann von Helmholtz in the 1850s.
Originally used as acoustic filters, Helmholtz resonators are rigid-wall
cavities which reverberate at given fixed frequencies. An adjustable type of
resonator is the so-called universal Helmholtz resonator, a device consisting
of two sliding cylinders capable of producing sounds over a continuous range of
frequencies. Here we propose a simple experiment using a smartphone and normal
bottle of tea, with a nearly uniform cylindrical section, which, filled with
water at different levels, mimics a universal Helmholtz resonator. Blowing over
the bottle, different sounds are produced. Taking advantage of the great
processing capacity of smartphones, sound spectra together with frequencies of
resonance are obtained in real time."
physics,"Applications of object detection networks at high-power laser systems
  and experiments","The recent advent of deep artificial neural networks has resulted in a
dramatic increase in performance for object classification and detection. While
pre-trained with everyday objects, we find that a state-of-the-art object
detection architecture can very efficiently be fine-tuned to work on a variety
of object detection tasks in a high-power laser laboratory. In this manuscript,
three exemplary applications are presented. We show that the plasma waves in a
laser-plasma accelerator can be detected and located on the optical
shadowgrams. The plasma wavelength and plasma density are estimated
accordingly. Furthermore, we present the detection of all the peaks in an
electron energy spectrum of the accelerated electron beam, and the beam charge
of each peak is estimated accordingly. Lastly, we demonstrate the detection of
optical damage in a high-power laser system. The reliability of the object
detector is demonstrated over one thousand laser shots in each application. Our
study shows that deep object detection networks are suitable to assist online
and offline experiment analysis, even with small training sets. We believe that
the presented methodology is adaptable yet robust, and we encourage further
applications in high-power laser facilities regarding the control and
diagnostic tools, especially for those involving image data."
physics,Gravitational Waves: An Introduction,"In this article, I present an elementary introduction to the theory of
gravitational waves. This article is meant for students who have had an
exposure to general relativity, but, results from general relativity used in
the main discussion have been derived and discussed in the appendices. The weak
gravitational field approximation is first considered and the linearized
Einstein's equations are obtained. We discuss the plane wave solutions to these
equations and consider the transverse-traceless (TT) gauge. We then discuss the
motion of test particles in the presence of a gravitational wave and their
polarization. The method of Green's functions is applied to obtain the
solutions to the linearized field equations in presence of a nonrelativistic,
isolated source."
economics,A Practical Approach to Social Learning,"Models of social learning feature either binary signals or abstract signal
structures often deprived of micro-foundations. Both models are limited when
analyzing interim results or performing empirical analysis. We present a method
of generating signal structures which are richer than the binary model, yet are
tractable enough to perform simulations and empirical analysis. We demonstrate
the method's usability by revisiting two classical papers: (1) we discuss the
economic significance of unbounded signals Smith and Sorensen (2000); (2) we
use experimental data from Anderson and Holt (1997) to perform econometric
analysis. Additionally, we provide a necessary and sufficient condition for the
occurrence of action cascades."
economics,Revealed Price Preference: Theory and Empirical Analysis,"To determine the welfare implications of price changes in demand data, we
introduce a revealed preference relation over prices. We show that the absence
of cycles in this relation characterizes a consumer who trades off the utility
of consumption against the disutility of expenditure. Our model can be applied
whenever a consumer's demand over a strict subset of all available goods is
being analyzed; it can also be extended to settings with discrete goods and
nonlinear prices. To illustrate its use, we apply our model to a single-agent
data set and to a data set with repeated cross-sections. We develop a novel
test of linear hypotheses on partially identified parameters to estimate the
proportion of the population who are revealed better off due to a price change
in the latter application. This new technique can be used for nonparametric
counterfactual analysis more broadly."
economics,Second-order Inductive Inference: an axiomatic approach,"Consider a predictor who ranks eventualities on the basis of past cases: for
instance a search engine ranking webpages given past searches. Resampling past
cases leads to different rankings and the extraction of deeper information. Yet
a rich database, with sufficiently diverse rankings, is often beyond reach.
Inexperience demands either ""on the fly"" learning-by-doing or prudence: the
arrival of a novel case does not force (i) a revision of current rankings, (ii)
dogmatism towards new rankings, or (iii) intransitivity. For this higher-order
framework of inductive inference, we derive a suitably unique numerical
representation of these rankings via a matrix on eventualities x cases and
describe a robust test of prudence. Applications include: the success/failure
of startups; the veracity of fake news; and novel conditions for the existence
of a yield curve that is robustly arbitrage-free."
economics,Cheating with (Recursive) Models,"To what extent can agents with misspecified subjective models predict false
correlations? We study an ""analyst"" who utilizes models that take the form of a
recursive system of linear regression equations. The analyst fits each equation
to minimize the sum of squared errors against an arbitrarily large sample. We
characterize the maximal pairwise correlation that the analyst can predict
given a generic objective covariance matrix, subject to the constraint that the
estimated model does not distort the mean and variance of individual variables.
We show that as the number of variables in the model grows, the false pairwise
correlation can become arbitrarily close to one, regardless of the true
correlation."
economics,On Vickrey's Income Averaging,"We consider a small set of axioms for income averaging -- recursivity,
continuity, and the boundary condition for the present. These properties yield
a unique averaging function that is the density of the reflected Brownian
motion with a drift started at the current income and moving over the past
incomes. When averaging is done over the short past, the weighting function is
asymptotically converging to a Gaussian. When averaging is done over the long
horizon, the weighing function converges to the exponential distribution. For
all intermediate averaging scales, we derive an explicit solution that
interpolates between the two."
economics,Subjective Complexity Under Uncertainty,"Complexity of the problem of choosing among uncertain acts is a salient
feature of many of the environments in which departures from expected utility
theory are observed. I propose and axiomatize a model of choice under
uncertainty in which the size of the partition with respect to which an act is
measurable arises endogenously as a measure of subjective complexity. I derive
a representation of incomplete Simple Bounds preferences in which acts that are
complex from the perspective of the decision maker are bracketed by simple acts
to which they are related by statewise dominance. The key axioms are motivated
by a model of learning from limited data. I then consider choice behavior
characterized by a ""cautious completion"" of Simple Bounds preferences, and
discuss the relationship between this model and models of ambiguity aversion. I
develop general comparative statics results, and explore applications to
portfolio choice, contracting, and insurance choice."
economics,Asset Prices and Capital Share Risks: Theory and Evidence,"An asset pricing model using long-run capital share growth risk has recently
been found to successfully explain U.S. stock returns. Our paper adopts a
recursive preference utility framework to derive an heterogeneous asset pricing
model with capital share risks.While modeling capital share risks, we account
for the elevated consumption volatility of high income stockholders. Capital
risks have strong volatility effects in our recursive asset pricing model.
Empirical evidence is presented in which capital share growth is also a source
of risk for stock return volatility. We uncover contrasting unconditional and
conditional asset pricing evidence for capital share risks."
economics,Matching Multidimensional Types: Theory and Application,"Becker (1973) presents a bilateral matching model in which scalar types
describe agents. For this framework, he establishes the conditions under which
positive sorting between agents' attributes is the unique market outcome.
Becker's celebrated sorting result has been applied to address many economic
questions. However, recent empirical studies in the fields of health,
household, and labor economics suggest that agents have multiple
outcome-relevant attributes. In this paper, I study a matching model with
multidimensional types. I offer multidimensional generalizations of concordance
and supermodularity to construct three multidimensional sorting patterns and
two classes of multidimensional complementarities. For each of these sorting
patterns, I identify the sufficient conditions which guarantee its optimality.
In practice, we observe sorting patterns between observed attributes that are
aggregated over unobserved characteristics. To reconcile theory with practice,
I establish the link between production complementarities and the aggregated
sorting patterns. Finally, I examine the relationship between agents' health
status and their spouses' education levels among U.S. households within the
framework for multidimensional matching markets. Preliminary analysis reveals a
weak positive association between agents' health status and their spouses'
education levels. This weak positive association is estimated to be a product
of three factors: (a) an attraction between better-educated individuals, (b) an
attraction between healthier individuals, and (c) a weak positive association
between agents' health status and their education levels. The attraction
channel suggests that the insurance risk associated with a two-person family
plan is higher than the aggregate risk associated with two individual policies."
economics,The Decision-Conflict Logit,"We introduce the *decision-conflict logit*, a simple and disciplined
extension of the logit with an outside option that assigns a menu-dependent
utility to that option. The relative value of this utility at a menu could be
interpreted as proxying decision difficulty and determines the probability of
avoiding/delaying choice at that menu. We focus on two intuitively structured
special cases of the model that offer complementary insights, and argue that
they explain a variety of observed choice-deferral effects that are caused by
hard decisions. We conclude by illustrating the usability of the proposed
modelling framework in applications."
economics,Finite-Sample Average Bid Auction,"The paper studies the problem of auction design in a setting where the
auctioneer accesses the knowledge of the valuation distribution only through
statistical samples. A new framework is established that combines the
statistical decision theory with mechanism design. Two optimality criteria,
maxmin, and equivariance, are studied along with their implications on the form
of auctions. The simplest form of the equivariant auction is the average bid
auction, which set individual reservation prices proportional to the average of
other bids and historical samples. This form of auction can be motivated by the
Gamma distribution, and it sheds new light on the estimation of the optimal
price, an irregular parameter. Theoretical results show that it is often
possible to use the regular parameter population mean to approximate the
optimal price. An adaptive average bid estimator is developed under this idea,
and it has the same asymptotic properties as the empirical Myerson estimator.
The new proposed estimator has a significantly better performance in terms of
value at risk and expected shortfall when the sample size is small."
economics,"Identification of hedonic equilibrium and nonseparable simultaneous
  equations","This paper derives conditions under which preferences and technology are
nonparametrically identified in hedonic equilibrium models, where products are
differentiated along more than one dimension and agents are characterized by
several dimensions of unobserved heterogeneity. With products differentiated
along a quality index and agents characterized by scalar unobserved
heterogeneity, single crossing conditions on preferences and technology provide
identifying restrictions in Ekeland, Heckman and Nesheim (2004) and Heckman,
Matzkin and Nesheim (2010). We develop similar shape restrictions in the
multi-attribute case. These shape restrictions, which are based on optimal
transport theory and generalized convexity, allow us to identify preferences
for goods differentiated along multiple dimensions, from the observation of a
single market. We thereby derive nonparametric identification results for
nonseparable simultaneous equations and multi-attribute hedonic equilibrium
models with (possibly) multiple dimensions of unobserved heterogeneity. One of
our results is a proof of absolute continuity of the distribution of
endogenously traded qualities, which is of independent interest."
economics,Identifying Present-Bias from the Timing of Choices,"Timing decisions are common: when to file your taxes, finish a referee
report, or complete a task at work. We ask whether time preferences can be
inferred when \textsl{only} task completion is observed. To answer this
question, we analyze the following model: each period a decision maker faces
the choice whether to complete the task today or to postpone it to later. Cost
and benefits of task completion cannot be directly observed by the analyst, but
the analyst knows that net benefits are drawn independently between periods
from a time-invariant distribution and that the agent has time-separable
utility. Furthermore, we suppose the analyst can observe the agent's exact
stopping probability. We establish that for any agent with quasi-hyperbolic
$\beta,\delta$-preferences and given level of partial naivete $\hat{\beta}$,
the probability of completing the task conditional on not having done it
earlier increases towards the deadline. And conversely, for any given
preference parameters $\beta,\delta$ and (weakly increasing) profile of task
completion probability, there exists a stationary payoff distribution that
rationalizes her behavior as long as the agent is either sophisticated or fully
naive. An immediate corollary being that, without parametric assumptions, it is
impossible to rule out time-consistency even when imposing an a priori
assumption on the permissible long-run discount factor. We also provide an
exact partial identification result when the analyst can, in addition to the
stopping probability, observe the agent's continuation value."
economics,The Income Fluctuation Problem and the Evolution of Wealth,"We analyze the household savings problem in a general setting where returns
on assets, non-financial income and impatience are all state dependent and
fluctuate over time. All three processes can be serially correlated and
mutually dependent. Rewards can be bounded or unbounded and wealth can be
arbitrarily large. Extending classic results from an earlier literature, we
determine conditions under which (a) solutions exist, are unique and are
globally computable, (b) the resulting wealth dynamics are stationary, ergodic
and geometrically mixing, and (c) the wealth distribution has a Pareto tail. We
show how these results can be used to extend recent studies of the wealth
distribution. Our conditions have natural economic interpretations in terms of
asymptotic growth rates for discounting and return on savings."
economics,The Theory of Weak Revealed Preference,"We offer a rationalization of the weak generalized axiom of revealed
preference (WGARP) for both finite and infinite data sets of consumer choice.
We call it maximin rationalization, in which each pairwise choice is associated
with a ""local"" utility function. We develop its associated weak
revealed-preference theory. We show that preference recoverability and welfare
analysis \`a la Varian (1982) may not be informative enough, when the weak
axiom holds, but when consumers are not utility maximizers. We clarify the
reasons for this failure and provide new informative bounds for the consumer's
true preferences."
economics,"Identification and Estimation of Discrete Choice Models with Unobserved
  Choice Sets","We propose a framework for nonparametric identification and estimation of
discrete choice models with unobserved choice sets. We recover the joint
distribution of choice sets and preferences from a panel dataset on choices. We
assume that either the latent choice sets are sparse or that the panel is
sufficiently long. Sparsity requires the number of possible choice sets to be
relatively small. It is satisfied, for instance, when the choice sets are
nested, or when they form a partition. Our estimation procedure is
computationally fast and uses mixed-integer optimization to recover the sparse
support of choice sets. Analyzing the ready-to-eat cereal industry using a
household scanner dataset, we find that ignoring the unobservability of choice
sets can lead to biased estimates of preferences due to significant latent
heterogeneity in choice sets."
economics,Testing the Drift-Diffusion Model,"The drift diffusion model (DDM) is a model of sequential sampling with
diffusion (Brownian) signals, where the decision maker accumulates evidence
until the process hits a stopping boundary, and then stops and chooses the
alternative that corresponds to that boundary. This model has been widely used
in psychology, neuroeconomics, and neuroscience to explain the observed
patterns of choice and response times in a range of binary choice decision
problems. This paper provides a statistical test for DDM's with general
boundaries. We first prove a characterization theorem: we find a condition on
choice probabilities that is satisfied if and only if the choice probabilities
are generated by some DDM. Moreover, we show that the drift and the boundary
are uniquely identified. We then use our condition to nonparametrically
estimate the drift and the boundary and construct a test statistic."
economics,Recovering Preferences from Finite Data,"We study preferences estimated from finite choice experiments and provide
sufficient conditions for convergence to a unique underlying ""true"" preference.
Our conditions are weak, and therefore valid in a wide range of economic
environments. We develop applications to expected utility theory, choice over
consumption bundles, menu choice and intertemporal consumption. Our framework
unifies the revealed preference tradition with models that allow for errors."
economics,Discerning Solution Concepts,"The empirical analysis of discrete complete-information games has relied on
behavioral restrictions in the form of solution concepts, such as Nash
equilibrium. Choosing the right solution concept is crucial not just for
identification of payoff parameters, but also for the validity and
informativeness of counterfactual exercises and policy implications. We say
that a solution concept is discernible if it is possible to determine whether
it generated the observed data on the players' behavior and covariates. We
propose a set of conditions that make it possible to discern solution concepts.
In particular, our conditions are sufficient to tell whether the players'
choices emerged from Nash equilibria. We can also discern between
rationalizable behavior, maxmin behavior, and collusive behavior. Finally, we
identify the correlation structure of unobserved shocks in our model using a
novel approach."
economics,Occupational segregation in a Roy model with composition preferences,"We propose a model of labor market sector self-selection that combines
comparative advantage, as in the Roy model, and sector composition preference.
Two groups choose between two sectors based on heterogeneous potential incomes
and group compositions in each sector. Potential incomes incorporate group
specific human capital accumulation and wage discrimination. Composition
preferences are interpreted as reflecting group specific amenity preferences as
well as homophily and aversion to minority status. We show that occupational
segregation is amplified by the composition preferences and we highlight a
resulting tension between redistribution and diversity. The model also exhibits
tipping from extreme compositions to more balanced ones. Tipping occurs when a
small nudge, associated with affirmative action, pushes the system to a very
different equilibrium, and when the set of equilibria changes abruptly when a
parameter governing the relative importance of pecuniary and composition
preferences crosses a threshold."
economics,Robust decision-making under risk and ambiguity,"Economists often estimate economic models on data and use the point estimates
as a stand-in for the truth when studying the model's implications for optimal
decision-making. This practice ignores model ambiguity, exposes the decision
problem to misspecification, and ultimately leads to post-decision
disappointment. Using statistical decision theory, we develop a framework to
explore, evaluate, and optimize robust decision rules that explicitly account
for estimation uncertainty. We show how to operationalize our analysis by
studying robust decisions in a stochastic dynamic investment model in which a
decision-maker directly accounts for uncertainty in the model's transition
dynamics."
economics,Identification of Incomplete Preferences,"We provide a sharp identification region for discrete choice models where
consumers' preferences are not necessarily complete and only aggregate choice
data is available. Behavior is modeled using an upper and a lower utility for
each alternative so that non-comparability can arise. The identification region
places intuitive bounds on the probability distribution of upper and lower
utilities. We show that the existence of an instrumental variable can be used
to reject the hypothesis that the preferences of all consumers are complete. We
apply our methods to data from the 2018 mid-term elections in Ohio."
economics,Gambits: Theory and Evidence,"Gambits are central to human decision-making. Our goal is to provide a theory
of Gambits. A Gambit is a combination of psychological and technical factors
designed to disrupt predictable play. Chess provides an environment to study
gambits and behavioral game theory. Our theory is based on the Bellman
optimality path for sequential decision-making. This allows us to calculate the
$Q$-values of a Gambit where material (usually a pawn) is sacrificed for
dynamic play. On the empirical side, we study the effectiveness of a number of
popular chess Gambits. This is a natural setting as chess Gambits require a
sequential assessment of a set of moves (a.k.a. policy) after the Gambit has
been accepted. Our analysis uses Stockfish 14.1 to calculate the optimal
Bellman $Q$ values, which fundamentally measures if a position is winning or
losing. To test whether Bellman's equation holds in play, we estimate the
transition probabilities to the next board state via a database of expert human
play. This then allows us to test whether the \emph{Gambiteer} is following the
optimal path in his decision-making. Our methodology is applied to the popular
Stafford and reverse Stafford (a.k.a. Boden-Kieretsky-Morphy) Gambit and other
common ones including the Smith-Morra, Goring, Danish and Halloween Gambits. We
build on research in human decision-making by proving an irrational skewness
preference within agents in chess. We conclude with directions for future
research."
economics,Attention Overload,"We introduce an Attention Overload Model that captures the idea that
alternatives compete for the decision maker's attention, and hence the
attention that each alternative receives decreases as the choice problem
becomes larger. We provide testable implications on the observed choice
behavior that can be used to (point or partially) identify the decision maker's
preference and attention frequency. We then enhance our attention overload
model to accommodate heterogeneous preferences based on the idea of List-based
Attention Overload, where alternatives are presented to the decision makers as
a list that correlates with both heterogeneous preferences and random
attention. We show that preference and attention frequencies are (point or
partially) identifiable under nonparametric assumptions on the list and
attention formation mechanisms, even when the true underlying list is unknown
to the researcher. Building on our identification results, we develop
econometric methods for estimation and inference."
economics,"Rational AI: A comparison of human and AI responses to triggers of
  economic irrationality in poker","Humans exhibit irrational decision-making patterns in response to
environmental triggers, such as experiencing an economic loss or gain. In this
paper we investigate whether algorithms exhibit the same behavior by examining
the observed decisions and latent risk and rationality parameters estimated by
a random utility model with constant relative risk-aversion utility function.
We use a dataset consisting of 10,000 hands of poker played by Pluribus, the
first algorithm in the world to beat professional human players and find (1)
Pluribus does shift its playing style in response to economic losses and gains,
ceteris paribus; (2) Pluribus becomes more risk-averse and rational following a
trigger but the humans become more risk-seeking and irrational; (3) the
difference in playing styles between Pluribus and the humans on the dimensions
of risk-aversion and rationality are particularly differentiable when both have
experienced a trigger. This provides support that decision-making patterns
could be used as ""behavioral signatures"" to identify human versus algorithmic
decision-makers in unlabeled contexts."
economics,Behavioral Foundations of Nested Stochastic Choice and Nested Logit,"We provide the first behavioral characterization of nested logit, a
foundational and widely applied discrete choice model, through the introduction
of a non-parametric version of nested logit that we call Nested Stochastic
Choice (NSC). NSC is characterized by a single axiom that weakens Independence
of Irrelevant Alternatives based on revealed similarity to allow for the
similarity effect. Nested logit is characterized by an additional
menu-independence axiom. Our axiomatic characterization leads to a practical,
data-driven algorithm that identifies the true nest structure from choice data.
We also discuss limitations of generalizing nested logit by studying the
testable implications of cross-nested logit."
economics,Random Rank-Dependent Expected Utility,"We present a novel characterization of random rank-dependent expected utility
for finite datasets and finite prizes. The test lends itself to statistical
testing using the tools in Kitamura and Stoye (2018)."
economics,A General Description of Growth Trends,"Time series that display periodicity can be described with a Fourier
expansion. In a similar vein, a recently developed formalism enables
description of growth patterns with the optimal number of parameters (Elitzur
et al, 2020). The method has been applied to the growth of national GDP,
population and the COVID-19 pandemic; in all cases the deviations of long-term
growth patterns from pure exponential required no more than two additional
parameters, mostly only one. Here I utilize the new framework to develop a
unified formulation for all functions that describe growth deceleration,
wherein the growth rate decreases with time. The result offers the prospects
for a new general tool for trend removal in time-series analysis."
economics,The Transfer Performance of Economic Models,"Economists often estimate models using data from a particular domain, e.g.
estimating risk preferences in a particular subject pool or for a specific
class of lotteries. Whether a model's predictions extrapolate well across
domains depends on whether the estimated model has captured generalizable
structure. We provide a tractable formulation for this ""out-of-domain""
prediction problem and define the transfer error of a model based on how well
it performs on data from a new domain. We derive finite-sample forecast
intervals that are guaranteed to cover realized transfer errors with a
user-selected probability when domains are iid, and use these intervals to
compare the transferability of economic models and black box algorithms for
predicting certainty equivalents. We find that in this application, the black
box algorithms we consider outperform standard economic models when estimated
and tested on data from the same domain, but the economic models generalize
across domains better than the black-box algorithms do."
economics,"An Equilibrium Model of the First-Price Auction with Strategic
  Uncertainty: Theory and Empirics","In many first-price auctions, bidders face considerable strategic
uncertainty: They cannot perfectly anticipate the other bidders' bidding
behavior. We propose a model in which bidders do not know the entire
distribution of opponent bids but only the expected (winning) bid and lower and
upper bounds on the opponent bids. We characterize the optimal bidding
strategies and prove the existence of equilibrium beliefs. Finally, we apply
the model to estimate the cost distribution in highway procurement auctions and
find good performance out-of-sample."
economics,Approximating Choice Data by Discrete Choice Models,"We obtain a necessary and sufficient condition under which random-coefficient
discrete choice models, such as mixed-logit models, are rich enough to
approximate any nonparametric random utility models arbitrarily well across
choice sets. The condition turns out to be the affine-independence of the set
of characteristic vectors. When the condition fails, resulting in some random
utility models that cannot be closely approximated, we identify preferences and
substitution patterns that are challenging to approximate accurately. We also
propose algorithms to quantify the magnitude of approximation errors."
economics,Robust Data-Driven Decisions Under Model Uncertainty,"When sample data are governed by an unknown sequence of independent but
possibly non-identical distributions, the data-generating process (DGP) in
general cannot be perfectly identified from the data. For making decisions
facing such uncertainty, this paper presents a novel approach by studying how
the data can best be used to robustly improve decisions. That is, no matter
which DGP governs the uncertainty, one can make a better decision than without
using the data. I show that common inference methods, e.g., maximum likelihood
and Bayesian updating cannot achieve this goal. To address, I develop new
updating rules that lead to robustly better decisions either asymptotically
almost surely or in finite sample with a pre-specified probability. Especially,
they are easy to implement as are given by simple extensions of the standard
statistical procedures in the case where the possible DGPs are all independent
and identically distributed. Finally, I show that the new updating rules also
lead to more intuitive conclusions in existing economic models such as asset
pricing under ambiguity."
economics,A Two-Ball Ellsberg Paradox: An Experiment,"We conduct an incentivized experiment on a nationally representative US
sample \\ (N=708) to test whether people prefer to avoid ambiguity even when it
means choosing dominated options. In contrast to the literature, we find that
55\% of subjects prefer a risky act to an ambiguous act that always provides a
larger probability of winning. Our experimental design shows that such a
preference is not mainly due to a lack of understanding. We conclude that
subjects avoid ambiguity \textit{per se} rather than avoiding ambiguity because
it may yield a worse outcome. Such behavior cannot be reconciled with existing
models of ambiguity aversion in a straightforward manner."
economics,Stable Matching with Mistaken Agents,"Motivated by growing evidence of agents' mistakes in strategically simple
environments, we propose a solution concept -- robust equilibrium -- that
requires only an asymptotically optimal behavior. We use it to study large
random matching markets operated by the applicant-proposing Deferred Acceptance
(DA). Although truth-telling is a dominant strategy, almost all applicants may
be non-truthful in robust equilibrium; however, the outcome must be arbitrarily
close to the stable matching. Our results imply that one can assume truthful
agents to study DA outcomes, theoretically or counterfactually. However, to
estimate the preferences of mistaken agents, one should assume stable matching
but not truth-telling."
economics,"(Functional)Characterizations vs (Finite)Tests: Partially Unifying
  Functional and Inequality-Based Approaches to Testing","Historically, testing if decision-makers obey certain choice axioms using
choice data takes two distinct approaches. The 'functional' approach observes
and tests the entire 'demand' or 'choice' function, whereas the 'revealed
preference(RP)' approach constructs inequalities to test finite choices. I
demonstrate that a statistical recasting of the revealed enables uniting both
approaches. Specifically, I construct a computationally efficient algorithm to
output one-sided statistical tests of choice data from functional
characterizations of axiomatic behavior, thus linking statistical and RP
testing. An application to weakly separable preferences, where RP
characterizations are provably NP-Hard, demonstrates the approach's merit. I
also show that without assuming monotonicity, all restrictions disappear.
Hence, any ability to resolve axiomatic behavior relies on the monotonicity
assumption."
economics,A Structural Model for Detecting Communities in Networks,"The objective of this paper is to identify and analyze the response actions
of a set of players embedded in sub-networks in the context of interaction and
learning. We characterize strategic network formation as a static game of
interactions where players maximize their utility depending on the connections
they establish and multiple interdependent actions that permit group-specific
parameters of players. It is challenging to apply this type of model to
real-life scenarios for two reasons: The computation of the Bayesian Nash
Equilibrium is highly demanding and the identification of social influence
requires the use of excluded variables that are oftentimes unavailable. Based
on the theoretical proposal, we propose a set of simulant equations and discuss
the identification of the social interaction effect employing multi-modal
network autoregressive."
economics,Robust Hicksian Welfare Analysis under Individual Heterogeneity,"Welfare effects of price changes are often estimated with cross-sections;
these do not identify demand with heterogeneous consumers. We develop a
theoretical method addressing this, utilizing uncompensated demand moments to
construct local approximations for compensated demand moments, robust to
unobserved preference heterogeneity. Our methodological contribution offers
robust approximations for average and distributional welfare estimates,
extending to price indices, taxable income elasticities, and general
equilibrium welfare. Our methods apply to any cross-section; we demonstrate
them via UK household budget survey data. We uncover an insight: simple
non-parametric representative agent models might be less biased than complex
parametric models accounting for heterogeneity."
economics,The Core of Bayesian Persuasion,"An analyst observes the frequency with which an agent takes actions, but not
the frequency with which she takes actions conditional on a payoff relevant
state. In this setting, we ask when the analyst can rationalize the agent's
choices as the outcome of the agent learning something about the state before
taking action. Our characterization marries the obedience approach in
information design (Bergemann and Morris, 2016) and the belief approach in
Bayesian persuasion (Kamenica and Gentzkow, 2011) relying on a theorem by
Strassen (1965) and Hall's marriage theorem. We apply our results to
ring-network games and to identify conditions under which a data set is
consistent with a public information structure in first-order Bayesian
persuasion games."
economics,Forecasting with Feedback,"Systematically biased forecasts are typically interpreted as evidence of
forecasters' irrationality and/or asymmetric loss. In this paper we propose an
alternative explanation: when forecasts inform economic policy decisions, and
the resulting actions affect the realization of the forecast target itself,
forecasts may be optimally biased even under quadratic loss. The result arises
in environments in which the forecaster is uncertain about the decision maker's
reaction to the forecast, which is presumably the case in most applications. We
illustrate the empirical relevance of our theory by reviewing some stylized
properties of Green Book inflation forecasts and relating them to the
predictions from our model. Our results point out that the presence of policy
feedback poses a challenge to traditional tests of forecast rationality."
economics,Improving Robust Decisions with Data,"A decision-maker (DM) faces uncertainty governed by a data-generating process
(DGP), which is only known to belong to a set of sequences of independent but
possibly non-identical distributions. A robust decision maximizes the DM's
expected payoff against the worst possible DGP in this set. This paper studies
how such robust decisions can be improved with data, where improvement is
measured by expected payoff under the true DGP. In this paper, I fully
characterize when and how such an improvement can be guaranteed under all
possible DGPs and develop inference methods to achieve it. These inference
methods are needed because, as this paper shows, common inference methods
(e.g., maximum likelihood or Bayesian) often fail to deliver such an
improvement. Importantly, the developed inference methods are given by simple
augmentations to standard inference procedures, and are thus easy to implement
in practice."
economics,Exploring Distributions of House Prices and House Price Indices,"We use house prices (HP) and house price indices (HPI) as a proxy to income
distribution. Specifically, we analyze sale prices in the 1970-2010 window of
over 116,000 single-family homes in Hamilton County, Ohio, including Cincinnati
metro area of about 2.2 million people. We also analyze HPI, published by
Federal Housing Finance Agency (FHFA), for nearly 18,000 US ZIP codes that
cover a period of over 40 years starting in 1980's. If HP can be viewed as a
first derivative of income, HPI can be viewed as its second derivative. We use
generalized beta (GB) family of functions to fit distributions of HP and HPI
since GB naturally arises from the models of economic exchange described by
stochastic differential equations. Our main finding is that HP and multi-year
HPI exhibit a negative Dragon King (nDK) behavior, wherein power-law
distribution tail gives way to an abrupt decay to a finite upper limit value,
which is similar to our recent findings for realized volatility of S\&P500
index in the US stock market. This type of tail behavior is best fitted by a
modified GB (mGB) distribution. Tails of single-year HPI appear to show more
consistency with power-law behavior, which is better described by a GB Prime
(GB2) distribution. We supplement full distribution fits by mGB and GB2 with
direct linear fits (LF) of the tails. Our numerical procedure relies on
evaluation of confidence intervals (CI) of the fits, as well as of p-values
that give the likelihood that data come from the fitted distributions."
economics,Investigating Wheat Price with a Multi-Agent Model,"In this paper, we build a computational model for the analysis of
international wheat spot price formation, its dynamics and the dynamics of
internationally exchanged quantities. The model has been calibrated using
FAOSTAT data to evaluate its in-sample predictive power. The model is able to
generate wheat prices in twelve international markets and wheat used quantities
in twenty-four world regions. The time span considered goes from 1992 to 2013.
In our study, a particular attention was paid to the impact of Russian
Federation's 2010 grain export ban on wheat price and internationally traded
quantities. Among other results, we find that wheat average weighted world
price in 2013 would have been 3.55\% lower than the observed one if the Russian
Federation would not have imposed the export ban in 2010."
economics,"Exceeding Expectations: Stochastic Dominance as a General Decision
  Theory","The principle that rational agents should maximize expected utility or
choiceworthiness is intuitively plausible in many ordinary cases of
decision-making under uncertainty. But it is less plausible in cases of
extreme, low-probability risk (like Pascal's Mugging), and intolerably
paradoxical in cases like the St. Petersburg and Pasadena games. In this paper
I show that, under certain conditions, stochastic dominance reasoning can
capture most of the plausible implications of expectational reasoning while
avoiding most of its pitfalls. Specifically, given sufficient background
uncertainty about the choiceworthiness of one's options, many
expectation-maximizing gambles that do not stochastically dominate their
alternatives ""in a vacuum"" become stochastically dominant in virtue of that
background uncertainty. But, even under these conditions, stochastic dominance
will not require agents to accept options whose expectational superiority
depends on sufficiently small probabilities of extreme payoffs. The sort of
background uncertainty on which these results depend looks unavoidable for any
agent who measures the choiceworthiness of her options in part by the total
amount of value in the resulting world. At least for such agents, then,
stochastic dominance offers a plausible general principle of choice under
uncertainty that can explain more of the apparent rational constraints on such
choices than has previously been recognized."
economics,"Banking Stability System: Does it Matter if the Rate of Return is Fixed
  or Stochastic?","The purpose is to compare the perfect Stochastic Return (SR) model like
Islamic banks to the Fixed Return (FR) model as in conventional banks by
measuring up their impacts at the macroeconomic level. We prove that if the
optimal choice of investor share in SR model {\alpha}* realizes the
indifference of the financial institution toward SR and FR models, there exists
{\alpha} less than {\alpha}* such that the banks strictly prefers the SR model.
Also, there exists {\alpha}, {\gamma} and {\lambda} verifying the conditions of
{\alpha}-sharing such that each party in economy can be better under the SR
model and the economic welfare could be improved in a Pareto-efficient way."
economics,Preference Identification,"An experimenter seeks to learn a subject's preference relation. The
experimenter produces pairs of alternatives. For each pair, the subject is
asked to choose. We argue that, in general, large but finite data do not give
close approximations of the subject's preference, even when the limiting
(countably infinite) data are enough to infer the preference perfectly. We
provide sufficient conditions on the set of alternatives, preferences, and
sequences of pairs so that the observation of finitely many choices allows the
experimenter to learn the subject's preference with arbitrary precision. While
preferences can be identified under our sufficient conditions, we show that it
is harder to identify utility functions. We illustrate our results with several
examples, including consumer choice, expected utility, and preferences in the
Anscombe-Aumann model."
economics,Strictly strategy-proof auctions,"A strictly strategy-proof mechanism is one that asks agents to use strictly
dominant strategies. In the canonical one-dimensional mechanism design setting
with private values, we show that strict strategy-proofness is equivalent to
strict monotonicity plus the envelope formula, echoing a well-known
characterisation of (weak) strategy-proofness. A consequence is that
strategy-proofness can be made strict by an arbitrarily small modification, so
that strictness is 'essentially for free'."
economics,Dynamic Random Subjective Expected Utility,"Dynamic Random Subjective Expected Utility (DR-SEU) allows to model choice
data observed from an agent or a population of agents whose beliefs about
objective payoff-relevant states and tastes can both evolve stochastically. Our
observable, the augmented Stochastic Choice Function (aSCF) allows, in contrast
to previous work in decision theory, for a direct test of whether the agent's
beliefs reflect the true data-generating process conditional on their private
information as well as identification of the possibly incorrect beliefs. We
give an axiomatic characterization of when an agent satisfies the model, both
in a static as well as in a dynamic setting. We look at the case when the agent
has correct beliefs about the evolution of objective states as well as at the
case when her beliefs are incorrect but unforeseen contingencies are
impossible.
  We also distinguish two subvariants of the dynamic model which coincide in
the static setting: Evolving SEU, where a sophisticated agent's utility evolves
according to a Bellman equation and Gradual Learning, where the agent is
learning about her taste. We prove easy and natural comparative statics results
on the degree of belief incorrectness as well as on the speed of learning about
taste.
  Auxiliary results contained in the online appendix extend previous decision
theory work in the menu choice and stochastic choice literature from a
technical as well as a conceptual perspective."
economics,"A characterization of ""Phelpsian"" statistical discrimination","We establish that statistical discrimination is possible if and only if it is
impossible to uniquely identify the signal structure observed by an employer
from a realized empirical distribution of skills. The impossibility of
statistical discrimination is shown to be equivalent to the existence of a
fair, skill-dependent, remuneration for workers. Finally, we connect the
statistical discrimination literature to Bayesian persuasion, establishing that
if discrimination is absent, then the optimal signaling problem results in a
linear payoff function (as well as a kind of converse)."
economics,Existence of Equilibrium Prices: A Pedagogical Proof,"Under the same assumptions made by Mas-Colell et al. (1995), I develop a
short, simple, and complete proof of existence of equilibrium prices based on
excess demand functions. The result is obtained by applying the Brouwer fixed
point theorem to a trimmed simplex which does not contain prices equal to zero.
The mathematical techniques are based on some results obtained in Neuefeind
(1980) and Geanakoplos (2003)."
economics,Mechanism Design with News Utility,"News utility is the idea that the utility of an agent depends on changes in
her beliefs over consumption and money. We introduce news utility into
otherwise classical static Bayesian mechanism design models. We show that a key
role is played by the timeline of the mechanism, i.e. whether there are delays
between the announcement stage, the participation stage, the play stage and the
realization stage of a mechanism. Depending on the timing, agents with news
utility can experience two additional news utility effects: a surprise effect
derived from comparing to pre-mechanism beliefs, as well as a realization
effect derived from comparing post-play beliefs with the actual outcome of the
mechanism.
  We look at two distinct mechanism design settings reflecting the two main
strands of the classical literature. In the first model, a monopolist screens
an agent according to the magnitude of her loss aversion. In the second model,
we consider a general multi-agent Bayesian mechanism design setting where the
uncertainty of each player stems from not knowing the intrinsic types of the
other agents. We give applications to auctions and public good provision which
illustrate how news utility changes classical results.
  For both models we characterize the optimal design of the timeline. A
timeline featuring no delay between participation and play but a delay in
realization is never optimal in either model. In the screening model the
optimal timeline is one without delays. In auction settings, under fairly
natural assumptions the optimal timeline has delays between all three stages of
the mechanism."
economics,$k$th price auctions and Catalan numbers,"This paper establishes an interesting link between $k$th price auctions and
Catalan numbers by showing that for distributions that have linear density, the
bid function at any symmetric, increasing equilibrium of a $k$th price auction
with $k\geq 3$ can be represented as a finite series of $k-2$ terms whose
$\ell$th term involves the $\ell$th Catalan number. Using an integral
representation of Catalan numbers, together with some classical combinatorial
identities, we derive the closed form of the unique symmetric, increasing
equilibrium of a $k$th price auction for a non-uniform distribution."
economics,The Structure of Equilibria in Trading Networks with Frictions,"Several structural results for the set of competitive equilibria in trading
networks with frictions are established: The lattice theorem, the rural
hospitals theorem, the existence of side-optimal equilibria, and a
group-incentive-compatibility result hold with imperfectly transferable utility
and in the presence of frictions. While our results are developed in a trading
network model, they also imply analogous (and new) results for exchange
economies with combinatorial demand and for two-sided matching markets with
transfers."
economics,Repeated Coordination with Private Learning,"We study a repeated game with payoff externalities and observable actions
where two players receive information over time about an underlying
payoff-relevant state, and strategically coordinate their actions. Players
learn about the true state from private signals, as well as the actions of
others. They commonly learn the true state (Cripps et al., 2008), but do not
coordinate in every equilibrium. We show that there exist stable equilibria in
which players can overcome unfavorable signal realizations and eventually
coordinate on the correct action, for any discount factor. For high discount
factors, we show that in addition players can also achieve efficient payoffs."
economics,The Indirect Cost of Information,"We study the indirect cost of information from sequential information cost
minimization. A key sub-additivity condition, together with monotonicity
equivalently characterizes the class of indirect cost functions generated from
any direct information cost. Adding an extra (uniform) posterior separability
condition equivalently characterizes the indirect cost generated from any
direct cost favoring incremental evidences. We also provide the necessary and
sufficient condition when prior independent direct cost generates posterior
separable indirect cost."
economics,The Core of an Economy with an Endogenous Social Division of Labour,"This paper considers the core of a competitive market economy with an
endogenous social division of labour. The theory is founded on the notion of a
""consumer-producer"", who consumes as well as produces commodities. First, we
show that the Core of such an economy with an endogenous social division of
labour can be founded on deviations of coalitions of arbitrary size, extending
the seminal insights of Vind and Schmeidler for pure exchange economies.
Furthermore, we establish the equivalence between the Core and the set of
competitive equilibria for continuum economies with an endogenous social
division of labour. Our analysis also concludes that self-organisation in a
social division of labour can be incorporated into the Edgeworthian barter
process directly. This is formulated as a Core equivalence result stated for a
Structured Core concept based on renegotiations among fully specialised
economic agents, i.e., coalitions that use only fully developed internal
divisions of labour. Our approach bridges the gap between standard economies
with social production and coalition production economies. Therefore, a more
straightforward and natural interpretation of coalitional improvement and the
Core can be developed than for coalition production economies."
economics,A note on contests with a constrained choice set of effort,"We consider a symmetric two-player contest, in which the choice set of effort
is constrained. We apply a fundamental property of the payoff function to show
that, under standard assumptions, there exists a unique Nash equilibrium in
pure strategies. It is shown that all equilibria are near the unconstrained
equilibrium. Perhaps surprisingly, this is not the case when players have
different prize evaluations."
economics,Time preference and information acquisition,"I consider the sequential implementation of a target information structure. I
characterize the set of decision time distributions induced by all signal
processes that satisfy a per-period learning capacity constraint. I find that
all decision time distributions have the same expectation, and the maximal and
minimal elements by mean-preserving spread order are deterministic distribution
and exponential distribution. The result implies that when time preference is
risk loving (e.g. standard or hyperbolic discounting), Poisson signal is
optimal since it induces the most risky exponential decision time distribution.
When time preference is risk neutral (e.g. constant delay cost), all signal
processes are equally optimal."
economics,Sorting and filtering as effective rational choice procedures,"Many online shops offer functionality that help their customers navigate the
available alternatives. For instance, options to filter and to sort goods are
wide-spread. In this paper we show that sorting and filtering can be used by
rational consumers to find their most preferred choice -- quickly. We
characterize the preferences which can be expressed through filtering and
sorting and show that these preferences exhibit a simple and intuitive logical
structure."
economics,Selling Information,"I consider the monopolistic pricing of informational good. A buyer's
willingness to pay for information is from inferring the unknown payoffs of
actions in decision making. A monopolistic seller and the buyer each observes a
private signal about the payoffs. The seller's signal is binary and she can
commit to sell any statistical experiment of her signal to the buyer. Assuming
that buyer's decision problem involves rich actions, I characterize the profit
maximizing menu. It contains a continuum of experiments, each containing
different amount of information. I also find a complementarity between buyer's
private information and information provision: when buyer's private signal is
more informative, the optimal menu contains more informative experiments."
economics,Matching in Dynamic Imbalanced Markets,"We study dynamic matching in exchange markets with easy- and hard-to-match
agents. A greedy policy, which attempts to match agents upon arrival, ignores
the positive externality that waiting agents generate by facilitating future
matchings. We prove that this trade-off between a ``thicker'' market and faster
matching vanishes in large markets; A greedy policy leads to shorter waiting
times, and more agents matched than any other policy. We empirically confirm
these findings in data from the National Kidney Registry. Greedy matching
achieves as many transplants as commonly-used policies (1.6\% more than
monthly-batching), and shorter patient waiting times."
economics,Completeness and Transitivity of Preferences on Mixture Sets,"In this paper, we show that the presence of the Archimedean and the
mixture-continuity properties of a binary relation, both empirically
non-falsifiable in principle, foreclose the possibility of consistency
(transitivity) without decisiveness (completeness), or decisiveness without
consistency, or in the presence of a weak consistency condition, neither. The
basic result can be sharpened when specialized from the context of a
generalized mixture set to that of a mixture set in the sense of
Herstein-Milnor (1953). We relate the results to the antecedent literature, and
view them as part of an investigation into the interplay of the structure of
the choice space and the behavioral assumptions on the binary relation defined
on it; the ES research program due to Eilenberg (1941) and Sonnenschein (1965),
and one to which Schmeidler (1971) is an especially influential contribution."
economics,The Model Selection Curse,"A ""statistician"" takes an action on behalf of an agent, based on the agent's
self-reported personal data and a sample involving other people. The action
that he takes is an estimated function of the agent's report. The estimation
procedure involves model selection. We ask the following question: Is
truth-telling optimal for the agent given the statistician's procedure? We
analyze this question in the context of a simple example that highlights the
role of model selection. We suggest that our simple exercise may have
implications for the broader issue of human interaction with ""machine learning""
algorithms."
economics,Optimal policy design for the sugar tax,"Healthy nutrition promotions and regulations have long been regarded as a
tool for increasing social welfare. One of the avenues taken in the past decade
is sugar consumption regulation by introducing a sugar tax. Such a tax
increases the price of extensive sugar containment in products such as soft
drinks. In this article we consider a typical problem of optimal regulatory
policy design, where the task is to determine the sugar tax rate maximizing the
social welfare. We model the problem as a sequential game represented by the
three-level mathematical program. On the upper level, the government decides
upon the tax rate. On the middle level, producers decide on the product
pricing. On the lower level, consumers decide upon their preferences towards
the products. While the general problem is computationally intractable, the
problem with a few product types is polynomially solvable, even for an
arbitrary number of heterogeneous consumers. This paper presents a simple,
intuitive and easily implementable framework for computing optimal sugar tax in
a market with a few products. This resembles the reality as the soft drinks,
for instance, are typically categorized in either regular or no-sugar drinks,
e.g. Coca-Cola and Coca-Cola Zero. We illustrate the algorithm using an example
based on the real data and draw conclusions for a specific local market."
economics,The Losses from Integration in Matching Markets can be Large,"Although the integration of two-sided matching markets using stable
mechanisms generates expected gains from integration, I show that there are
worst-case scenarios in which these are negative. The losses from integration
can be large enough that the average rank of an agent's spouse decreases by
37.5% of the length of their preference list in any stable matching mechanism."
economics,Revealed Stochastic Preference: A One-Paragraph Proof and Generalization,"McFadden and Richter (1991) and later McFadden (2005) show that the Axiom of
Revealed Stochastic Preference characterizes rationalizability of choice
probabilities through random utility models on finite universal choice spaces.
This note proves the result in one short, elementary paragraph and extends it
to set valued choice. The latter requires a different axiom than is reported in
McFadden (2005)."
economics,"Corrigendum to ""Managerial Incentive Problems: A Dynamic Perspective""","This paper corrects some mathematical errors in Holmstr\""om (1999) and
clarifies the assumptions that are sufficient for the results of Holmstr\""om
(1999). The results remain qualitatively the same."
economics,Uncertainty and Robustness of Surplus Extraction,"This paper studies a robust version of the classic surplus extraction
problem, in which the designer knows only that the beliefs of each type belong
to some set, and designs mechanisms that are suitable for all possible beliefs
in that set. We derive necessary and sufficient conditions for full extraction
in this setting, and show that these are natural set-valued analogues of the
classic convex independence condition identified by Cremer and McLean (1985,
1988). We show that full extraction is neither generically possible nor
generically impossible, in contrast to the standard setting in which full
extraction is generic. When full extraction fails, we show that natural
additional conditions can restrict both the nature of the contracts a designer
can offer and the surplus the designer can obtain."
economics,"Characterizing Permissibility, Proper Rationalizability, and Iterated
  Admissibility by Incomplete Information","We characterize three interrelated concepts in epistemic game theory:
permissibility, proper rationalizability, and iterated admissibility. We define
the lexicographic epistemic model for a game with incomplete information. Based
on it, we give two groups of characterizations. The first group characterizes
permissibility and proper rationalizability. The second group characterizes
permissibility in an alternative way and iterated admissibility. In each group,
the conditions for the latter are stronger than those for the former, which
corresponds to the fact that proper rationalizability and iterated
admissibility are two (compatible) refinements of permissibility within the
complete information framework. The intrinsic difference between the two groups
are the role of rationality: the first group does not need it, while the second
group does."
economics,Mechanism Design with Limited Commitment,"We develop a tool akin to the revelation principle for dynamic
mechanism-selection games in which the designer can only commit to short-term
mechanisms. We identify a canonical class of mechanisms rich enough to
replicate the outcomes of any equilibrium in a mechanism-selection game between
an uninformed designer and a privately informed agent. A cornerstone of our
methodology is the idea that a mechanism should encode not only the rules that
determine the allocation, but also the information the designer obtains from
the interaction with the agent. Therefore, how much the designer learns, which
is the key tension in design with limited commitment, becomes an explicit part
of the design. Our result simplifies the search for the designer-optimal
outcome by reducing the agent's behavior to a series of participation,
truthtelling, and Bayes' plausibility constraints the mechanisms must satisfy."
economics,Constrained Information Design,"We provide tools to analyze information design problems subject to
constraints. We do so by extending the insight in Le Treust and Tomala (2019)
to the case of multiple inequality and equality constraints. Namely, that an
information design problem subject to constraints can be represented as an
unconstrained information design problem with a additional states, one for each
constraint. Thus, without loss of generality, optimal solutions induce as many
posteriors as the number of states and constraints. We provide results that
refine this upper bound. Furthermore, we provide conditions under which there
is no duality gap in constrained information design, thus validating a
Lagrangian approach. We illustrate our results with applications to mechanism
design with limited commitment (Doval and Skreta, 2022a) and persuasion of a
privately informed receiver (Kolotilin et al., 2017)."
economics,A Model of Competing Narratives,"We formalize the argument that political disagreements can be traced to a
""clash of narratives"". Drawing on the ""Bayesian Networks"" literature, we model
a narrative as a causal model that maps actions into consequences, weaving a
selection of other random variables into the story. An equilibrium is defined
as a probability distribution over narrative-policy pairs that maximizes a
representative agent's anticipatory utility, capturing the idea that public
opinion favors hopeful narratives. Our equilibrium analysis sheds light on the
structure of prevailing narratives, the variables they involve, the policies
they sustain and their contribution to political polarization."
economics,Measuring Knowledge for Recognition and Knowledge Entropy,"People employ their knowledge to recognize things. This paper is concerned
with how to measure people's knowledge for recognition and how it changes. The
discussion is based on three assumptions. Firstly, we construct two evolution
process equations, of which one is for uncertainty and knowledge, and the other
for uncertainty and ignorance. Secondly, by solving the equations, formulas for
measuring the levels of knowledge and the levels of ignorance are obtained in
two particular cases. Thirdly, a new concept of knowledge entropy is
introduced. Its similarity with Boltzmann's entropy and its difference with
Shannon's Entropy are examined. Finally, it is pointed out that the obtained
formulas of knowledge and knowledge entropy reflect two fundamental principles:
(1) The knowledge level of a group is not necessarily a simple sum of the
individuals' knowledge levels; and (2) An individual's knowledge entropy never
increases if the individual's thirst for knowledge never decreases."
economics,Fairness for Multi-Self Agents,"We investigate whether fairness is compatible with efficiency in economies
with multi-self agents, who may not be able to integrate their multiple
objectives into a single complete and transitive ranking. We adapt
envy-freeness, egalitarian-equivalence and the fair-share guarantee in two
different ways. An allocation is unambiguously-fair if it satisfies the chosen
criterion of fairness according to every objective of any agent; it is
aggregate-fair if it satisfies the criterion for some aggregation of each
agent's objectives.
  While efficiency is always compatible with the unambiguous fair-share
guarantee, it is incompatible with unambiguous envy-freeness in economics with
at least three agents. Two agents are enough for efficiency and unambiguous
egalitarian-equivalence to clash. Efficiency and the unambiguous fair-share
guarantee can be attained together with aggregate envy-freeness, or aggregate
egalitarian-equivalence."
economics,Why are prices proportional to embodied energies?,"The observed proportionality between nominal prices and average embodied
energies cannot be interpreted with conventional economic theory. A model is
presented that places energy transfers as the focal point of scarcity based on
the idea that (1) goods are material rearrangements, and (2) humans can only
rearrange matter with energy transfers. Modified consumer and producer problems
for an autarkic agent show that the opportunity cost of goods are given by
their marginal energy transfers, which depend on subjective and objective
factors (e.g. consumer preferences and direct energy transfers). Allowing for
exchange and under perfect competition, nominal prices arise as social
manifestations of goods' marginal energy transfers. The proportionality between
nominal prices and average embodied energy follows given the relation between
the latter and marginal energy transfers."
economics,Fair Odds for Noisy Probabilities,"We suggest that one individual holds multiple degrees of belief about an
outcome, given the evidence. We then investigate the implications of such noisy
probabilities for a buyer and a seller of binary options and find the odds
agreed upon to ensure zero-expectation betting, differ from those consistent
with the relative frequency of outcomes. More precisely, the buyer and the
seller agree to odds that are higher (lower) than the reciprocal of their
averaged unbiased probabilities when this average indicates the outcome is more
(less) likely to occur than chance. The favorite-longshot bias thereby emerges
to establish the foundation of an equitable market. As corollaries, our work
suggests the old-established way of revealing someone's degree of belief
through wagers may be more problematic than previously thought, and implies
that betting markets cannot generally promise to support rational decisions."
economics,Strategically Simple Mechanisms,"We define and investigate a property of mechanisms that we call ""strategic
simplicity,"" and that is meant to capture the idea that, in strategically
simple mechanisms, strategic choices require limited strategic sophistication.
We define a mechanism to be strategically simple if choices can be based on
first-order beliefs about the other agents' preferences and first-order
certainty about the other agents' rationality alone, and there is no need for
agents to form higher-order beliefs, because such beliefs are irrelevant to the
optimal strategies. All dominant strategy mechanisms are strategically simple.
But many more mechanisms are strategically simple. In particular, strategically
simple mechanisms may be more flexible than dominant strategy mechanisms in the
bilateral trade problem and the voting problem."
economics,"The Income Fluctuation Problem with Capital Income Risk: Optimality and
  Stability","This paper studies the income fluctuation problem with capital income risk
(i.e., dispersion in the rate of return to wealth). Wealth returns and labor
earnings are allowed to be serially correlated and mutually dependent. Rewards
can be bounded or unbounded. Under rather general conditions, we develop a set
of new results on the existence and uniqueness of solutions, stochastic
stability of the model economy, as well as efficient computation of the ergodic
wealth distribution. A variety of applications are discussed. Quantitative
analysis shows that both stochastic volatility and mean persistence in wealth
returns have nontrivial impact on wealth inequality."
economics,Mutual Conversion Between Preference Maps And Cook-Seiford Vectors,"In group decision making, the preference map and Cook-Seiford vector are two
concepts as ways of describing ties-permitted ordinal rankings. This paper
shows that they are equivalent for representing ties-permitted ordinal
rankings. Transformation formulas from one to the other are given and the
inherent consistency of the mutual conversion is discussed. The proposed
methods are illustrated by some examples. Some possible future applications of
the proposed formulas are also pointed out."
economics,The Cost of Information: The Case of Constant Marginal Costs,"We develop an axiomatic theory of information acquisition that captures the
idea of constant marginal costs in information production: the cost of
generating two independent signals is the sum of their costs, and generating a
signal with probability half costs half its original cost. Together with
Blackwell monotonicity and a continuity condition, these axioms determine the
cost of a signal up to a vector of parameters. These parameters have a clear
economic interpretation and determine the difficulty of distinguishing states."
economics,"A theoretical framework to consider energy transfers within growth
  theory","Growth theory has rarely considered energy despite its invisible hand in all
physical systems. We develop a theoretical framework that places energy
transfers at centerstage of growth theory based on two principles: (1) goods
are material rearrangements and (2) such rearrangements are done by energy
transferred by prime movers (e.g. workers, engines). We derive the implications
of these principles for an autarkic agent that maximizes utility subject to an
energy budget constraint and maximizes energy surplus to relax such constraint.
The solution to these problems shows that growth is driven by positive marginal
energy surplus of energy goods (e.g. rice, oil), yet materializes through prime
mover accumulation. This perspective brings under one framework several results
from previous attempts to insert energy within growth theory, reconciles
economics with natural sciences, and provides a basis for a general
reinterpretation of economics and growth as the interplay between human desires
and thermodynamic processes."
economics,Causality: a decision theoretic approach,"We propose a decision-theoretic model akin to Savage (1972) that is useful
for defining causal effects. Within this framework, we define what it means for
a decision maker (DM) to act as if the relation between the two variables is
causal. Next, we provide axioms on preferences and show that these axioms are
equivalent to the existence of a (unique) Directed Acyclic Graph (DAG) that
represents the DM's preference. The notion of representation has two
components: the graph factorizes the conditional independence properties of the
DM's subjective beliefs, and arrows point from cause to effect. Finally, we
explore the connection between our representation and models used in the
statistical causality literature (for example, Pearl (1995))."
economics,"Duesenberry's Theory of Consumption: Habit, Learning, and Ratcheting","This paper investigates the consumption and risk taking decision of an
economic agent with partial irreversibility of consumption decision by
formalizing the theory proposed by Duesenberry (1949). The optimal policies
exhibit a type of the (s, S) policy: there are two wealth thresholds within
which consumption stays constant. Consumption increases or decreases at the
thresholds and after the adjustment new thresholds are set. The share of risky
investment in the agent's total investment is inversely U-shaped within the (s,
S) band, which generates time-varying risk aversion that can fluctuate widely
over time. This property can explain puzzles and questions on asset pricing and
households' portfolio choices, e.g., why aggregate consumption is so smooth
whereas the high equity premium is high and the equity return has high
volatility, why the risky share is so low whereas the estimated risk aversion
by the micro-level data is small, and whether and when an increase in wealth
has an impact on the risky share. Also, the partial irreversibility model can
explain both the excess sensitivity and the excess smoothness of consumption."
economics,Cartel Stability under Quality Differentiation,"This note considers cartel stability when the cartelized products are
vertically differentiated. If market shares are maintained at pre-collusive
levels, then the firm with the lowest competitive price-cost margin has the
strongest incentive to deviate from the collusive agreement. The lowest-quality
supplier has the tightest incentive constraint when the difference in unit
production costs is sufficiently small."
economics,Equivalent Choice Functions and Stable Mechanisms,"We study conditions for the existence of stable and group-strategy-proof
mechanisms in a many-to-one matching model with contracts if students'
preferences are monotone in contract terms. We show that ""equivalence"",
properly defined, to a choice profile under which contracts are substitutes and
the law of aggregate holds is a necessary and sufficient condition for the
existence of a stable and group-strategy-proof mechanism.
  Our result can be interpreted as a (weak) embedding result for choice
functions under which contracts are observable substitutes and the observable
law of aggregate demand holds."
economics,Interdistrict School Choice: A Theory of Student Assignment,"Interdistrict school choice programs-where a student can be assigned to a
school outside of her district-are widespread in the US, yet the market-design
literature has not considered such programs. We introduce a model of
interdistrict school choice and present two mechanisms that produce stable or
efficient assignments. We consider three categories of policy goals on
assignments and identify when the mechanisms can achieve them. By introducing a
novel framework of interdistrict school choice, we provide a new avenue of
research in market design."
economics,Optimal Insurance with Limited Commitment in a Finite Horizon,"We study a finite horizon optimal contracting problem of a risk-neutral
principal and a risk-averse agent who receives a stochastic income stream when
the agent is unable to make commitments. The problem involves an infinite
number of constraints at each time and each state of the world. Miao and Zhang
(2015) have developed a dual approach to the problem by considering a
Lagrangian and derived a Hamilton-Jacobi-Bellman equation in an infinite
horizon. We consider a similar Lagrangian in a finite horizon, but transform
the dual problem into an infinite series of optimal stopping problems. For each
optimal stopping problem we provide an analytic solution by providing an
integral equation representation for the free boundary. We provide a
verification theorem that the value function of the original principal's
problem is the Legender-Fenchel transform of the integral of the value
functions of the optimal stopping problems. We also provide some numerical
simulation results of optimal contracting strategies"
economics,"Credit Cycles, Securitization, and Credit Default Swaps","We present a limits-to-arbitrage model to study the impact of securitization,
leverage and credit risk protection on the cyclicity of bank credit. In a
stable bank credit situation, no cycles of credit expansion or contraction
appear. Unlevered securitization together with mis-pricing of securitized
assets increases lending cyclicality, favoring credit booms and busts. Leverage
changes the state of affairs with respect to the simple securitization. First,
the volume of real activity and banking profits increases. Second, banks sell
securities when markets decline. This selling puts further pressure on falling
prices. The mis-pricing of credit risk protection or securitized assets
influences the real economy. Trading in these contracts reduces the amount of
funding available to entrepreneurs, particularly to high-credit-risk borrowers.
This trading decreases the liquidity of the securitized assets, and especially
those based on investments with high credit risk."
economics,Conditions for the uniqueness of the Gately point for cooperative games,"We are studying the Gately point, an established solution concept for
cooperative games. We point out that there are superadditive games for which
the Gately point is not unique, i.e. in general the concept is rather
set-valued than an actual point. We derive conditions under which the Gately
point is guaranteed to be a unique imputation and provide a geometric
interpretation. The Gately point can be understood as the intersection of a
line defined by two points with the set of imputations. Our uniqueness
conditions guarantee that these two points do not coincide. We provide
demonstrative interpretations for negative propensities to disrupt. We briefly
show that our uniqueness conditions for the Gately point include quasibalanced
games and discuss the relation of the Gately point to the $\tau$-value in this
context. Finally, we point out relations to cost games and the ACA method and
end upon a few remarks on the implementation of the Gately point and an
upcoming software package for cooperative game theory."
economics,RPS(1) Preferences,"We consider a model for decision making based on an adaptive, k-period,
learning process where the priors are selected according to Von
Neumann-Morgenstern expected utility principle. A preference relation between
two prospects is introduced, defined by the condition which prospect is
selected more often. We show that the new preferences have similarities with
the preferences obtained by Kahneman and Tversky (1979) in the context of the
prospect theory. Additionally, we establish that in the limit of large learning
period, the new preferences coincide with the expected utility principle."
economics,Relational Communication,"We study a communication game between an informed sender and an uninformed
receiver with repeated interactions and voluntary transfers. Transfers motivate
the receiver's decision-making and signal the sender's information. Although
full separation can always be supported in equilibrium, partial or complete
pooling is optimal if the receiver's decision-making is highly responsive to
information. In this case, the receiver's decision-making is disciplined by
pooling extreme states where she is most tempted to defect."
economics,A Noncooperative Model of Contest Network Formation,"In this paper we study a model of weighted network formation. The bilateral
interaction is modeled as a Tullock contest game with the possibility of a
draw. We describe stable networks under different concepts of stability. We
show that a Nash stable network is either the empty network or the complete
network. The complete network is not immune to bilateral deviations. When we
allow for limited farsightedness, stable networks immune to bilateral
deviations must be complete $M$-partite networks, with partitions of different
sizes. The empty network is the efficient network. We provide several
comparative statics results illustrating the importance of network structure in
mediating the effects of shocks and interventions. In particular, we show that
an increase in the likelihood of a draw has a non-monotonic effect on the level
of wasteful contest spending in the society. To the best of our knowledge, this
paper is the first attempt to model weighted network formation when the actions
of individuals are neither strategic complements nor strategic substitutes."
economics,"Theories and Practice of Agent based Modeling: Some practical
  Implications for Economic Planners","Nowadays, we are surrounded by a large number of complex phenomena ranging
from rumor spreading, social norms formation to rise of new economic trends and
disruption of traditional businesses. To deal with such phenomena,Complex
Adaptive System (CAS) framework has been found very influential among social
scientists,especially economists. As the most powerful methodology of CAS
modeling, Agent-based modeling (ABM) has gained a growing application among
academicians and practitioners. ABMs show how simple behavioral rules of agents
and local interactions among them at micro-scale can generate surprisingly
complex patterns at macro-scale. Despite a growing number of ABM publications,
those researchers unfamiliar with this methodology have to study a number of
works to understand (1) the why and what of ABMs and (2) the ways they are
rigorously developed. Therefore, the major focus of this paper is to help
social sciences researchers,especially economists get a big picture of ABMs and
know how to develop them both systematically and rigorously."
economics,"Modelling transfer profits as externalities in a cooperative
  game-theoretic model of natural gas networks","Existing cooperative game theoretic studies of bargaining power in gas
pipeline systems are based on the so called characteristic function form (CFF).
This approach is potentially misleading if some pipelines fall under regulated
third party access (TPA). TPA, which is by now the norm in the EU, obliges the
owner of a pipeline to transport gas for others, provided they pay a regulated
transport fee. From a game theoretic perspective, this institutional setting
creates so called ""externalities,"" the description of which requires partition
function form (PFF) games. In this paper we propose a method to compute
payoffs, reflecting the power structure, for a pipeline system with regulated
TPA. The method is based on an iterative flow mechanism to determine gas flows
and transport fees for individual players and uses the recursive core and the
minimal claim function to convert the PPF game back into a CFF game, which can
be solved by standard methods. We illustrate the approach with a simple
stylized numerical example of the gas network in Central Eastern Europe with a
focus on Ukraine's power index as a major transit country."
economics,Bayesian Elicitation,"How can a receiver design an information structure in order to elicit
information from a sender? We study how a decision-maker can acquire more
information from an agent by reducing her own ability to observe what the agent
transmits. Intuitively, when the two parties' preferences are not perfectly
aligned, this garbling relaxes the sender's concern that the receiver will use
her information to the sender's disadvantage. We characterize the optimal
information structure for the receiver. The main result is that under broad
conditions, the receiver can do just as well as if she could commit to a rule
mapping the sender's message to actions: information design is just as good as
full commitment. Similarly, we show that these conditions guarantee that ex
ante information acquisition always benefits the receiver, even though this
learning might actually lower the receiver's expected payoff in the absence of
garbling. We illustrate these effects in a range of economically relevant
examples."
economics,Persuasion Meets Delegation,"A principal can restrict an agent's information (the persuasion problem) or
restrict an agent's discretion (the delegation problem). We show that these
problems are generally equivalent - solving one solves the other. We use tools
from the persuasion literature to generalize and extend many results in the
delegation literature, as well as to address novel delegation problems, such as
monopoly regulation with a participation constraint."
economics,The preference lattice,"Most comparisons of preferences are instances of single-crossing dominance.
We examine the lattice structure of single-crossing dominance, proving
characterisation, existence and uniqueness results for minimum upper bounds of
arbitrary sets of preferences. We apply these theorems to derive new
comparative statics theorems for collective choice and under analyst
uncertainty, to characterise a general 'maxmin' class of uncertainty-averse
preferences over Savage acts, and to revisit the tension between liberalism and
Pareto-efficiency in social choice."
economics,Persuading part of an audience,"I propose a cheap-talk model in which the sender can use private messages and
only cares about persuading a subset of her audience. For example, a candidate
only needs to persuade a majority of the electorate in order to win an
election. I find that senders can gain credibility by speaking truthfully to
some receivers while lying to others. In general settings, the model admits
information transmission in equilibrium for some prior beliefs. The sender can
approximate her preferred outcome when the fraction of the audience she needs
to persuade is sufficiently small. I characterize the sender-optimal
equilibrium and the benefit of not having to persuade your whole audience in
separable environments. I also analyze different applications and verify that
the results are robust to some perturbations of the model, including
non-transparent motives as in Crawford and Sobel (1982), and full commitment as
in Kamenica and Gentzkow (2011)."
economics,"Exact Solution for the Portfolio Diversification Problem Based on
  Maximizing the Risk Adjusted Return","The potential benefits of portfolio diversification have been known to
investors for a long time. Markowitz (1952) suggested the seminal approach for
optimizing the portfolio problem based on finding the weights as budget shares
that minimize the variance of the underlying portfolio. Hatemi-J and El-Khatib
(2015) suggested finding the weights that will result in maximizing the risk
adjusted return of the portfolio. This approach seems to be preferred by the
rational investors since it combines risk and return when the optimal budget
shares are sought for. The current paper provides a general solution for this
risk adjusted return problem that can be utilized for any potential number of
assets that are included in the portfolio."
economics,Price competition with uncertain quality and cost,"Consumers in many markets are uncertain about firms' qualities and costs, so
buy based on both the price and the quality inferred from it. Optimal pricing
depends on consumer heterogeneity only when firms with higher quality have
higher costs, regardless of whether costs and qualities are private or public.
If better quality firms have lower costs, then good quality is sold cheaper
than bad under private costs and qualities, but not under public. However, if
higher quality is costlier, then price weakly increases in quality under both
informational environments."
economics,J. S. Mill's Liberal Principle and Unanimity,"The broad concept of an individual's welfare is actually a cluster of related
specific concepts that bear a ""family resemblance"" to one another. One might
care about how a policy will affect people both in terms of their subjective
preferences and also in terms of some notion of their objective interests. This
paper provides a framework for evaluation of policies in terms of welfare
criteria that combine these two considerations. Sufficient conditions are
provided for such a criterion to imply the same ranking of social states as
does Pareto's unanimity criterion. Sufficiency is proved via study of a
community of agents with interdependent ordinal preferences."
economics,Slow persuasion,"What are the value and form of optimal persuasion when information can be
generated only slowly? We study this question in a dynamic model in which a
'sender' provides public information over time subject to a graduality
constraint, and a decision-maker takes an action in each period. Using a novel
'viscosity' dynamic programming principle, we characterise the sender's
equilibrium value function and information provision. We show that the
graduality constraint inhibits information provision relative to unconstrained
persuasion. The gap can be substantial, but closes as the constraint slackens.
Contrary to unconstrained persuasion, less-than-full information may be
provided even if players have aligned preferences but different prior beliefs."
economics,"On the core of normal form games with a continuum of players : a
  correction","We study the core of normal form games with a continuum of players and
without side payments. We consider the weak-core concept, which is an
approximation of the core, introduced by Weber, Shapley and Shubik. For payoffs
depending on the players' strategy profile, we prove that the weak-core is
nonempty. The existence result establishes a weak-core element as a limit of
elements in weak-cores of appropriate finite games. We establish by examples
that our regularity hypotheses are relevant in the continuum case and the
weak-core can be strictly larger than the Aumann's $\alpha$-core. For games
where payoffs depend on the distribution of players' strategy profile, we prove
that analogous regularity conditions ensuring the existence of pure strategy
Nash equilibria are irrelevant for the non-vacuity of the weak-core."
economics,"An interim core for normal form games and exchange economies with
  incomplete information: a correction","We consider the interim core of normal form cooperative games and exchange
economies with incomplete information based on the partition model. We develop
a solution concept that we can situate roughly between Wilson's coarse core and
Yannelis's private core. We investigate the interim negotiation of contracts
and address the two situations of contract delivery: interim and ex post. Our
solution differs from Wilson's concept because the measurability of strategies
in our solution is postponed until the consumption date (assumed with respect
to the information that will be known by the players at the consumption date).
For interim consumption, our concept differs from Yannelis's private core
because players can negotiate conditional on proper common knowledge events in
our solution, which strengthens the interim aspect of the game, as we will
illustrate with examples."
economics,Herding driven by the desire to differ,"Observational learning often involves congestion: an agent gets lower payoff
from an action when more predecessors have taken that action. This preference
to act differently from previous agents may paradoxically increase all but one
agent's probability of matching the actions of the predecessors. The reason is
that when previous agents conform to their predecessors despite the preference
to differ, their actions become more informative. The desire to match
predecessors' actions may reduce herding by a similar reasoning."
economics,Optimal mechanism for the sale of a durable good,"A buyer wishes to purchase a durable good from a seller who in each period
chooses a mechanism under limited commitment. The buyer's valuation is binary
and fully persistent. We show that posted prices implement all equilibrium
outcomes of an infinite-horizon, mechanism selection game. Despite being able
to choose mechanisms, the seller can do no better and no worse than if he chose
prices in each period, so that he is subject to Coase's conjecture. Our
analysis marries insights from information and mechanism design with those from
the literature on durable goods. We do so by relying on the revelation
principle in Doval and Skreta (2020)."
economics,Limits to green growth and the dynamics of innovation,"Central to the official ""green growth"" discourse is the conjecture that
absolute decoupling can be achieved with certain market instruments. This paper
evaluates this claim focusing on the role of technology, while changes in GDP
composition are treated elsewhere. Some fundamental difficulties for absolute
decoupling, referring specifically to thermodynamic costs, are identified
through a stylized model based on empirical knowledge on innovation and
learning. Normally, monetary costs decrease more slowly than production grows,
and this is unlikely to change should monetary costs align with thermodynamic
costs, except, potentially, in the transition after the price reform.
Furthermore, thermodynamic efficiency must eventually saturate for physical
reasons. While this model, as usual, introduces technological innovation just
as a source of efficiency, innovation also creates challenges: therefore,
attempts to sustain growth by ever-accelerating innovation collide also with
the limited reaction capacity of people and institutions. Information
technology could disrupt innovation dynamics in the future, permitting quicker
gains in eco-efficiency, but only up to saturation and exacerbating the
downsides of innovation. These observations suggest that long-term
sustainability requires much deeper transformations than the green growth
discourse presumes, exposing the need to rethink scales, tempos and
institutions, in line with ecological economics and the degrowth literature."
economics,Tax Mechanisms and Gradient Flows,"We demonstrate how a static optimal income taxation problem can be analyzed
using dynamical methods. Specifically, we show that the taxation problem is
intimately connected to the heat equation. Our first result is a new property
of the optimal tax which we call the fairness principle. The optimal tax at any
income is invariant under a family of properly adjusted Gaussian averages (the
heat kernel) of the optimal taxes at other incomes. That is, the optimal tax at
a given income is equal to the weighted by the heat kernels average of optimal
taxes at other incomes and income densities. Moreover, this averaging happens
at every scale tightly linked to each other providing a unified weighting
scheme at all income ranges. The fairness principle arises not due to equality
considerations but rather it represents an efficient way to smooth the burden
of taxes and generated revenues across incomes. Just as nature wants to
distribute heat evenly, the optimal way for a government to raise revenues is
to distribute the tax burden and raised revenues evenly among individuals. We
then construct a gradient flow of taxes -- a dynamic process changing the
existing tax system in the direction of the increase in tax revenues -- and
show that it takes the form of a heat equation. The fairness principle holds
also for the short-term asymptotics of the gradient flow, where the averaging
is done over the current taxes. The gradient flow we consider can be viewed as
a continuous process of a reform of the nonlinear income tax schedule and thus
unifies the variational approach to taxation and optimal taxation. We present
several other characteristics of the gradient flow focusing on its smoothing
properties."
economics,Reversals of signal-posterior monotonicity imply a bias of screening,"This note strengthens the main result of Lagziel and Lehrer (2019) (LL) ""A
bias in screening"" using Chambers Healy (2011) (CH) ""Reversals of
signal-posterior monotonicity for any bounded prior"". LL show that the
conditional expectation of an unobserved variable of interest, given that a
noisy signal of it exceeds a cutoff, may decrease in the cutoff. CH prove that
the distribution of a variable conditional on a lower signal may first order
stochastically dominate the distribution conditional on a higher signal.
  The nonmonotonicity result is also extended to the empirically relevant
exponential and Pareto distributions, and to a wide range of signals."
economics,"Transboundary Pollution Externalities: Think Globally, Act Locally?","We analyze the implications of transboundary pollution externalities on
environmental policymaking in a spatial and finite time horizon setting. We
focus on a simple regional optimal pollution control problem in order to
compare the global and local solutions in which, respectively, the
transboundary externality is and is not taken into account in the determination
of the optimal policy by individual local policymakers. We show that the local
solution is suboptimal and as such a global approach to environmental problems
is effectively needed. Our conclusions hold true in different frameworks,
including situations in which the spatial domain is either bounded or
unbounded, and situations in which macroeconomic-environmental feedback effects
are taken into account. We also show that if every local economy implements an
environmental policy stringent enough, then the global average level of
pollution will fall. If this is the case, over the long run the entire global
economy will be able to achieve a completely pollution-free status."
economics,"Necessary and sufficient condition for equilibrium of the Hotelling
  model on a circle","We study a model of vendors competing to sell a homogeneous product to
customers spread evenly along a circular city. This model is based on
Hotelling's celebrated paper in 1929. Our aim in this paper is to present a
necessary and sufficient condition for the equilibrium. This yields a
representation for the equilibrium. To achieve this, we first formulate the
model mathematically. Next, we prove that the condition holds if and only if
vendors are equilibrium."
economics,The Persuasion Duality,"We present a unified duality approach to Bayesian persuasion. The optimal
dual variable, interpreted as a price function on the state space, is shown to
be a supergradient of the concave closure of the objective function at the
prior belief. Strong duality holds when the objective function is Lipschitz
continuous.
  When the objective depends on the posterior belief through a set of moments,
the price function induces prices for posterior moments that solve the
corresponding dual problem. Thus, our general approach unifies known results
for one-dimensional moment persuasion, while yielding new results for the
multi-dimensional case. In particular, we provide a necessary and sufficient
condition for the optimality of convex-partitional signals, derive structural
properties of solutions, and characterize the optimal persuasion scheme in the
case when the state is two-dimensional and the objective is quadratic."
economics,Lexicographic Choice Under Variable Capacity Constraints,"In several matching markets, in order to achieve diversity, agents'
priorities are allowed to vary across an institution's available seats, and the
institution is let to choose agents in a lexicographic fashion based on a
predetermined ordering of the seats, called a (capacity-constrained)
lexicographic choice rule. We provide a characterization of lexicographic
choice rules and a characterization of deferred acceptance mechanisms that
operate based on a lexicographic choice structure under variable capacity
constraints. We discuss some implications for the Boston school choice system
and show that our analysis can be helpful in applications to select among
plausible choice rules."
economics,Persuasion with Coarse Communication,"How does an expert's ability persuade change with the availability of
messages? We study games of Bayesian persuasion the sender is unable to fully
describe every state of the world or recommend all possible actions. We
characterize the set of attainable payoffs. Sender always does worse with
coarse communication and values additional signals. We show that there exists
an upper bound on the marginal value of a signal for the sender. In a special
class of games, the marginal value of a signal is increasing when the receiver
is difficult to persuade. We show that an additional signal does not directly
translate into more information and the receiver might prefer coarse
communication. Finally, we study the geometric properties of optimal
information structures. Using these properties, we show that the sender's
optimization problem can be solved by searching within a finite set."
economics,Disclosure Games with Large Evidence Spaces,"We study a disclosure game with a large evidence space. There is an unknown
binary state. A sender observes a sequence of binary signals about the state
and discloses a left truncation of the sequence to a receiver in order to
convince him that the state is good. We focus on truth-leaning equilibria (cf.
Hart et al. (2017)), where the sender discloses truthfully when doing so is
optimal, and the receiver takes off-path disclosure at face value. In
equilibrium, seemingly sub-optimal truncations are disclosed, and the
disclosure contains the longest truncation that yields the maximal difference
between the number of good and bad signals. We also study a general framework
of disclosure games which is compatible with large evidence spaces, a wide
range of disclosure technologies, and finitely many states. We characterize the
unique equilibrium value function of the sender and propose a method to
construct equilibria for a broad class of games."
economics,Costly Verification in Collective Decisions,"We study how a principal should optimally choose between implementing a new
policy and maintaining the status quo when information relevant for the
decision is privately held by agents. Agents are strategic in revealing their
information; the principal cannot use monetary transfers to elicit this
information, but can verify an agent's claim at a cost. We characterize the
mechanism that maximizes the expected utility of the principal. This mechanism
can be implemented as a cardinal voting rule, in which agents can either cast a
baseline vote, indicating only whether they are in favor of the new policy, or
they make specific claims about their type. The principal gives more weight to
specific claims and verifies a claim whenever it is decisive."
economics,Time discounting under uncertainty,"We study intertemporal decision making under uncertainty. We fully
characterize discounted expected utility in a framework \`a la Savage. Despite
the popularity of this model, no characterization is available in this setting.
The concept of stationarity, introduced by Koopmans for deterministic
discounted utility, plays a central role for both attitudes towards time and
towards uncertainty. We show that a strong stationarity axiom characterizes
discounted expected utility. When hedging considerations are taken into
account, a weaker stationarity axiom generalizes discounted expected utility to
Choquet discounted expected utility, allowing for non-neutral attitudes towards
uncertainty."
economics,"Aggregation for potentially infinite populations without continuity or
  completeness","We present an abstract social aggregation theorem. Society, and each
individual, has a preorder that may be interpreted as expressing values or
beliefs. The preorders are allowed to violate both completeness and continuity,
and the population is allowed to be infinite. The preorders are only assumed to
be represented by functions with values in partially ordered vector spaces, and
whose product has convex range. This includes all preorders that satisfy strong
independence. Any Pareto indifferent social preorder is then shown to be
represented by a linear transformation of the representations of the individual
preorders. Further Pareto conditions on the social preorder correspond to
positivity conditions on the transformation. When all the Pareto conditions
hold and the population is finite, the social preorder is represented by a sum
of individual preorder representations. We provide two applications. The first
yields an extremely general version of Harsanyi's social aggregation theorem.
The second generalizes a classic result about linear opinion pooling."
economics,Relative Maximum Likelihood Updating of Ambiguous Beliefs,"This paper proposes and axiomatizes a new updating rule: Relative Maximum
Likelihood (RML) for ambiguous beliefs represented by a set of priors (C). This
rule takes the form of applying Bayes' rule to a subset of C. This subset is a
linear contraction of C towards its subset ascribing a maximal probability to
the observed event. The degree of contraction captures the extent of
willingness to discard priors based on likelihood when updating. Two well-known
updating rules of multiple priors, Full Bayesian (FB) and Maximum Likelihood
(ML), are included as special cases of RML. An axiomatic characterization of
conditional preferences generated by RML updating is provided when the
preferences admit Maxmin Expected Utility representations. The axiomatization
relies on weakening the axioms characterizing FB and ML. The axiom
characterizing ML is identified for the first time in this paper, addressing a
long-standing open question in the literature."
economics,Behavioral Equivalence of Extensive Game Structures,"Two extensive game structures with imperfect information are said to be
behaviorally equivalent if they share the same map (up to relabelings) from
profiles of structurally reduced strategies to induced terminal paths. We show
that this is the case if and only if one can be transformed into the other
through a composition of two elementary transformations, commonly known as
\textquotedblleft Interchanging of Simultaneous Moves\textquotedblright\ and
\textquotedblleft Coalescing Moves/Sequential Agent
Splitting.\textquotedblright"
economics,Distributionally Robust Optimal Auction Design under Mean Constraints,"We study a seller who sells a single good to multiple bidders with
uncertainty over the joint distribution of bidders' valuations, as well as
bidders' higher-order beliefs about their opponents. The seller only knows the
(possibly asymmetric) means of the marginal distributions of each bidder's
valuation and the range. An adversarial nature chooses the worst-case
distribution within this ambiguity set along with the worst-case information
structure. We find that a second-price auction with a symmetric, random reserve
price obtains the optimal revenue guarantee within a broad class of mechanisms
we refer to as competitive mechanisms, which include standard auction formats,
including the first-price auction, with or without reserve prices. The optimal
mechanism possesses two notable characteristics. First, the mechanism treats
all bidders identically even in the presence of ex-ante asymmetries. Second,
when bidders are identical and the number of bidders $n$ grows large, the
seller's optimal reserve price converges in probability to a non-binding
reserve price and the revenue guarantee converges to the best possible revenue
guarantee at rate $O(1/n)$."
economics,Information Disclosure and Promotion Policy Design for Platforms,"We consider a platform facilitating trade between sellers and buyers with the
objective of maximizing consumer surplus. Even though in many such marketplaces
prices are set by revenue-maximizing sellers, platforms can influence prices
through (i) price-dependent promotion policies that can increase demand for a
product by featuring it in a prominent position on the webpage and (ii) the
information revealed to sellers about the value of being promoted. Identifying
effective joint information design and promotion policies is a challenging
dynamic problem as sellers can sequentially learn the promotion value from
sales observations and update prices accordingly. We introduce the notion of
confounding promotion policies, which are designed to prevent a Bayesian seller
from learning the promotion value (at the expense of the short-run loss of
diverting some consumers from the best product offering). Leveraging these
policies, we characterize the maximum long-run average consumer surplus that is
achievable through joint information design and promotion policies when the
seller sets prices myopically. We then construct a Bayesian Nash equilibrium in
which the seller's best response to the platform's optimal policy is to price
myopically in every period. Moreover, the equilibrium we identify is
platform-optimal within the class of horizon-maximin equilibria, in which
strategies are not predicated on precise knowledge of the horizon length, and
are designed to maximize payoff over the worst-case horizon. Our analysis
allows one to identify practical long-run average optimal platform policies in
a broad range of demand models."
economics,Guarantees in Fair Division: general or monotone preferences,"To divide a ""manna"" {\Omega} of private items (commodities, workloads, land,
time intervals) between n agents, the worst case measure of fairness is the
welfare guaranteed to each agent, irrespective of others' preferences. If the
manna is non atomic and utilities are continuous (not necessarily monotone or
convex), we can guarantee the minMax utility: that of our agent's best share in
her worst partition of the manna; and implement it by Kuhn's generalisation of
Divide and Choose. The larger Maxmin utility -- of her worst share in her best
partition -- cannot be guaranteed, even for two agents. If for all agents more
manna is better than less (or less is better than more), our Bid & Choose rules
implement guarantees between minMax and Maxmin by letting agents bid for the
smallest (or largest) size of a share they find acceptable."
economics,"A Contribution to Theory of Factor Income Distribution, Cambridge
  Capital Controversy and Equity Premium Puzzle","Under very general conditions, we construct a micro-macro model for closed
economy with a large number of heterogeneous agents. By introducing both
financial capital (i.e. valued capital---- equities of firms) and physical
capital (i.e. capital goods), our framework gives a logically consistent,
complete factor income distribution theory with micro-foundation. The model
shows factor incomes obey different distribution rules at the micro and macro
levels, while marginal distribution theory and no-arbitrage princi-ple are
unified into a common framework. Our efforts solve the main problems of
Cambridge capital controversy, and reasonably explain the equity premium
puzzle. Strong empirical evidences support our results."
economics,Super-Nash performance in games,"Since the 1990s, artificial intelligence (AI) systems have achieved
'superhuman performance' in major zero-sum games, where winning has an
unambiguous definition. However, most economic and social interactions are
non-zero-sum, where measuring 'performance' is a non-trivial task. In this
paper, I introduce a novel benchmark, super-Nash performance, and a solution
concept, optimin, whereby every player maximizes their minimal payoff under
unilateral profitable deviations of the others. Optimin achieves super-Nash
performance in that, for every Nash equilibrium, there exists an optimin where
each player not only receives but also guarantees super-Nash payoffs, even if
other players deviate unilaterally and profitably from the optimin. Further,
optimin generalizes and unifies several key results across domains: it
coincides with (i) the maximin strategies in zero-sum games, and (ii) the core
in cooperative games when the core is nonempty, though it exists even if the
core is empty; additionally, optimin generalizes (iii) Nash equilibrium in
$n$-person constant-sum games. Finally, optimin is consistent with the
direction of non-Nash deviations in games in which cooperation has been
extensively studied, including the finitely repeated prisoner's dilemma, the
centipede game, the traveler's dilemma, and the finitely repeated public goods
game."
economics,"Refuting Samuelson's Capitulation on the Re-switching of Techniques in
  the Cambridge Capital Controversy","Paul A. Samuelson's (1966) capitulation during the so-called Cambridge
controversy on the re-switching of techniques in capital theory had
implications not only in pointing at supposed internal contradiction of the
marginal theory of production and distribution, but also in preserving vested
interests in the academic and political world. Based on a new non-switching
theorem, the present paper demonstrates that Samuelson's capitulation was
logically groundless from the point of view of the economic theory of
production."
economics,Perfect bidder collusion through bribe and request,"We study collusion in a second-price auction with two bidders in a dynamic
environment. One bidder can make a take-it-or-leave-it collusion proposal,
which consists of both an offer and a request of bribes, to the opponent. We
show that there always exists a robust equilibrium in which the collusion
success probability is one. In the equilibrium, for each type of initiator the
expected payoff is generally higher than the counterpart in any robust
equilibria of the single-option model (Es\""{o} and Schummer (2004)) and any
other separating equilibria in our model."
economics,Voluntary Disclosure and Personalized Pricing,"Central to privacy concerns is that firms may use consumer data to price
discriminate. A common policy response is that consumers should be given
control over which firms access their data and how. Since firms learn about a
consumer's preferences based on the data seen and the consumer's disclosure
choices, the equilibrium implications of consumer control are unclear. We study
whether such measures improve consumer welfare in monopolistic and competitive
markets. We find that consumer control can improve consumer welfare relative to
both perfect price discrimination and no personalized pricing. First, consumers
can use disclosure to amplify competitive forces. Second, consumers can
disclose information to induce even a monopolist to lower prices. Whether
consumer control improves welfare depends on the disclosure technology and
market competitiveness. Simple disclosure technologies suffice in competitive
markets. When facing a monopolist, a consumer needs partial disclosure
possibilities to obtain any welfare gains."
economics,Fuzzy Group Identification Problems,"We present a fuzzy version of the Group Identification Problem (""Who is a
J?"") introduced by Kasher and Rubinstein (1997). We consider a class $N =
\{1,2,\ldots,n\}$ of agents, each one with an opinion about the membership to a
group J of the members of the society, consisting in a function $\pi : N \to
[0; 1]$, indicating for each agent, including herself, the degree of membership
to J. We consider the problem of aggregating those functions, satisfying
different sets of axioms and characterizing different aggregators. While some
results are analogous to those of the originally crisp model, the fuzzy version
is able to overcome some of the main impossibility results of Kasher and
Rubinstein."
economics,A Bilateral River Bargaining Problem with Negative Externality,"This article is addressing the problem of river sharing between two agents
along a river in the presence of negative externalities. Where, each agent
claims river water based on the hydrological characteristics of the
territories. The claims can be characterized by some international framework
(principles) of entitlement. These international principles are appears to be
inequitable by the other agents in the presence of negative externalities. The
negotiated treaties address sharing water along with the issue of negative
externalities imposed by the upstream agent on the downstream agents. The
market based bargaining mechanism is used for modeling and for characterization
of agreement points."
economics,Alternative Axioms in Group Identification Problems,"Kasher and Rubinstein (1997) introduced the problem of classifying the
members of a group in terms of the opinions of their potential members. This
involves a finite set of agents $N = \{1,2,\ldots,n\}$, each one having an
opinion about which agents should be classified as belonging to a specific
subgroup J. A Collective Identity Function (CIF) aggregates those opinions
yielding the class of members deemed $J$. Kasher and Rubinstein postulate
axioms, intended to ensure fair and socially desirable outcomes, characterizing
different CIFs. We follow their lead by replacing their liberal axiom by other
axioms, constraining the spheres of influence of the agents. We show that some
of them lead to different CIFs while in another instance we find an
impossibility result."
economics,Efficient allocations in double auction markets,"This paper proposes a simple descriptive model of discrete-time double
auction markets for divisible assets. As in the classical models of exchange
economies, we consider a finite set of agents described by their initial
endowments and preferences. Instead of the classical Walrasian-type market
models, however, we assume that all trades take place in a centralized double
auction where the agents communicate through sealed limit orders for buying and
selling. We find that, under nonstrategic bidding, the double auction clears
with zero trades precisely when the agents' current holdings are on the Pareto
frontier. More interestingly, the double auctions implement Adam Smith's
""invisible hand"" in the sense that, when starting from disequilibrium, repeated
double auctions lead to a sequence of allocations that converges to
individually rational Pareto allocations."
economics,Bilateral Tariffs Under International Competition,"This paper explores the gain maximization problem of two nations engaging in
non-cooperative bilateral trade. Probabilistic model of an exchange of
commodities under different price systems is considered. Volume of commodities
exchanged determines the demand each nation has over the counter party's
currency. However, each nation can manipulate this quantity by imposing a
tariff on imported commodities. As long as the gain from trade is determined by
the balance between imported and exported commodities, such a scenario results
in a two party game where Nash equilibrium tariffs are determined for various
foreign currency demand functions and ultimately, the exchange rate based on
optimal tariffs is obtained."
economics,Targeting in social networks with anonymized information,"This paper studies whether a planner who only has information about the
network topology can discriminate among agents according to their network
position. The planner proposes a simple menu of contracts, one for each
location, in order to maximize total welfare, and agents choose among the menu.
This mechanism is immune to deviations by single agents, and to deviations by
groups of agents of sizes 2, 3 and 4 if side-payments are ruled out. However,
if compensations are allowed, groups of agents may have an incentive to jointly
deviate from the optimal contract in order to exploit other agents. We identify
network topologies for which the optimal contract is group incentive compatible
with transfers: undirected networks and regular oriented trees, and network
topologies for which the planner must assign uniform quantities: single root
and nested neighborhoods directed networks."
economics,"In Simple Communication Games, When Does Ex Ante Fact-Finding Benefit
  the Receiver?","Always, if the number of states is equal to two; or if the number of receiver
actions is equal to two and i. The number of states is three or fewer, or ii.
The game is cheap talk, or ii. There are just two available messages for the
sender. A counterexample is provided for each failure of these conditions."
economics,Agenda-manipulation in ranking,"We study the susceptibility of committee governance (e.g. by boards of
directors), modelled as the collective determination of a ranking of a set of
alternatives, to manipulation of the order in which pairs of alternatives are
voted on -- agenda-manipulation. We exhibit an agenda strategy called insertion
sort that allows a self-interested committee chair with no knowledge of how
votes will be cast to do as well as if she had complete knowledge. Strategies
with this 'regret-freeness' property are characterised by their efficiency, and
by their avoidance of two intuitive errors. What distinguishes regret-free
strategies from each other is how they prioritise among alternatives; insertion
sort prioritises lexicographically."
economics,"Compromise, Don't Optimize: Generalizing Perfect Bayesian Equilibrium to
  Allow for Ambiguity","We introduce a solution concept for extensive-form games of incomplete
information in which players need not assign likelihoods to what they do not
know about the game. This is embedded in a model in which players can hold
multiple priors. Players make choices by looking for compromises that yield a
good performance under each of their updated priors. Our solution concept is
called perfect compromise equilibrium. It generalizes perfect Bayesian
equilibrium. We show how it deals with ambiguity in Cournot and Bertrand
markets, public good provision, Spence's job market signaling, bilateral trade
with common value, and forecasting."
economics,A Model of Justification,"I consider decision-making constrained by considerations of morality,
rationality, or other virtues. The decision maker (DM) has a true preference
over outcomes, but feels compelled to choose among outcomes that are top-ranked
by some preference that he considers ""justifiable."" This model unites a broad
class of empirical work on distributional preferences, charitable donations,
prejudice/discrimination, and corruption/bribery. I provide a behavioral
characterization of the model. I also show that the set of justifications can
be identified from choice behavior when the true preference is known, and that
choice behavior substantially restricts both the true preference and
justifications when neither is known. I argue that the justifiability model
represents an advancement over existing models of rationalization because the
structure it places on possible ""rationales"" improves tractability,
interpretation and identification."
economics,Game Theoretic Consequences of Resident Matching,"The resident matching algorithm, Gale-Shapley, currently used by SF Match and
the National Residency Match Program (NRMP), has been in use for over 50 years
without fundamental alteration. The algorithm is a 'stable-marriage' method
that favors applicant outcomes. However, in these 50 years, there has been a
big shift in the supply and demand of applicants and programs. These changes
along with the way the Match is implemented have induced a costly race among
applicants to apply and interview at as many programs as possible. Meanwhile
programs also incur high costs as they maximize their probability of matching
by interviewing as many candidates as possible."
economics,Keeping the Listener Engaged: a Dynamic Model of Bayesian Persuasion,"We consider a dynamic model of Bayesian persuasion in which information takes
time and is costly for the sender to generate and for the receiver to process,
and neither player can commit to their future actions. Persuasion may totally
collapse in a Markov perfect equilibrium (MPE) of this game. However, for
persuasion costs sufficiently small, a version of a folk theorem holds:
outcomes that approximate Kamenica and Gentzkow (2011)'s sender-optimal
persuasion as well as full revelation and everything in between are obtained in
MPE, as the cost vanishes."
economics,Bemerkungen zum paarweisen Vergleich,"The simple pairwise comparison is a method to provide different criteria with
weights. We show that the values of those weights (in particular the maximum)
depend just on the number of criteria. Additionally, it is shown that the
distance between the weights is always the same.
  -----
  Der einfache paarweise Vergleich ist ein Verfahren verschiedene Kriterien mit
einer Gewichtung zu versehen. Wir zeigen, dass die Werte dieser Gewichte
(insbesondere auch der maximale Wert) ausschlie{\ss}lich von der Anzahl der
Kriterien abh\""angt. Dar\""uber hinaus wird gezeigt, dass der Abstand der
Gewichtungen stets gleich ist."
economics,Final Topology for Preference Spaces,"We say a model is continuous in utilities (resp., preferences) if small
perturbations of utility functions (resp., preferences) generate small changes
in the model's outputs. While similar, these two concepts are equivalent only
when the topology satisfies the following universal property: for each
continuous mapping from preferences to model's outputs there is a unique
mapping from utilities to model's outputs that is faithful to the preference
map and is continuous. The topologies that satisfy such a universal property
are called final topologies. In this paper we analyze the properties of the
final topology for preference sets. This is of practical importance since most
of the analysis on continuity is done via utility functions and not the
primitive preference space. Our results allow the researcher to extrapolate
continuity in utility to continuity in the underlying preferences."
economics,A Search Model of Statistical Discrimination,"We offer a search-theoretic model of statistical discrimination, in which
firms treat identical groups unequally based on their occupational choices. The
model admits symmetric equilibria in which the group characteristic is ignored,
but also asymmetric equilibria in which a group is statistically discriminated
against, even when symmetric equilibria are unique. Moreover, a robust
possibility is that symmetric equilibria become unstable when the group
characteristic is introduced. Unlike most previous literature, our model can
justify affirmative action since it eliminates asymmetric equilibria without
distorting incentives."
economics,"A geometric characterization of VES and Kadiyala-type production
  functions","The basic concepts of the differential geometry are shortly reviewed and
applied to the study of VES production function in the spirit of the works of
V\^ilcu and collaborators. A similar characterization is given for a more
general production function, namely the Kadiyala production function, in the
case of developable surfaces."
economics,Dynamically Consistent Objective and Subjective Rationality,"A group of experts, for instance climate scientists, is to choose among two
policies $f$ and $g$. Consider the following decision rule. If all experts
agree that the expected utility of $f$ is higher than the expected utility of
$g$, the unanimity rule applies, and $f$ is chosen. Otherwise the precautionary
principle is implemented and the policy yielding the highest minimal expected
utility is chosen.
  This decision rule may lead to time inconsistencies when an intermediate
period of partial resolution of uncertainty is added. We provide axioms that
enlarge the initial group of experts with veto power, which leads to a set of
probabilistic beliefs that is ""rectangular"" in a minimal sense. This makes this
decision rule dynamically consistent and provides, as a byproduct, a novel
behavioral characterization of rectangularity."
economics,Matching with Generalized Lexicographic Choice Rules,"Motivated by the need for real-world matching problems, this paper formulates
a large class of practical choice rules, Generalized Lexicographic Choice Rules
(GLCR), for institutions that consist of multiple divisions. Institutions fill
their divisions sequentially, and each division is endowed with a sub-choice
rule that satisfies classical substitutability and size monotonicity in
conjunction with a new property that we introduce, quota monotonicity. We allow
rich interactions between divisions in the form of capacity transfers. The
overall choice rule of an institution is defined as the union of the
sub-choices of its divisions. The cumulative offer mechanism (COM) with respect
to GLCR is the unique stable and strategy-proof mechanism. We define a
choice-based improvement notion and show that the COM respects improvements. We
employ the theory developed in this paper in our companion paper, Ayg\""un and
Turhan (2020), to design satisfactory matching mechanisms for India with
comprehensive affirmative action constraints."
economics,"Designing Direct Matching Mechanism for India with Comprehensive
  Affirmative Action","Since 1950, India has been implementing the most comprehensive affirmative
action program in the world. Vertical reservations are provided to members of
historically discriminated Scheduled Castes (SC), Scheduled Tribes (ST), and
Other Backward Classes (OBC). Horizontal reservations are provided for other
disadvantaged groups, such as women and disabled people, within each vertical
category. There is no well-defined procedure to implement horizontal
reservations jointly with vertical reservation and OBC de-reservations.
Sequential processes currently in use for OBC de-reservations and meritorious
reserve candidates lead to severe shortcomings. Most importantly, indirect
mechanisms currently used in practice do not allow reserve category applicants
to fully express their preferences. To overcome these and other related issues,
we design several different choice rules for institutions that take
meritocracy, vertical and horizontal reservations, and OBC de-reservations into
account. We propose a centralized mechanism to satisfactorily clear matching
markets in India."
economics,Slot-specific Priorities with Capacity Transfers,"In many real-world matching applications, there are restrictions for
institutions either on priorities of their slots or on the transferability of
unfilled slots over others (or both). Motivated by the need in such real-life
matching problems, this paper formulates a family of practical choice rules,
slot-specific priorities with capacity transfers (SSPwCT). These practical
rules invoke both slot-specific priorities structure and transferability of
vacant slots. We show that the cumulative offer mechanism (COM) is stable,
strategy-proof and respects improvements with regards to SSPwCT choice rules.
Transferring the capacity of one more unfilled slot, while all else is
constant, leads to strategy-proof Pareto improvement of the COM. Following
Kominer's (2020) formulation, we also provide comparative static results for
expansion of branch capacity and addition of new contracts in the SSPwCT
framework. Our results have implications for resource allocation problems with
diversity considerations."
economics,"Evaluating the Properties of a First Choice Weighted Approval Voting
  System","Plurality and approval voting are two well-known voting systems with
different strengths and weaknesses. In this paper we consider a new voting
system we call beta(k) which allows voters to select a single first-choice
candidate and approve of any other number of candidates, where k denotes the
relative weight given to a first choice; this system is essentially a hybrid of
plurality and approval. Our primary goal is to characterize the behavior of
beta(k) for any value of k. Under certain reasonable assumptions, beta(k) can
be made to mimic plurality or approval voting in the event of a single winner
while potentially breaking ties otherwise. Under the assumption that voters are
honest, we show that it is possible to find the values of k for which a given
candidate will win the election if the respective approval and plurality votes
are known. Finally, we show how some of the commonly used voting system
criteria are satisfied by beta(k)."
economics,Extractive contest design,"We consider contest success functions (CSFs) that extract contestants' prize
values. In the common-value case, there exists a CSF extractive in any
equilibrium. In the observable-private-value case, there exists a CSF
extractive in some equilibrium; there exists a CSF extractive in any
equilibrium if and only if the number of contestants is greater than or equal
to three or the values are homogeneous. In the unobservable-private-value case,
there exists no CSF extractive in some equilibrium. When extractive CSFs exist,
we explicitly present one of them."
economics,"The importance of being discrete: on the inaccuracy of continuous
  approximations in auction theory","While auction theory views bids and valuations as continuous variables,
real-world auctions are necessarily discrete. In this paper, we use a
combination of analytical and computational methods to investigate whether
incorporating discreteness substantially changes the predictions of auction
theory, focusing on the case of uniformly distributed valuations so that our
results bear on the majority of auction experiments. In some cases, we find
that introducing discreteness changes little. For example, the first-price
auction with two bidders and an even number of values has a symmetric
equilibrium that closely resembles its continuous counterpart and converges to
its continuous counterpart as the discretisation goes to zero. In others,
however, we uncover discontinuity results. For instance, introducing an
arbitrarily small amount of discreteness into the all-pay auction makes its
symmetric, pure-strategy equilibrium disappear; and appears (based on
computational experiments) to rob the game of pure-strategy equilibria
altogether. These results raise questions about the continuity approximations
on which auction theory is based and prompt a re-evaluation of the experimental
literature."
economics,Innovation and imitation,"We study several models of growth driven by innovation and imitation by a
continuum of firms, focusing on the interaction between the two. We first
investigate a model on a technology ladder where innovation and imitation
combine to generate a balanced growth path (BGP) with compact support, and with
productivity distributions for firms that are truncated power-laws. We start
with a simple model where firms can adopt technologies of other firms with
higher productivities according to exogenous probabilities. We then study the
case where the adoption probabilities depend on the probability distribution of
productivities at each time. We finally consider models with a finite number of
firms, which by construction have firm productivity distributions with bounded
support. Stochastic imitation and innovation can make the distance of the
productivity frontier to the lowest productivity level fluctuate, and this
distance can occasionally become large. Alternatively, if we fix the length of
the support of the productivity distribution because firms too far from the
frontier cannot survive, the number of firms can fluctuate randomly."
economics,Delegation in Veto Bargaining,"A proposer requires the approval of a veto player to change a status quo.
Preferences are single peaked. Proposer is uncertain about Vetoer's ideal
point. We study Proposer's optimal mechanism without transfers. Vetoer is given
a menu, or a delegation set, to choose from. The optimal delegation set
balances the extent of Proposer's compromise with the risk of a veto. Under
reasonable conditions, ""full delegation"" is optimal: Vetoer can choose any
action between the status quo and Proposer's ideal action. This outcome largely
nullifies Proposer's bargaining power; Vetoer frequently obtains her ideal
point, and there is Pareto efficiency despite asymmetric information. More
generally, we identify when ""interval delegation"" is optimal. Optimal interval
delegation can be a Pareto improvement over cheap talk. We derive comparative
statics. Vetoer receives less discretion when preferences are more likely to be
aligned, by contrast to expertise-based delegation. Methodologically, our
analysis handles stochastic mechanisms."
economics,Incentives and Efficiency in Constrained Allocation Mechanisms,"We study private-good allocation under general constraints. Several prominent
examples are special cases, including house allocation, roommate matching,
social choice, and multiple assignment. Every individually strategy-proof and
Pareto efficient two-agent mechanism is an ""adapted local dictatorship."" Every
group strategy-proof N-agent mechanism has two-agent marginal mechanisms that
are adapted local dictatorships. These results yield new characterizations and
unifying insights for known characterizations. We find all group strategy-proof
and Pareto efficient mechanisms for the roommates problem. We give a related
result for multiple assignment. We prove the Gibbard--Satterthwaite Theorem and
give a partial converse."
economics,Optimal Attention Management: A Tractable Framework,"A well-intentioned principal provides information to a rationally inattentive
agent without internalizing the agent's cost of processing information.
Whatever information the principal makes available, the agent may choose to
ignore some. We study optimal information provision in a tractable model with
quadratic payoffs where full disclosure is not optimal. We characterize
incentive-compatible information policies, that is, those to which the agent
willingly pays full attention. In a leading example with three states, optimal
disclosure involves information distortion at intermediate costs of attention.
As the cost increases, optimal information abruptly changes from downplaying
the state to exaggerating the state."
economics,Reputation Building under Observational Learning,"I study a social learning model in which the object to learn is a strategic
player's endogenous actions rather than an exogenous state. A patient seller
faces a sequence of buyers and decides whether to build a reputation for
supplying high quality products. Each buyer does not have access to the
seller's complete records, but can observe all previous buyers' actions, and
some informative private signal about the seller's actions. I examine how the
buyers' private signals affect the speed of social learning and the seller's
incentives to establish reputations. When each buyer privately observes a
bounded subset of the seller's past actions, the speed of learning is strictly
positive but can vanish to zero as the seller becomes patient. As a result,
reputation building can lead to low payoff for the patient seller and low
social welfare. When each buyer observes an unboundedly informative private
signal about the seller's current-period action, the speed of learning is
uniformly bounded from below and a patient seller can secure high returns from
building reputations. My results shed light on the effectiveness of various
policies in accelerating social learning and encouraging sellers to establish
good reputations."
economics,Repeated Communication with Private Lying Cost,"I study repeated communication games between a patient sender and a sequence
of receivers. The sender has persistent private information about his
psychological cost of lying, and in every period, can privately observe the
realization of an i.i.d. state before communication takes place. I characterize
every type of sender's highest equilibrium payoff. When the highest lying cost
in the support of the receivers' prior belief approaches the sender's benefit
from lying, every type's highest equilibrium payoff in the repeated
communication game converges to his equilibrium payoff in a one-shot Bayesian
persuasion game. I also show that in every sender-optimal equilibrium, no type
of sender mixes between telling the truth and lying at every history. When
there exist ethical types whose lying costs outweigh their benefits, I provide
necessary and sufficient conditions for all non-ethical type senders to attain
their optimal commitment payoffs. I identify an outside option effect through
which the possibility of being ethical decreases every non-ethical type's
payoff."
economics,"Trust and Betrayals: Reputational Payoffs and Behaviors without
  Commitment","I study a repeated game in which a patient player (e.g., a seller) wants to
win the trust of some myopic opponents (e.g., buyers) but can strictly benefit
from betraying them. Her benefit from betrayal is strictly positive and is her
persistent private information. I characterize every type of patient player's
highest equilibrium payoff. Her persistent private information affects this
payoff only through the lowest benefit in the support of her opponents' prior
belief. I also show that in every equilibrium which is optimal for the patient
player, her on-path behavior is nonstationary, and her long-run action
frequencies are pinned down for all except two types. Conceptually, my
payoff-type approach incorporates a realistic concern that no type of
reputation-building player is immune to reneging temptations. Compared to
commitment-type models, the incentive constraints for all types of patient
player lead to a sharp characterization of her highest attainable payoff and
novel predictions on her behaviors."
economics,"Nash SIR: An Economic-Epidemiological Model of Strategic Behavior During
  a Viral Epidemic","This paper develops a Nash-equilibrium extension of the classic SIR model of
infectious-disease epidemiology (""Nash SIR""), endogenizing people's decisions
whether to engage in economic activity during a viral epidemic and allowing for
complementarity in social-economic activity. An equilibrium epidemic is one in
which Nash equilibrium behavior during the epidemic generates the epidemic.
There may be multiple equilibrium epidemics, in which case the epidemic
trajectory can be shaped through the coordination of expectations, in addition
to other sorts of interventions such as stay-at-home orders and accelerated
vaccine development. An algorithm is provided to compute all equilibrium
epidemics."
economics,"Mechanism of Instrumental Game Theory in The Legal Process via
  Stochastic Options Pricing Induction","Economic theory has provided an estimable intuition in understanding the
perplexing ideologies in law, in the areas of economic law, tort law, contract
law, procedural law and many others. Most legal systems require the parties
involved in a legal dispute to exchange information through a process called
discovery. The purpose is to reduce the relative optimisms developed by
asymmetric information between the parties. Like a head or tail phenomenon in
stochastic processes, uncertainty in the adjudication affects the decisions of
the parties in a legal negotiation. This paper therefore applies the principles
of aleatory analysis to determine how negotiations fail in the legal process,
introduce the axiological concept of optimal transaction cost and formulates a
numerical methodology based on backwards induction and stochastic options
pricing economics in estimating the reasonable and fair bargain in order to
induce settlements thereby increasing efficiency and reducing social costs."
economics,The uniqueness of dynamic Groves mechanisms on restricted domains,"This paper examines necessary and sufficient conditions for the uniqueness of
dynamic Groves mechanisms when the domain of valuations is restricted. Our
approach is to appropriately define the total valuation function, which is the
expected discounted sum of each period's valuation function from the allocation
and thus a dynamic counterpart of the static valuation function, and then to
port the results for static Groves mechanisms to the dynamic setting."
economics,Comparative Statics in Multicriteria Search Models,"McCall (1970) examines the search behaviour of an infinitely-lived and
risk-neutral job seeker maximizing her lifetime earnings by accepting or
rejecting real-valued scalar wage offers. In practice, job offers have multiple
attributes, and job seekers solve a multicriteria search problem. This paper
presents a multicriteria search model and new comparative statics results."
economics,Social Welfare in Search Games with Asymmetric Information,"We consider games in which players search for a hidden prize, and they have
asymmetric information about the prize location. We study the social payoff in
equilibria of these games. We present sufficient conditions for the existence
of an equilibrium that yields the first-best payoff (i.e., the highest social
payoff under any strategy profile), and we characterize the first-best payoff.
The results have interesting implications for innovation contests and R&D
races."
economics,Revealing Choice Bracketing,"In a decision problem comprised of multiple choices, a person may fail to
take into account the interdependencies between their choices. To understand
how people make decisions in such problems, we design a novel experiment and
revealed preference tests that determine how each subject brackets their
choices. In separate portfolio allocation under risk, social allocation, and
induced-value function shopping experiments, we find that 40-43% of our
subjects are consistent with narrow bracketing while 0-15% are consistent with
broad bracketing. Adjusting for each model's predictive precision, 74% of
subjects are best described by narrow bracketing, 13% by broad bracketing, and
6% by intermediate cases."
economics,Biased-Belief Equilibrium,"We investigate how distorted, yet structured, beliefs can persist in
strategic situations. Specifically, we study two-player games in which each
player is endowed with a biased-belief function that represents the discrepancy
between a player's beliefs about the opponent's strategy and the actual
strategy. Our equilibrium condition requires that (i) each player choose a
best-response strategy to his distorted belief about the opponent's strategy,
and (ii) the distortion functions form best responses to one another. We obtain
sharp predictions and novel insights into the set of stable outcomes and their
supporting stable biases in various classes of games."
economics,"Coevolution of deception and preferences: Darwin and Nash meet
  Machiavelli","We develop a framework in which individuals' preferences coevolve with their
abilities to deceive others about their preferences and intentions.
Specifically, individuals are characterised by (i) a level of cognitive
sophistication and (ii) a subjective utility function. Increased cognition is
costly, but higher-level individuals have the advantage of being able to
deceive lower-level opponents about their preferences and intentions in some of
the matches. In the remaining matches, the individuals observe each other's
preferences. Our main result shows that, essentially, only efficient outcomes
can be stable. Moreover, under additional mild assumptions, we show that an
efficient outcome is stable if and only if the gain from unilateral deviation
is smaller than the effective cost of deception in the environment."
economics,"A closed-form solution to the risk-taking motivation of subordinated
  debtholders","Black and Cox (1976) claim that the value of junior debt is increasing in
asset risk when the firm's value is low. We show, using closed-form solution,
that the junior debt's value is hump-shaped. This has interesting implications
for the market-discipline role of banks' junior debt."
economics,Observations on Cooperation,"We study environments in which agents are randomly matched to play a
Prisoner's Dilemma, and each player observes a few of the partner's past
actions against previous opponents. We depart from the existing related
literature by allowing a small fraction of the population to be commitment
types. The presence of committed agents destabilizes previously proposed
mechanisms for sustaining cooperation. We present a novel intuitive combination
of strategies that sustains cooperation in various environments. Moreover, we
show that under an additional assumption of stationarity, this combination of
strategies is essentially the unique mechanism to support full cooperation, and
it is robust to various perturbations. Finally, we extend the results to a
setup in which agents also observe actions played by past opponents against the
current partner, and we characterize which observation structure is optimal for
sustaining cooperation."
economics,Reputation for Playing Mixed Actions: A Characterization Theorem,"A patient player privately observes a persistent state that directly affects
his myopic opponents' payoffs, and can be one of the several commitment types
that plays the same mixed action in every period. I characterize the set of
environments under which the patient player obtains at least his commitment
payoff in all equilibria regardless of his stage-game payoff function. Due to
interdependent values, the patient player cannot guarantee his mixed commitment
payoff by imitating the mixed-strategy commitment type, and small perturbations
to a pure commitment action can significantly reduce the patient player's
guaranteed equilibrium payoff."
economics,"Fair Allocation of Vaccines, Ventilators and Antiviral Treatments:
  Leaving No Ethical Value Behind in Health Care Rationing","A priority system has traditionally been the protocol of choice for the
allocation of scarce life-saving resources during public health emergencies.
Covid-19 revealed the limitations of this allocation rule. Many argue that
priority systems abandon ethical values such as equity by discriminating
against disadvantaged communities. We show that a restrictive feature of the
traditional priority system largely drives these limitations. Following
minimalist market design, an institution design paradigm that integrates
research and policy efforts, we formulate pandemic allocation of scarce
life-saving resources as a new application of market design. Interfering only
with the restrictive feature of the priority system to address its
shortcomings, we formulate a reserve system as an alternative allocation rule.
Our theoretical analysis develops a general theory of reserve design. We relate
our analysis to debates during Covid-19 and describe the impact of our paper on
policy and practice."
economics,Robust Sequential Search,"We study sequential search without priors. Our interest lies in decision
rules that are close to being optimal under each prior and after each history.
We call these rules dynamically robust. The search literature employs optimal
rules based on cutoff strategies that are not dynamically robust. We derive
dynamically robust rules and show that their performance exceeds 1/2 of the
optimum against binary environments and 1/4 of the optimum against all
environments. This performance improves substantially with the outside option
value, for instance, it exceeds 2/3 of the optimum if the outside option
exceeds 1/6 of the highest possible alternative."
economics,Existence and uniqueness of recursive utilities without boundedness,"This paper derives primitive, easily verifiable sufficient conditions for
existence and uniqueness of (stochastic) recursive utilities for several
important classes of preferences. In order to accommodate models commonly used
in practice, we allow both the state-space and per-period utilities to be
unbounded. For many of the models we study, existence and uniqueness is
established under a single, primitive ""thin tail"" condition on the distribution
of growth in per-period utilities. We present several applications to robust
preferences, models of ambiguity aversion and learning about hidden states, and
Epstein-Zin preferences."
economics,Connected Incomplete Preferences,"The standard model of choice in economics is the maximization of a complete
and transitive preference relation over a fixed set of alternatives. While
completeness of preferences is usually regarded as a strong assumption,
weakening it requires care to ensure that the resulting model still has enough
structure to yield interesting results. This paper takes a step in this
direction by studying the class of ""connected preferences"", that is,
preferences that may fail to be complete but have connected maximal domains of
comparability. We offer four new results. Theorem 1 identifies a basic
necessary condition for a continuous preference to be connected in the sense
above, while Theorem 2 provides sufficient conditions. Building on the latter,
Theorem 3 characterizes the maximal domains of comparability. Finally, Theorem
4 presents conditions that ensure that maximal domains are arc-connected."
economics,"Exact solutions for a Solow-Swan model with non-constant returns to
  scale","The Solow-Swan model is shortly reviewed from a mathematical point of view.
By considering non-constant returns to scale, we obtain a general solution
strategy. We then compute the exact solution for the Cobb-Douglas production
function, for both the classical model and the von Bertalanffy model. Numerical
simulations are provided."
economics,Mobility and Social Efficiency,"This is a general competitive analysis paper. A model is presented that
describes how an individual with a physical disability, or mobility impairment,
would go about utility maximization. These results are then generalized.
Subsequently, a selection of disability policies from Canada and the United
States are compared to the insights of the model, and it is shown that there
are sources of inefficiency in many North American disability support systems."
economics,Competing Persuaders in Zero-Sum Games,"We study Bayesian Persuasion with multiple senders who have access to
conditionally independent experiments (and possibly others). Senders have
zero-sum preferences over information revealed. We characterize when any set of
states can be pooled in equilibrium and when all equilibria are fully
revealing. The state is fully revealed in every equilibrium if and only if
sender utility functions are `globally nonlinear'. With two states, this is
equivalent to some sender having nontrivial preferences. The upshot is that
`most' zero-sum sender preferences result in full revelation. We explore what
conditions are important for competition to result in such stark information
revelation."
economics,A theoretical look at ELECTRE TRI-nB and related sorting models,"Electre Tri is a set of methods designed to sort alternatives evaluated on
several criteria into ordered categories. In these methods, alternatives are
assigned to categories by comparing them with reference profiles that represent
either the boundary or central elements of the category. The original Electre
Tri-B method uses one limiting profile for separating a category from the
category below. A more recent method, Electre Tri-nB, allows one to use several
limiting profiles for the same purpose. We investigate the properties of
Electre Tri-nB using a conjoint measurement framework. When the number of
limiting profiles used to define each category is not restricted, Electre
Tri-nB is easy to characterize axiomatically and is found to be equivalent to
several other methods proposed in the literature. We extend this result in
various directions."
economics,Optimal Rating Design under Moral Hazard,"We examine the design of optimal rating systems in the presence of moral
hazard. First, an intermediary commits to a rating scheme. Then, a
decision-maker chooses an action that generates value for the buyer. The
intermediary then observes a noisy signal of the decision-maker's choice and
sends the buyer a signal consistent with the rating scheme. Here we fully
characterize the set of allocations that can arise in equilibrium under any
arbitrary rating system. We use this characterization to study various design
aspects of optimal rating systems. Specifically, we study the properties of
optimal ratings when the decision-maker's effort is productive and when the
decision-maker can manipulate the intermediary's signal with a noise. With
manipulation, rating uncertainty is a fairly robust feature of optimal rating
systems."
economics,Lindahl Equilibrium as a Collective Choice Rule,"A collective choice problem is a finite set of social alternatives and a
finite set of economic agents with vNM utility functions. We associate a public
goods economy with each collective choice problem and establish the existence
and efficiency of (equal income) Lindahl equilibrium allocations. We interpret
collective choice problems as cooperative bargaining problems and define a
set-valued solution concept, {\it the equitable solution} (ES). We provide
axioms that characterize ES and show that ES contains the Nash bargaining
solution. Our main result shows that the set of ES payoffs is the same a the
set of Lindahl equilibrium payoffs. We consider two applications: in the first,
we show that in a large class of matching problems without transfers the set of
Lindahl equilibrium payoffs is the same as the set of (equal income) Walrasian
equilibrium payoffs. In our second application, we show that in any discrete
exchange economy without transfers every Walrasian equilibrium payoff is a
Lindahl equilibrium payoff of the corresponding collective choice market.
Moreover, for any cooperative bargaining problem, it is possible to define a
set of commodities so that the resulting economy's utility possibility set is
that bargaining problem {\it and} the resulting economy's set of Walrasian
equilibrium payoffs is the same as the set of Lindahl equilibrium payoffs of
the corresponding collective choice market."
economics,"Transaction Costs: Economies of Scale, Optimum, Equilibrium and
  Efficiency","The aim of this article is to propose a core game theory model of transaction
costs wherein it is indicated how direct costs determine the probability of
loss and subsequent transaction costs. The existence of optimum is proven, and
the way in which exposure influences the location of the optimum is
demonstrated. The decisions are described as a two-player game and it is
discussed how the transaction cost sharing rule determines whether the optimum
point of transaction costs is the same as the equilibrium of the game. A game
modelling dispute between actors regarding changing the share of transaction
costs to be paid by each party is also presented. Requirements of efficient
transaction cost sharing rules are defined, and it is posited that a solution
exists which is not unique. Policy conclusions are also devised based on
principles of design of institutions to influence the nature of transaction
costs."
economics,"""Near"" Weighted Utilitarian Characterizations of Pareto Optima","We characterize Pareto optimality via ""near"" weighted utilitarian welfare
maximization. One characterization sequentially maximizes utilitarian welfare
functions using a finite sequence of nonnegative and eventually positive
welfare weights. The other maximizes a utilitarian welfare function with a
certain class of positive hyperreal weights. The social welfare ordering
represented by these ""near"" weighted utilitarian welfare criteria is
characterized by the standard axioms for weighted utilitarianism under a
suitable weakening of the continuity axiom."
economics,Optimal Echo Chambers,"When learning from others, people tend to focus their attention on those with
similar views. This is often attributed to flawed reasoning, and thought to
slow learning and polarize beliefs. However, we show that echo chambers are a
rational response to uncertainty about the accuracy of information sources, and
can improve learning and reduce disagreement. Furthermore, overextending the
range of views someone is exposed to can backfire, slowing their learning by
making them less responsive to information from others. We model a Bayesian
decision maker who chooses a set of information sources and then observes a
signal from one. With uncertainty about which sources are accurate, focusing
attention on signals close to one's own expectation can be beneficial, as their
expected accuracy is higher. The optimal echo chamber balances the credibility
of views similar to one's own against the usefulness of those further away."
economics,Debreu's open gap lemma for semiorders,"The problem of finding a (continuous) utility function for a semiorder has
been studied since in 1956 R.D. Luce introduced in \emph{Econometrica} the
notion. There was almost no results on the continuity of the representation. A
similar result to Debreu's Lemma, but for semiorders, was never achieved.
Recently, some necessary conditions for the existence of a continuous
representation as well as some conjectures were presented by A. Estevan. In the
present paper we prove these conjectures, achieving the desired version of
Debreu's Open Gap Lemma for bounded semiorders. This result allows to remove
the open-closed and closed-open gaps of a subset $S\subseteq \mathbb{R}$, but
now keeping the constant threshold, so that $x+1<y$ if and only if $g(x)+1<g(y)
\, (x,y\in S)$. Therefore, the continuous representation (in the sense of
Scott-Suppes) of bounded semiorders is characterized. These results are
achieved thanks to the key notion of $\epsilon$-continuity, which generalizes
the idea of continuity for semiorders."
economics,Proportional resource allocation in dynamic n-player Blotto games,"A variety of social, economic, and political interactions have long been
modelled after Blotto games. In this paper, we introduce a general model of
dynamic $n$-player Blotto contests. The players have asymmetric resources, and
the battlefield prizes are not necessarily homogeneous. Each player's
probability of winning the prize in a battlefield is governed by a contest
success function and players' resource allocation on that battlefield. We show
that there exists a subgame perfect equilibrium in which players allocate their
resources proportional to the battlefield prizes for every history. This result
is robust to exogenous resource shocks throughout the game."
economics,Ambiguous Persuasion: An Ex-Ante Formulation,"Consider a persuasion game where both the sender and receiver are ambiguity
averse with maxmin expected utility (MEU) preferences and the sender can choose
to design an ambiguous information structure. This paper studies the game with
an ex-ante formulation: The sender first commits to a (possibly ambiguous)
information structure and then the receiver best responds by choosing an
ex-ante message-contingent action plan. Under this formulation, I show it is
never strictly beneficial for the sender to use an ambiguous information
structure as opposed to a standard (unambiguous) information structure. This
result is shown to be robust to the receiver having non-MEU Uncertainty Averse
preferences but not to the sender having non-MEU preferences."
economics,Non-Additive Axiologies in Large Worlds,"Is the overall value of a world just the sum of values contributed by each
value-bearing entity in that world? Additively separable axiologies (like total
utilitarianism, prioritarianism, and critical level views) say 'yes', but
non-additive axiologies (like average utilitarianism, rank-discounted
utilitarianism, and variable value views) say 'no'. This distinction is
practically important: additive axiologies support 'arguments from astronomical
scale' which suggest (among other things) that it is overwhelmingly important
for humanity to avoid premature extinction and ensure the existence of a large
future population, while non-additive axiologies need not. We show, however,
that when there is a large enough 'background population' unaffected by our
choices, a wide range of non-additive axiologies converge in their implications
with some additive axiology -- for instance, average utilitarianism converges
to critical-level utilitarianism and various egalitarian theories converge to
prioritiarianism. We further argue that real-world background populations may
be large enough to make these limit results practically significant. This means
that arguments from astronomical scale, and other arguments in practical ethics
that seem to presuppose additive separability, may be truth-preserving in
practice whether or not we accept additive separability as a basic axiological
principle."
economics,Background risk and small-stakes risk aversion,"We show that under plausible levels of background risk, no theory of choice
under risk -- such as expected utility theory, prospect theory, or rank
dependent utility -- can simultaneously satisfy the following three economic
postulates: (i) Decision makers are risk-averse over small gambles, (ii) they
respect stochastic dominance, and (iii) they account for background risk."
economics,An Application of Hölder's Inequality to Economics,"We use H\""older's inequality to get simple derivations of certain economic
formulas involving CES, Armington, or $n$-stage Armington functions."
economics,The Large Core of College Admission Markets: Theory and Evidence,"We study stable allocations in college admissions markets where students can
attend the same college under different financial terms. The deferred
acceptance algorithm identifies a stable allocation where funding is allocated
based on merit. While merit-based stable allocations assign the same students
to college, non-merit-based stable allocations may differ in the number of
students assigned to college. In large markets, this possibility requires
heterogeneity in applicants' sensitivity to financial terms. In Hungary, where
such heterogeneity is present, a non-merit-based stable allocation would
increase the number of assigned applicants by 1.9%, and affect 8.3% of the
applicants relative to any merit-based stable allocation. These findings
contrast sharply with findings from the matching (without contracts)
literature."
economics,A Model of Choice with Minimal Compromise,"I formulate and characterize the following two-stage choice behavior. The
decision maker is endowed with two preferences. She shortlists all maximal
alternatives according to the first preference. If the first preference is
decisive, in the sense that it shortlists a unique alternative, then that
alternative is the choice. If multiple alternatives are shortlisted, then, in a
second stage, the second preference vetoes its minimal alternative in the
shortlist, and the remaining members of the shortlist form the choice set. Only
the final choice set is observable. I assume that the first preference is a
weak order and the second is a linear order. Hence the shortlist is fully
rationalizable but one of its members can drop out in the second stage, leading
to bounded rational behavior. Given the asymmetric roles played by the
underlying binary relations, the consequent behavior exhibits a minimal
compromise between two preferences. To our knowledge it is the first Choice
function that satisfies Sen's $\beta$ axiom of choice,but not $\alpha$."
economics,Information Design in Optimal Auctions,"We study the information design problem in a single-unit auction setting. The
information designer controls independent private signals according to which
the buyers infer their binary private values. Assuming that the seller adopts
the optimal auction due to Myerson (1981) in response, we characterize both the
buyer-optimal information structure, which maximizes the buyers' surplus, and
the sellerworst information structure, which minimizes the seller's revenue. We
translate both information design problems into finite-dimensional, constrained
optimization problems in which one can explicitly solve for the optimal
information structures. In contrast to the case with one buyer (Roesler and
Szentes, 2017), we show that with two or more buyers, the symmetric
buyer-optimal information structure is different from the symmetric
seller-worst information structure. The good is always sold under the
seller-worst information structure but not under the buyer-optimal information
structure. Nevertheless, as the number of buyers goes to infinity, both
symmetric information structures converge to no disclosure. We also show that
in an ex ante symmetric setting, an asymmetric information structure is never
seller-worst but can generate a strictly higher surplus for the buyers than the
symmetric buyer-optimal information structure."
economics,The Duopoly Analysis of Graphics Card Market,"By analyzing the duopoly market of computer graphics cards, we categorized
the effects of enterprise's technological progress into two types, namely, cost
reduction and product diversification. Our model proved that technological
progress is the most effective means for enterprises in this industry to
increase profits. Due to the technology-intensive nature of this industry,
monopolistic enterprises face more intense competition compared with
traditional manufacturing. Therefore, they have more motivation for
technological innovation. Enterprises aiming at maximizing profits have
incentives to reduce costs and achieve a higher degree of product
differentiation through technological innovation."
economics,Naive analytics equilibrium,"We study interactions with uncertainty about demand sensitivity. In our
solution concept (1) firms choose seemingly-optimal strategies given the level
of sophistication of their data analytics, and (2) the levels of sophistication
form best responses to one another. Under the ensuing equilibrium firms
underestimate price elasticities and overestimate advertising effectiveness, as
observed empirically. The misestimates cause firms to set prices too high and
to over-advertise. In games with strategic complements (substitutes), profits
Pareto dominate (are dominated by) those of the Nash equilibrium. Applying the
model to team production games explains the prevalence of overconfidence among
entrepreneurs and salespeople."
economics,Strategy-proof and Envy-free Mechanisms for House Allocation,"We consider the problem of allocating indivisible objects to agents when
agents have strict preferences over objects. There are inherent trade-offs
between competing notions of efficiency, fairness and incentives in assignment
mechanisms. It is, therefore, natural to consider mechanisms that satisfy two
of these three properties in their strongest notions, while trying to improve
on the third dimension. In this paper, we are motivated by the following
question: Is there a strategy-proof and envy-free random assignment mechanism
more efficient than equal division?
  Our contributions in this paper are twofold. First, we further explore the
incompatibility between efficiency and envy-freeness in the class of
strategy-proof mechanisms. We define a new notion of efficiency that is weaker
than ex-post efficiency and prove that any strategy-proof and envy-free
mechanism must sacrifice efficiency even in this very weak sense. Next, we
introduce a new family of mechanisms called Pairwise Exchange mechanisms and
make the surprising observation that strategy-proofness is equivalent to
envy-freeness within this class. We characterize the set of all neutral and
strategy-proof (and hence, also envy-free) mechanisms in this family and show
that they admit a very simple linear representation."
economics,Bus operators in competition: a directed location approach,"We present a directed variant of Salop (1979) model to analyze bus transport
dynamics. The players are operators competing in cooperative and
non-cooperative games. Utility, like in most bus concession schemes in emerging
countries, is proportional to the total fare collection. Competition for
picking up passengers leads to well documented and dangerous driving practices
that cause road accidents, traffic congestion and pollution. We obtain
theoretical results that support the existence and implementation of such
practices, and give a qualitative description of how they come to occur. In
addition, our results allow to compare the current or base transport system
with a more cooperative one."
economics,Strength in Numbers: Robust Mechanisms for Public Goods with Many Agents,"This study examines the mechanism design problem for public goods provision
in a large economy with $n$ independent agents. We propose a class of
dominant-strategy incentive compatible and ex-post individually rational
mechanisms, which we call the adjusted mean-thresholding (AMT) mechanisms. We
show that when the cost of provision grows slower than the $\sqrt{n}$-rate, the
AMT mechanisms are both eventually ex-ante budget balanced and asymptotically
efficient. When the cost grows faster than the $\sqrt{n}$-rate, in contrast, we
show that any incentive compatible, individually rational, and eventually
ex-ante budget balanced mechanism must have provision probability converging to
zero and hence cannot be asymptotically efficient. The AMT mechanisms have a
simple form and are more informationally robust when compared to, for example,
the second-best mechanism. This is because the construction of an AMT mechanism
depends only on the first moment of the valuation distribution."
economics,Assignment mechanisms: common preferences and information acquisition,"I study costly information acquisition in a two-sided matching problem, such
as matching applicants to schools. An applicant's utility is a sum of common
and idiosyncratic components. The idiosyncratic component is unknown to the
applicant but can be learned at a cost. When applicants are assigned using an
ordinal strategy-proof mechanism, too few acquire information, generating a
significant welfare loss. Affirmative action and other realistic policies may
lead to a Pareto improvement. As incentives to acquire information differ
across mechanisms, ignoring such incentives may lead to incorrect welfare
assessments, for example, in comparing a popular Immediate Assignment and an
ordinal strategy-proof mechanism."
economics,DKPRG or how to succeed in the Kolkata Paise Restaurant gamevia TSP,"The Kolkata Paise Restaurant Problem is a challenging game, in which $n$
agents must decide where to have lunch during their lunch break. The game is
very interesting because there are exactly $n$ restaurants and each restaurant
can accommodate only one agent. If two or more agents happen to choose the same
restaurant, only one gets served and the others have to return back to work
hungry. In this paper we tackle this problem from an entirely new angle. We
abolish certain implicit assumptions, which allows us to propose a novel
strategy that results in greater utilization for the restaurants. We emphasize
the spatially distributed nature of our approach, which, for the first time,
perceives the locations of the restaurants as uniformly distributed in the
entire city area. This critical change in perspective has profound
ramifications in the topological layout of the restaurants, which now makes it
completely realistic to assume that every agent has a second chance. Every
agent now may visit, in case of failure, more than one restaurants, within the
predefined time constraints."
economics,Leadership and Institutional Reforms,"Large-scale institutional changes require strong commitment and involvement
of all stakeholders. We use the standard framework of cooperative game theory
developed by Ichiishi (1983, pp. 78-149) to: (i) establish analytically the
difference between policy maker and political leader; (ii) formally study
interactions between a policy maker and his followers; (iii) examine the role
of leadership in the implementation of structural reforms. We show that a
policy maker can be both partisan and non-partisan, while a political leader
can only be non-partisan. Following this distinction, we derive the probability
of success of an institutional change, as well as the nature of the gain that
such a change would generate on the beneficiary population. Based on the
restrictions of this simple mathematical model and using some evidence from the
Congolese experience between 2012 and 2016, we show that institutional changes
can indeed benefit the majority of the population, when policy makers are truly
partisan."
economics,Machine Learning for Strategic Inference,"We study interactions between strategic players and markets whose behavior is
guided by an algorithm. Algorithms use data from prior interactions and a
limited set of decision rules to prescribe actions. While as-if rational play
need not emerge if the algorithm is constrained, it is possible to guide
behavior across a rich set of possible environments using limited details.
Provided a condition known as weak learnability holds, Adaptive Boosting
algorithms can be specified to induce behavior that is (approximately) as-if
rational. Our analysis provides a statistical perspective on the study of
endogenous model misspecification."
economics,Optimal Disclosure of Information to a Privately Informed Receiver,"We study information design settings where the designer controls information
about a state, and there are multiple agents interacting in a game who are
privately informed about their types. Each agent's utility depends on all
agents' types and actions, as well as (linearly) on the state. To optimally
screen the agents, the designer first asks agents to report their types and
then sends a private action recommendation to each agent whose distribution
depends on all reported types and the state. We show that there always exists
an optimal mechanism which is laminar partitional. Such a mechanism partitions
the state space for each type profile and recommends the same action profile
for states that belong to the same partition element. Furthermore, the convex
hulls of any two partition elements are such that either one contains the other
or they have an empty intersection. In the single-agent case, each state is
either perfectly revealed or lies in an interval in which the number of
different signal realizations is at most the number of different types of the
agent plus two. A similar result is established for the multi-agent case.
  We also highlight the value of screening: without screening the best
achievable payoff could be as low as one over the number of types fraction of
the optimal payoff. Along the way, we shed light on the solutions of
optimization problems over distributions subject to a mean-preserving
contraction constraint and additional side constraints, which might be of
independent interest."
economics,Structural Interventions in Networks,"Two types of interventions are commonly implemented in networks:
characteristic intervention, which influences individuals' intrinsic
incentives, and structural intervention, which targets the social links among
individuals. In this paper we provide a general framework to evaluate the
distinct equilibrium effects of both types of interventions. We identify a
hidden equivalence between a structural intervention and an endogenously
determined characteristic intervention. Compared with existing approaches in
the literature, the perspective from such an equivalence provides several
advantages in the analysis of interventions that target network structure. We
present a wide range of applications of our theory, including identifying the
most wanted criminal(s) in delinquent networks and targeting the key connector
for isolated communities."
economics,Dynamic Random Choice,"I study dynamic random utility with finite choice sets and exogenous total
menu variation, which I refer to as stochastic utility (SU). First, I
characterize SU when each choice set has three elements. Next, I prove several
mathematical identities for joint, marginal, and conditional Block--Marschak
sums, which I use to obtain two characterizations of SU when each choice set
but the last has three elements. As a corollary under the same cardinality
restrictions, I sharpen an axiom to obtain a characterization of SU with full
support over preference tuples. I conclude by characterizing SU without
cardinality restrictions. All of my results hold over an arbitrary finite
discrete time horizon."
economics,Conservative Updating,"This paper provides a behavioral analysis of conservatism in beliefs. I
introduce a new axiom, Dynamic Conservatism, that relaxes Dynamic Consistency
when information and prior beliefs ""conflict."" When the agent is a subjective
expected utility maximizer, Dynamic Conservatism implies that conditional
beliefs are a convex combination of the prior and the Bayesian posterior.
Conservatism may result in belief dynamics consistent with confirmation bias,
representativeness, and the good news-bad news effect, suggesting a deeper
behavioral connection between these biases. An index of conservatism and a
notion of comparative conservatism are characterized. Finally, I extend
conservatism to the case of an agent with incomplete preferences that admit a
multiple priors representation."
economics,Robust double auction mechanisms,"We study the robust double auction mechanisms, that is, the double auction
mechanisms that satisfy dominant strategy incentive compatibility, ex-post
individual rationality and ex-post budget balance. We first establish that the
price in any robust mechanism does not depend on the valuations of the trading
players. We next establish that, with a non-bossiness assumption, the price in
any robust mechanism does not depend on players' valuations at all, whether
trading or non-trading. Our main result is the characterization result that,
with a non-bossy assumption along with other assumptions on the properties of
the mechanism, the generalized posted mechanism in which a constant price is
posted for each possible set of traders is the only robust double auction
mechanism. We also show that, even without the non-bossiness assumption, it is
quite difficult to find a reasonable robust double auction mechanism other than
the generalized posted price mechanism."
economics,Dual theory of choice with multivariate risks,"We propose a multivariate extension of Yaari's dual theory of choice under
risk. We show that a decision maker with a preference relation on
multidimensional prospects that preserves first order stochastic dominance and
satisfies comonotonic independence behaves as if evaluating prospects using a
weighted sum of quantiles. Both the notions of quantiles and of comonotonicity
are extended to the multivariate framework using optimal transportation maps.
Finally, risk averse decision makers are characterized within this framework
and their local utility functions are derived. Applications to the measurement
of multi-attribute inequality are also discussed."
economics,The Refined Assortment Optimization Problem,"We introduce the refined assortment optimization problem where a firm may
decide to make some of its products harder to get instead of making them
unavailable as in the traditional assortment optimization problem. Airlines,
for example, offer fares with severe restrictions rather than making them
unavailable. This is a more subtle way of handling the trade-off between demand
induction and demand cannibalization. For the latent class MNL model, a firm
that engages in refined assortment optimization can make up to $\min(n,m)$
times more than one that insists on traditional assortment optimization, where
$n$ is the number of products and $m$ the number of customer types.
Surprisingly, the revenue-ordered assortment heuristic has the same performance
guarantees relative to {\em personalized} refined assortment optimization as it
does to traditional assortment optimization. Based on this finding, we
construct refinements of the revenue-order heuristic and measure their improved
performance relative to the revenue-ordered assortment and the optimal
traditional assortment optimization problem. We also provide tight bounds on
the ratio of the expected revenues for the refined versus the traditional
assortment optimization for some well known discrete choice models."
economics,"Can Economic Theory Be Informative for the Judiciary? Affirmative Action
  in India via Vertical and Horizontal Reservations","Sanctioned by its constitution, India is home to the world's most
comprehensive affirmative action program, where historically discriminated
groups are protected with vertical reservations implemented as ""set asides,""
and other disadvantaged groups are protected with horizontal reservations
implemented as ""minimum guarantees."" A mechanism mandated by the Supreme Court
in 1995 suffers from important anomalies, triggering countless litigations in
India. Foretelling a recent reform correcting the flawed mechanism, we propose
the 2SMG mechanism that resolves all anomalies, and characterize it with
desiderata reflecting laws of India. Subsequently rediscovered with a high
court judgment and enforced in Gujarat, 2SMG is also endorsed by Saurav Yadav
v. State of UP (2020), in a Supreme Court ruling that rescinded the flawed
mechanism. While not explicitly enforced, 2SMG is indirectly enforced for an
important subclass of applications in India, because no other mechanism
satisfies the new mandates of the Supreme Court."
economics,"Non-rationalizable Individuals, Stochastic Rationalizability, and
  Sampling","Experimental work regularly finds that individual choices are not
deterministically rationalized by well-defined preferences. Nonetheless, recent
work shows that data collected from many individuals can be stochastically
rationalized by a distribution of well-defined preferences. We study the
relationship between deterministic and stochastic rationalizability. We show
that a population can be stochastically rationalized even when half of the
individuals in the population cannot be deterministically rationalized. We also
find the ability to detect individuals who are not deterministically
rationalized from population level data can decrease as the number of
observations increases."
economics,Comonotonic measures of multivariate risks,"We propose a multivariate extension of a well-known characterization by S.
Kusuoka of regular and coherent risk measures as maximal correlation
functionals. This involves an extension of the notion of comonotonicity to
random vectors through generalized quantile functions. Moreover, we propose to
replace the current law invariance, subadditivity and comonotonicity axioms by
an equivalent property we call strong coherence and that we argue has more
natural economic interpretation. Finally, we reformulate the computation of
regular and coherent risk measures as an optimal transportation problem, for
which we provide an algorithm and implementation."
economics,"Matching in Closed-Form: Equilibrium, Identification, and Comparative
  Statics","This paper provides closed-form formulas for a multidimensional two-sided
matching problem with transferable utility and heterogeneity in tastes. When
the matching surplus is quadratic, the marginal distributions of the
characteristics are normal, and when the heterogeneity in tastes is of the
continuous logit type, as in Choo and Siow (J Polit Econ 114:172-201, 2006), we
show that the optimal matching distribution is also jointly normal and can be
computed in closed form from the model primitives. Conversely, the quadratic
surplus function can be identified from the optimal matching distribution, also
in closed-form. The closed-form formulas make it computationally easy to solve
problems with even a very large number of matches and allow for quantitative
predictions about the evolution of the solution as the technology and the
characteristics of the matching populations change."
economics,Identification in the Random Utility Model,"The random utility model is known to be unidentified, but there are times
when the model admits a unique representation. We offer two characterizations
for the existence of a unique random utility representation. Our first
characterization puts conditions on a graphical representation of the data set.
Non-uniqueness arises when multiple inflows can be assigned to multiple
outflows on this graph. Our second characterization provides a direct test for
uniqueness given a random utility representation. We also show that the support
of a random utility representation is identified if and only if the
representation itself is identified."
economics,Local Utility and Multivariate Risk Aversion,"We revisit Machina's local utility as a tool to analyze attitudes to
multivariate risks. We show that for non-expected utility maximizers choosing
between multivariate prospects, aversion to multivariate mean preserving
increases in risk is equivalent to the concavity of the local utility
functions, thereby generalizing Machina's result in Machina (1982). To analyze
comparative risk attitudes within the multivariate extension of rank dependent
expected utility of Galichon and Henry (2011), we extend Quiggin's monotone
mean and utility preserving increases in risk and show that the useful
characterization given in Landsberger and Meilijson (1994) still holds in the
multivariate case."
economics,An Axiom for Concavifiable Preferences in View of Alt's Theory,"We present a necessary and sufficient condition for Alt's system to be
represented by a continuous utility function. Moreover, we present a necessary
and sufficient condition for this utility function to be concave. The latter
condition can be seen as an extension of Gossen's first law, and thus has an
economic interpretation. Together with the above results, we provide a
necessary and sufficient condition for Alt's utility to be continuously
differentiable."
economics,A Theory of Choice Bracketing under Risk,"Aggregating risks from multiple sources can be complex and demanding, and
decision makers usually adopt heuristics to simplify the evaluation process.
This paper axiomatizes two closed related and yet different heuristics, narrow
bracketing and correlation neglect, by relaxing the independence axiom in the
expected utility theory. The flexibility of our framework allows for
applications in various economic problems. First, our model can explain the
experimental evidence of narrow bracketing over monetary gambles. Second, when
one source represents background risk, we can accommodate Rabin (2000)'s
critique and explain risk aversion over small gambles. Finally, when different
sources represent consumptions in different periods, we unify three seemingly
distinct models of time preferences and propose a novel model that
simultaneously satisfies indifference to temporal resolution of uncertainty,
separation of time and risk preferences, and recursivity in the domain of
lotteries. As a direct application to macroeconomics and finance, we provide an
alternative to Epstein and Zin (1989) which avoids the unreasonably high timing
premium discussed in Epstein, Farhi, and Strzalecki (2014)."
economics,"On the Basis of the Hamilton-Jacobi-Bellman Equation in Economic
  Dynamics","We consider the classical Ramsey-Cass-Koopmans capital accumulation model and
present three examples in which the Hamilton-Jacobi-Bellman (HJB) equation is
neither necessary nor sufficient for a function to be the value function. Next,
we present assumptions under which the HJB equation becomes a necessary and
sufficient condition for a function to be the value function, and using this
result, we propose a new method for solving the original problem using the
solution to the HJB equation. Our assumptions are so mild that many
macroeconomic growth models satisfy them. Therefore, our results ensure that
the solution to the HJB equation is rigorously the value function in many
macroeconomic models, and present a new solving method for these models."
economics,"Generalized Social Marginal Welfare Weights Imply Inconsistent
  Comparisons of Tax Policies","This paper concerns Saez and Stantcheva's (2016) generalized social marginal
welfare weights (GSMWW), which aggregate losses and gains due to tax policies,
while incorporating non-utilitarian ethical considerations. The approach
evaluates local tax changes without a global social objective. I show that
local tax policy comparisons implicitly entail global comparisons. Moreover,
whenever welfare weights do not have a utilitarian structure, these implied
global comparisons are inconsistent. I argue that broader ethical values cannot
in general be represented simply by modifying the weights placed on benefits to
different people, and a more thoroughgoing modification of the utilitarian
approach is required."
economics,Dynamic Pricing with Limited Commitment,"A monopolist wants to sell one item per period to a consumer with evolving
and persistent private information. The seller sets a price each period
depending on the history so far, but cannot commit to future prices. We show
that, regardless of the degree of persistence, any equilibrium under a D1-style
refinement gives the seller revenue no higher than what she would get from
posting all prices in advance."
economics,"Minimal entropy and uniqueness of price equilibria in a pure exchange
  economy","We introduce uncertainty into a pure exchange economy and establish a
connection between Shannon's differential entropy and uniqueness of price
equilibria. The following conjecture is proposed under the assumption of a
uniform probability distribution: entropy is minimal if and only if the price
is unique for every economy. We show the validity of this conjecture for an
arbitrary number of goods and two consumers and, under certain conditions, for
an arbitrary number of consumers and two goods."
economics,Ambiguity and Partial Bayesian Updating,"Models of updating a set of priors either do not allow a decision maker to
make inference about her priors (full bayesian updating or FB) or require an
extreme degree of selection (maximum likelihood updating or ML). I characterize
a general method for updating a set of priors, partial bayesian updating (PB),
in which the decision maker (i) utilizes an event-dependent threshold to
determine whether a prior is likely enough, conditional on observed
information, and then (ii) applies Bayes' rule to the sufficiently likely
priors. I show that PB nests FB and ML and explore its behavioral properties."
economics,A Quest for Knowledge,"Is more novel research always desirable? We develop a model in which
knowledge shapes society's policies and guides the search for discoveries.
Researchers select a question and how intensely to study it. The novelty of a
question determines both the value and difficulty of discovering its answer. We
show that the benefits of discoveries are nonmonotone in novelty. Knowledge
expands endogenously step-by-step over time. Through a dynamic externality,
moonshots -- research on questions more novel than what is myopically optimal
-- can improve the evolution of knowledge. Moonshots induce research cycles in
which subsequent researchers connect the moonshot to previous knowledge."
economics,Information Design in Multi-stage Games,"This paper generalizes the concept of Bayes correlated equilibrium (Bergemann
and Morris, 2016) to multi-stage games. We demonstrate the power of our
characterization results by applying them to a number of illustrative examples
and applications."
economics,Cross-verification and Persuasive Cheap Talk,"We study a cheap-talk game where two experts first choose what information to
acquire and then offer advice to a decision-maker whose actions affect the
welfare of all. The experts cannot commit to reporting strategies. Yet, we show
that the decision-maker's ability to cross-verify the experts' advice acts as a
commitment device for the experts. We prove the existence of an equilibrium,
where an expert's equilibrium payoff is equal to what he would obtain if he
could commit to truthfully revealing his information."
economics,Informational Robustness of Common Belief in Rationality,"In this note, I explore the implications of informational robustness under
the assumption of common belief in rationality. That is, predictions for
incomplete-information games which are valid across all possible information
structures. First, I address this question from a global perspective and then
generalize the analysis to allow for localized informational robustness."
economics,Decreasing Impatience,"We characterize decreasing impatience, a common behavioral phenomenon in
intertemporal choice. Discount factors that display decreasing impatience are
characterized through a convexit y axiom for investments at fixed interest
rates. Then we show that they are equivalent to a geometric average of
generalized quasi-hype rbolic discount rates. Finally, they emerge through
parimutuel preference aggregation of exponential discount factors."
economics,Mechanism Design under Approximate Incentive Compatibility,"A fundamental assumption in classical mechanism design is that buyers are
perfect optimizers. However, in practice, buyers may be limited by their
computational capabilities or a lack of information, and may not be able to
perfectly optimize. This has motivated the introduction of approximate
incentive compatibility (IC) as an appealing solution concept for practical
mechanism design. While most of the literature focuses on the analysis of
particular approximate IC mechanisms, this paper is the first to study the
design of optimal mechanisms in the space of approximate IC mechanisms and to
explore how much revenue can be garnered by moving from exact to approximate
incentive constraints. We study the problem of a seller facing one buyer with
private values and analyze optimal selling mechanisms under
$\varepsilon$-incentive compatibility. We establish that the gains that can be
garnered depend on the local curvature of the seller's revenue function around
the optimal posted price when the buyer is a perfect optimizer. If the revenue
function behaves locally like an $\alpha$-power for $\alpha \in (1,\infty)$,
then no mechanism can garner gains higher than order
$\varepsilon^{\alpha/(2\alpha-1)}$. This improves upon state-of-the-art results
which imply maximum gains of $\varepsilon^{1/2}$ by providing the first
parametric bounds that capture the impact of revenue function's curvature on
revenue gains. Furthermore, we establish that an optimal mechanism needs to
randomize as soon as $\varepsilon>0$ and construct a randomized mechanism that
is guaranteed to achieve order $\varepsilon^{\alpha/(2\alpha-1)}$ additional
revenues, leading to a tight characterization of the revenue implications of
approximate IC constraints. Our work brings forward the need to optimize not
only over allocations and payments but also over best responses, and we develop
a new framework to address this challenge."
economics,Stable matching: an integer programming approach,"This paper develops an integer programming approach to two-sided many-to-one
matching by investigating stable integral matchings of a fictitious market
where each worker is divisible. We show that stable matchings exist in a
discrete matching market when firms' preference profile satisfies a total
unimodularity condition that is compatible with various forms of
complementarities. We provide a class of firms' preference profiles that
satisfy this condition."
economics,Contracts for acquiring information,"This paper studies the provision of incentives for information acquisition.
Information is costly for an agent to acquire and unobservable to a principal.
We show that any Pareto optimal contract has a decomposition into a fraction of
output, a state-dependent transfer, and an optimal distortion. Under this
decomposition: 1) the fraction of output paid is increasing in the set of
experiments available to the agent, 2) the state-dependent transfer indexes
contract payments to account for differences in output between states, 3) the
optimal distortion exploits complementarities in the cost of information
acquisition: experiment probabilities unalterable via contract payments stuck
against liability limits are substituted for, the substitution occurring
according to complementarities in the cost of information acquisition, and 4)
if and only if the agent's cost of experimentation is mutual information, the
optimal distortion takes the form of a decision-dependent transfer."
economics,"A note on local uniqueness of equilibria: How isolated is a local
  equilibrium?","The motivation of this note is to show how singular values affect local
uniqueness. More precisely, Theorem 3.1 shows how to construct a neighborhood
(a ball) of a regular equilibrium whose diameter represents an estimate of
local uniqueness, hence providing a measure of how isolated a (local) unique
equilibrium can be. The result, whose relevance in terms of comparative statics
is evident, is based on reasonable and natural assumptions and hence is
applicable in many different settings, ranging from pure exchange economies to
non-cooperative games."
economics,Correlated Choice,"We study random joint choice rules, allowing for interdependence of choice
across agents. These capture random choice by multiple agents, or a single
agent across goods or time periods. Our interest is in separable choice rules,
where each agent can be thought of as acting independently of the other. A
random joint choice rule satisfies marginality if for every individual choice
set, we can determine the individual's choice probabilities over alternatives
independently of the other individual's choice set. We offer two
characterizations of random joint choice rules satisfying marginality in terms
of separable choice rules. While marginality is a necessary condition for
separability, we show that it fails to be sufficient. We provide an additional
condition on the marginal choice rules which, along with marginality, is
sufficient for separability."
economics,Core equivalence with large agents,"This paper studies the relationship between core and competitive equilibira
in economies that consist of a continuum of agents and some large agents. We
construct a class of these economies in which the core and competitive
allocations do not coincide."
economics,Competition in Costly Talk,"This paper studies a communication game between an uninformed decision maker
and two perfectly informed senders with conflicting interests. Senders can
misreport information at a cost that increases with the size of the
misrepresentation. The main results show that equilibria where the decision
maker obtains the complete-information payoff hinge on beliefs with undesirable
properties. The imposition of a minimal and sensible belief structure is
sufficient to generate a robust and essentially unique equilibrium with partial
information transmission. A complete characterization of this equilibrium
unveils the language senders use to communicate."
economics,How to De-Reserves Reserves: Admissions to Technical Colleges in India,"We study joint implementation of reservation and de-reservation policies in
India that has been enforcing a comprehensive affirmative action since 1950.
The landmark judgement of the Supreme Court of India in 2008 mandated that
whenever OBC category (with 27 percent reservation) has unfilled positions they
must be reverted to general category applicants in admissions to public schools
without specifying how to implement it. We disclose the drawbacks of recently
reformed allocation procedure in admissions to technical colleges and offer a
solution through de-reservation via choice rules. We propose a novel priority
design, Backward Transfers (BT) choice rule, for institutions and the deferred
acceptance mechanism under these rules (DA-BT) for centralized clearinghouses.
We show that DA-BT corrects the shortcomings of existing mechanisms. By
formulating the legal requirements and policy goals in India as formal axioms,
we show that the DA-BT mechanism is the unique mechanism for concurrent
implementation of reservation and de-reservation policies."
economics,Conditional strategy equilibrium,"In this note, we prove the existence of an equilibrium concept, dubbed
conditional strategy equilibrium, for non-cooperative games in which a strategy
of a player is a function from the other players' actions to her own actions.
We study the properties of efficiency and coalition-proofness of the
conditional strategy equilibrium in $n$-person games."
economics,Price and Fulfillment Strategies in Omnichannel Retailing,"Omnichannel retailing, a new form of distribution system, seamlessly
integrates the Internet and physical stores. This study considers the pricing
and fulfillment strategies of a retailer that has two sales channels: online
and one physical store. The retailer offers consumers three purchasing options:
delivery from the fulfillment center, buy online and pick up in-store (BOPS),
and purchasing at the store. Consumers choose one of these options to maximize
their utility, dividing them into several segments. Given the retailer can
induce consumers to the profitable segment by adjusting the online and store
prices, our analysis shows that it has three optimal strategies: (1) The
retailer excludes consumers far from the physical store from the market and
lets the others choose BOPS or purchasing at the store. (2) It lets consumers
far from the physical store choose delivery from the fulfillment center and the
others choose BOPS or purchasing at the store. (3) It lets all consumers choose
delivery from the fulfillment center. Finally, we present simple dynamic
simulations that considers how the retailer's optimal strategy changes as
consumers' subjective probability of believing the product is in stock
decreases. The results show that the retailer should offer BOPS in later
periods of the selling season to maximize its profit as the subjective
probability decreases."
economics,Advisors with Hidden Motives,"I study a model of advisors with hidden motives: a seller discloses
information about an object's value to a potential buyer, who doesn't know the
object's value or how profitable the object's sale is to the seller (the
seller's motives). I characterize optimal disclosure rules, used by the seller
to steer sales from lower- to higher-profitability objects. I investigate the
effects of a mandated transparency policy, which reveals the seller's motives
to the buyer. I show that, by removing the seller's steering incentive,
transparency can dissuade the seller from disclosing information about the
object's value, and from acquiring that information in the first place. This
result refines our understanding of effective regulation in advice markets, and
links it to the commitment protocol in the advisor-advisee relation."
economics,"On the Approximate Purification of Mixed Strategies in Games with
  Infinite Action Sets","We consider a game in which the action set of each player is uncountable, and
show that, from weak assumptions on the common prior, any mixed strategy has an
approximately equivalent pure strategy. The assumption of this result can be
further weakened if we consider the purification of a Nash equilibrium.
Combined with the existence theorem for a Nash equilibrium, we derive an
existence theorem for a pure strategy approximated Nash equilibrium under
sufficiently weak assumptions. All of the pure strategies we derive in this
paper can take a finite number of possible actions."
economics,Optimism and Pessimism in Strategic Interactions under Ignorance,"We study players interacting under the veil of ignorance, who have -- coarse
-- beliefs represented as subsets of opponents' actions. We analyze when these
players follow $\max \min$ or $\max\max$ decision criteria, which we identify
with pessimistic or optimistic attitudes, respectively. Explicitly formalizing
these attitudes and how players reason interactively under ignorance, we
characterize the behavioral implications related to common belief in these
events: while optimism is related to Point Rationalizability, a new algorithm
-- Wald Rationalizability -- captures pessimism. Our characterizations allow us
to uncover novel results: ($i$) regarding optimism, we relate it to wishful
thinking \'a la Yildiz (2007) and we prove that dropping the (implicit)
""belief-implies-truth"" assumption reverses an existence failure described
therein; ($ii$) we shed light on the notion of rationality in ordinal games;
($iii$) we clarify the conceptual underpinnings behind a discontinuity in
Rationalizability hinted in the analysis of Weinstein (2016)."
economics,"A production function with variable elasticity of substitution greater
  than one","The idea of this paper comes from the famous remark of Piketty and Zuckman:
""It is natural to imagine that $\sigma$ was much less than one in the
eighteenth and nineteenth centuries and became larger than one in the twentieth
and twenty-first centuries. One expects a higher elasticity of substitution in
high-tech economies where there are lots of alternative uses and forms for
capital."" The main aim of this paper is to prove the existence of a production
function of variable elasticity of substitution with values greater than one."
economics,Screening $p$-Hackers: Dissemination Noise as Bait,"We show that adding noise before publishing datasets effectively screens
p-hacked findings: spurious explanations of the outcome variable produced by
attempting multiple econometric specifications. Noise creates ""baits"" that
affect two types of researchers differently. Uninformed p-hackers, who are
fully ignorant of the true mechanism and engage in data mining, often fall for
baits. Informed researchers who start with an ex-ante hypothesis are minimally
affected. We characterize the optimal noise level and highlight the relevant
trade-offs. Dissemination noise is a tool that statistical agencies currently
use to protect privacy. We argue this existing practice can be repurposed to
improve research credibility."
economics,Conveying Value via Categories,"A sender sells an object of unknown quality to a receiver who pays his
expected value for it. Sender and receiver might hold different priors over
quality. The sender commits to a monotonic categorization of quality. We
characterize the sender's optimal monotonic categorization. Using our
characterization, we study the optimality of full pooling or full separation,
the alternation of pooling and separation, and make precise a sense in which
pooling is dominant relative to separation. We discuss applications, extensions
and generalizations, among them the design of a grading scheme by a
profit-maximizing school which seeks to signal student qualities and
simultaneously incentivize students to learn. Such incentive constraints force
monotonicity, and can also be embedded as a distortion of the school's prior
over student qualities, generating a categorization problem with distinct
sender and receiver priors."
economics,Efficiency and Stability in a Process of Teams Formation,"Motivated by data on coauthorships in scientific publications, we analyze a
team formation process that generalizes matching models and network formation
models, allowing for overlapping teams of heterogeneous size. We apply
different notions of stability: myopic team-wise stability, which extends to
our setup the concept of pair-wise stability, coalitional stability, where
agents are perfectly rational and able to coordinate, and stochastic stability,
where agents are myopic and errors occur with vanishing probability. We find
that, in many cases, coalitional stability in no way refines myopic team-wise
stability, while stochastically stable states are feasible states that maximize
the overall number of activities performed by teams."
economics,The Formation of Global Free Trade Agreement,"We investigate the formation of Free Trade Agreement (FTA) in a competing
importers framework with $n$ countries. We show that (i) FTA formation causes a
negative externality to non-participants, (ii) a non-participant is willing to
join an FTA, and (iii) new participation may decrease the welfare of incumbent
participants. A unique subgame perfect equilibrium of a sequential FTA
formation game does not achieve global free trade under an open-access rule
where a new applicant needs consent of members for accession, currently
employed by many open regionalism agreements including APEC. We further show
that global FTA is a unique subgame perfect equilibrium under an open-access
rule without consent."
economics,The lattice of worker-quasi-stable matchings,"In a many-to-one matching model in which firms' preferences satisfy
substitutability, we study the set of worker-quasi-stable matchings.
Worker-quasi-stability is a relaxation of stability that allows blocking pairs
involving a firm and an unemployed worker. We show that this set has a lattice
structure and define a Tarski operator on this lattice that models a
re-equilibration process and has the set of stable matchings as its fixed
points."
economics,Payoff Information and Learning in Signaling Games,"We add the assumption that players know their opponents' payoff functions and
rationality to a model of non-equilibrium learning in signaling games. Agents
are born into player roles and play against random opponents every period.
Inexperienced agents are uncertain about the prevailing distribution of
opponents' play, but believe that opponents never choose conditionally
dominated strategies. Agents engage in active learning and update beliefs based
on personal observations. Payoff information can refine or expand learning
predictions, since patient young senders' experimentation incentives depend on
which receiver responses they deem plausible. We show that with payoff
knowledge, the limiting set of long-run learning outcomes is bounded above by
rationality-compatible equilibria (RCE), and bounded below by uniform RCE. RCE
refine the Intuitive Criterion (Cho and Kreps, 1987) and include all divine
equilibria (Banks and Sobel, 1987). Uniform RCE sometimes but not always
exists, and implies universally divine equilibrium."
economics,Player-Compatible Learning and Player-Compatible Equilibrium,"Player-Compatible Equilibrium (PCE) imposes cross-player restrictions on the
magnitudes of the players' ""trembles"" onto different strategies. These
restrictions capture the idea that trembles correspond to deliberate
experiments by agents who are unsure of the prevailing distribution of play.
PCE selects intuitive equilibria in a number of examples where trembling-hand
perfect equilibrium (Selten, 1975) and proper equilibrium (Myerson, 1978) have
no bite. We show that rational learning and weighted fictitious play imply our
compatibility restrictions in a steady-state setting."
economics,"Compactification of Extensive Game Structures and Backward Dominance
  Procedure","We study the relationship between invariant transformations on extensive game
structures and backward dominance procedure (BD), a generalization of the
classical backward induction introduced in Perea (2014). We show that
behavioral equivalence with unambiguous orderings of information sets, a
critical property that guarantees BD's applicability, can be characterized by
the classical Coalescing and a modified Interchange/Simultanizing in Battigalli
et al. (2020). We also give conditions on transformations that improve BD's
efficiency. In addition, we discuss the relationship between transformations
and Bonanno (2014)'s generalized backward induction."
economics,Public goods in networks with constraints on sharing,"This paper considers incentives to provide goods that are partially shareable
along social links. We introduce a model in which each individual in a social
network not only decides how much of a shareable good to provide, but also
decides which subset of neighbours to nominate as co-beneficiaries. An outcome
of the model specifies an endogenously generated subnetwork of the original
network and a public goods game occurring over the realised subnetwork. We
prove the existence of specialised pure strategy Nash equilibria: those in
which some individuals contribute while the remaining individuals free ride. We
then consider how the set of efficient specialised equilibria vary as the
constraints on sharing are relaxed and we show that, paradoxically, an increase
in shareability may decrease efficiency."
economics,When abstinence increases prevalence,"In the pool of people seeking partners, a uniformly greater preference for
abstinence increases the prevalence of infection and worsens everyone's
welfare. In contrast, prevention and treatment reduce prevalence and improve
payoffs. The results are driven by adverse selection: people who prefer more
partners are likelier disease carriers. A given decrease in the number of
matches is a smaller proportional reduction for people with many partners, thus
increases the fraction of infected in the pool. The greater disease risk
further decreases partner-seeking and payoffs."
economics,Spherical Preferences,"We introduce and study the property of orthogonal independence, a restricted
additivity axiom applying when alternatives are orthogonal. The axiom requires
that the preference for one marginal change over another should be maintained
after each marginal change has been shifted in a direction that is orthogonal
to both.
  We show that continuous preferences satisfy orthogonal independence if and
only if they are spherical: their indifference curves are spheres with the same
center, with preference being ""monotone"" either away or towards the center.
Spherical preferences include linear preferences as a special (limiting) case.
We discuss different applications to economic and political environments. Our
result delivers Euclidean preferences in models of spatial voting, quadratic
welfare aggregation in social choice, and expected utility in models of choice
under uncertainty."
economics,The paradox of monotone structural QRE,"McKelvey and Palfrey (1995)'s monotone structural Quantal Response
Equilibrium theory may be misspecified for the study of monotone behavior."
economics,Empirical bias of extreme-price auctions: analysis,"We advance empirical equilibrium analysis (Velez and Brown, 2020,
arXiv:1907.12408) of the winner-bid and loser-bid auctions for the dissolution
of a partnership. We show, in a complete information environment, that even
though these auctions are essentially equivalent for the Nash equilibrium
prediction, they can be expected to differ in fundamental ways when they are
operated. Besides the direct policy implications, two general consequences
follow. First, a mechanism designer who accounts for the empirical plausibility
of equilibria may not be constrained by Maskin invariance. Second, a mechanism
designer who does not account for the empirical plausibility of equilibria may
inadvertently design biased mechanisms."
economics,Credit Scoring by Incorporating Dynamic Networked Information,"In this paper, the credit scoring problem is studied by incorporating
networked information, where the advantages of such incorporation are
investigated theoretically in two scenarios. Firstly, a Bayesian optimal filter
is proposed to provide risk prediction for lenders assuming that published
credit scores are estimated merely from structured financial data. Such
prediction can then be used as a monitoring indicator for the risk management
in lenders' future decisions. Secondly, a recursive Bayes estimator is further
proposed to improve the precision of credit scoring by incorporating the
dynamic interaction topology of clients. It is shown that under the proposed
evolution framework, the designed estimator has a higher precision than any
efficient estimator, and the mean square errors are strictly smaller than the
Cram\'er-Rao lower bound for clients within a certain range of scores. Finally,
simulation results for a special case illustrate the feasibility and
effectiveness of the proposed algorithms."
economics,On the many-to-one strongly stable fractional matching set,"For a many-to-one matching market where firms have strict and
$\boldsymbol{q}$-responsive preferences, we give a characterization of the set
of strongly stable fractional matchings as the union of the convex hull of all
connected sets of stable matchings. Also, we prove that a strongly stable
fractional matching is represented as a convex combination of stable matchings
that are ordered in the common preferences of all firms."
economics,"Detectability, Duality, and Surplus Extraction","We study surplus extraction in the general environment of McAfee and Reny
(1992), and provide two alternative proofs of their main theorem. The first is
an analogue of the classic argument of Cremer and McLean (1985, 1988), using
geometric features of the set of agents' beliefs to construct a menu of
contracts extracting the desired surplus. This argument, which requires a
finite state space, also leads to a counterexample showing that full extraction
is not possible without further significant conditions on agents' beliefs or
surplus, even if the designer offers an infinite menu of contracts. The second
argument uses duality and applies for an infinite state space, thus yielding
the general result of McAfee and Reny (1992). Both arguments suggest methods
for studying surplus extraction in settings beyond the standard model, in which
the designer or agents might have objectives other than risk neutral expected
value maximization."
economics,"Characterizing Shadow Price via Lagrangian Multiplier for Nonsmooth
  Problem","In this paper, a relation between shadow price and the Lagrangian multiplier
for nonsmooth problem is explored. It is shown that the Lagrangian Multiplier
is the upper bound of shadow price for convex optimization and a class of
Lipschtzian optimizations. This work can be used in shadow pricing for
nonsmooth situation. The several nonsmooth functions involved in this class of
Lipschtzian optimizations is listed. Finally, an application to electricity
pricing is discussed."
economics,Conventions and Coalitions in Repeated Games,"We develop a theory of repeated interaction for coalitional behavior. We
consider stage games where both individuals and coalitions may deviate.
However, coalition members cannot commit to long-run behavior, and anticipate
that today's actions influence tomorrow's behavior. We evaluate the degree to
which history-dependence can deter coalitional deviations. If monitoring is
perfect, every feasible and strictly individually rational payoff can be
supported by history-dependent conventions. By contrast, if players can make
secret side-payments to each other, every coalition achieves a coalitional
minmax value, potentially reducing the set of supportable payoffs to the core
of the stage game."
economics,"The interplay between migrants and natives as a determinant of migrants'
  assimilation: A coevolutionary approach","We study the migrants' assimilation, which we conceptualize as forming human
capital productive on the labor market of a developed host country, and we link
the observed frequent lack of assimilation with the relative deprivation that
the migrants start to feel when they move in social space towards the natives.
In turn, we presume that the native population is heterogenous and consists of
high-skill and low-skill workers. The presence of assimilated migrants might
shape the comparison group of the natives, influencing the relative deprivation
of the low-skill workers and, in consequence, the choice to form human capital
and become highly skilled. To analyse this interrelation between assimilation
choices of migrants and skill formation of natives, we construct a
coevolutionary model of the open-to-migration economy. Showing that the economy
might end up in a non-assimilation equilibrium, we discuss welfare consequences
of an assimilation policy funded from tax levied on the native population. We
identify conditions under which such costly policy can bring the migrants to
assimilation and at the same time increase the welfare of the natives, even
though the incomes of the former take a beating."
economics,"Addictive Auctions: using lucky-draw and gambling addiction to increase
  participation during auctioning","Auction theories are believed to provide a better selling opportunity for the
resources to be allocated. Various organizations have taken measures to
increase trust among participants towards their auction system, but trust alone
cannot ensure a high level of participation. We propose a new type of auction
system which takes advantage of lucky draw and gambling addictions to increase
the engagement level of candidates in an auction. Our system makes use of
security features present in existing auction systems for ensuring fairness and
maintaining trust among participants."
economics,"On the Equilibrium Uniqueness in Cournot Competition with Demand
  Uncertainty","We revisit the linear Cournot model with uncertain demand that is studied in
Lagerl\""of (2006)* and provide sufficient conditions for equilibrium uniqueness
that complement the existing results. We show that if the distribution of the
demand intercept has the decreasing mean residual demand (DMRD) or the
increasing generalized failure rate (IGFR) property, then uniqueness of
equilibrium is guaranteed. The DMRD condition implies log-concavity of the
expected profits per unit of output without additional assumptions on the
existence or the shape of the density of the demand intercept and, hence,
answers in the affirmative the conjecture of Lagerl\""of (2006)* that such
conditions may not be necessary.
  *Johan Lagerl\""of, Equilibrium uniqueness in a Cournot model with demand
uncertainty. The B.E. Journal in Theoretical Economics, Vol. 6: Iss 1.
(Topics), Article 19:1--6, 2006."
economics,"General equilibrium in a heterogeneous-agent incomplete-market economy
  with many consumption goods and a risk-free bond","We study a pure-exchange incomplete-market economy with heterogeneous agents.
In each period, the agents choose how much to save (i.e., invest in a risk-free
bond), how much to consume, and which bundle of goods to consume while their
endowments are fluctuating. We focus on a competitive stationary equilibrium
(CSE) in which the wealth distribution is invariant, the agents maximize their
expected discounted utility, and both the prices of consumption goods and the
interest rate are market-clearing. Our main contribution is to extend some
general equilibrium results to an incomplete-market Bewley-type economy with
many consumption goods. Under mild conditions on the agents' preferences, we
show that the aggregate demand for goods depends only on their relative prices
and that the aggregate demand for savings is homogeneous of degree in prices,
and we prove the existence of a CSE. When the agents' preferences can be
represented by a CES (constant elasticity of substitution) utility function
with an elasticity of substitution that is higher than or equal to one, we
prove that the CSE is unique. Under the same preferences, we show that a higher
inequality of endowments does not change the equilibrium prices of goods, and
decreases the equilibrium interest rate. Our results shed light on the impact
of market incompleteness on the properties of general equilibrium models."
economics,Informed Principal Problems in Bilateral Trading,"We study bilateral trade with interdependent values as an informed-principal
problem. The mechanism-selection game has multiple equilibria that differ with
respect to principal's payoff and trading surplus. We characterize the
equilibrium that is worst for every type of principal, and characterize the
conditions under which there are no equilibria with different payoffs for the
principal. We also show that this is the unique equilibrium that survives the
intuitive criterion."
economics,Dynamically Stable Matching,"I introduce a stability notion, dynamic stability, for two-sided dynamic
matching markets where (i) matching opportunities arrive over time, (ii)
matching is one-to-one, and (iii) matching is irreversible. The definition
addresses two conceptual issues. First, since not all agents are available to
match at the same time, one must establish which agents are allowed to form
blocking pairs. Second, dynamic matching markets exhibit a form of externality
that is not present in static markets: an agent's payoff from remaining
unmatched cannot be defined independently of what other contemporaneous agents'
outcomes are. Dynamically stable matchings always exist. Dynamic stability is a
necessary condition to ensure timely participation in the economy by ensuring
that agents do not strategically delay the time at which they are available to
match."
economics,Ordinal Imitative Dynamics,"This paper introduces an evolutionary dynamics based on imitate the better
realization (IBR) rule. Under this rule, agents in a population game imitate
the strategy of a randomly chosen opponent whenever the opponent`s realized
payoff is higher than their own. Such behavior generates an ordinal mean
dynamics which is polynomial in strategy utilization frequencies. We
demonstrate that while the dynamics does not possess Nash stationarity or
payoff monotonicity, under it pure strategies iteratively strictly dominated by
pure strategies are eliminated and strict equilibria are locally stable. We
investigate the relationship between the dynamics based on the IBR rule and the
replicator dynamics. In trivial cases, the two dynamics are topologically
equivalent. In Rock-Paper-Scissors games we conjecture that both dynamics
exhibit the same types of behavior, but the partitions of the game set do not
coincide. In other cases, the IBR dynamics exhibits behaviors that are
impossible under the replicator dynamics."
economics,"Existence and Uniqueness of Solutions to the Stochastic Bellman Equation
  with Unbounded Shock","In this paper we develop a general framework to analyze stochastic dynamic
problems with unbounded utility functions and correlated and unbounded shocks.
We obtain new results of the existence and uniqueness of solutions to the
Bellman equation through a general fixed point theorem that generalizes known
results for Banach contractions and local contractions. We study an endogenous
growth model as well as the Lucas asset pricing model in an exchange economy,
significantly expanding their range of applicability."
economics,Contract Design with Costly Convex Self-Control,"In this note, we consider the pricing problem of a profit-maximizing
monopolist who faces naive consumers with convex self-control preferences."
economics,Competing to Persuade a Rationally Inattentive Agent,"Firms strategically disclose product information in order to attract
consumers, but recipients often find it costly to process all of it, especially
when products have complex features. We study a model of competitive
information disclosure by two senders, in which the receiver may garble each
sender's experiment, subject to a cost increasing in the informativeness of the
garbling. For a large class of parameters, it is an equilibrium for the senders
to provide the receiver's first best level of information - i.e. as much as she
would learn if she herself controlled information provision. Information on one
sender substitutes for information on the other, which nullifies the
profitability of a unilateral provision of less information. Thus, we provide a
novel channel through which competition with attention costs encourages
information disclosure."
economics,"The method of Eneström and Phragmén for parliamentary elections by
  means of approval voting","We study a method for proportional representation that was proposed at the
turn from the nineteenth to the twentieth century by Gustav Enestr\""om and
Edvard Phragm\'en. Like Phragm\'en's better-known iterative minimax method, it
is assumed that the voters express themselves by means of approval voting. In
contrast to the iterative minimax method, however, here one starts by fixing a
quota, i.e. the number of votes that give the right to a seat. As a matter of
fact, the method of Enestr\""om and Phragm\'en can be seen as an extension of
the method of largest remainders from closed lists to open lists, or also as an
adaptation of the single transferable vote to approval rather than preferential
voting. The properties of this method are studied and compared with those of
other methods of the same kind."
economics,"Closed form solutions of Lucas Uzawa model with externalities via
  partial Hamiltonian approach. Some Clarifications","The main aim of this paper is to give some clarifications to the recent paper
published in Computational and Applied Mathematics by Naz and Chaudhry."
economics,A Production Function with Variable Elasticity of Factor Substitution,"The main aim of this paper is to prove the existence of a new production
function with variable elasticity of factor substitution. This production
function is a more general form which includes the Cobb-Douglas production
function and the CES production function as particular cases. The econometric
estimates presented in the paper confirm some other results and reinforces the
conclusion that the sigma is well-below the Cobb-Douglas value of one."
economics,On the Solutions of the Lucas-Uzawa Model,"In a recent paper, Naz and Chaudry provided two solutions for the model of
Lucas-Uzawa, via the Partial Hamiltonian Approach. The first one of these
solutions coincides exactly with that determined by Chilarescu. For the second
one, they claim that this is a new solution, fundamentally different than that
obtained by Chilarescu. We will prove in this paper, using the existence and
uniqueness theorem of nonlinear differential equations, that this is not at all
true."
economics,Dynamic Information Design with Diminishing Sensitivity Over News,"A Bayesian agent experiences gain-loss utility each period over changes in
belief about future consumption (""news utility""), with diminishing sensitivity
over the magnitude of news. Diminishing sensitivity induces a preference over
news skewness: gradual bad news, one-shot good news is worse than one-shot
resolution, which is in turn worse than gradual good news, one-shot bad news.
So, the agent's preference between gradual information and one-shot resolution
can depend on his consumption ranking of different states. In a dynamic
cheap-talk framework where a benevolent sender communicates the state over
multiple periods, the babbling equilibrium is essentially unique without loss
aversion. More loss-averse agents may enjoy higher news utility in equilibrium,
contrary to the commitment case. We characterize the family of gradual good
news equilibria that exist with high enough loss aversion, and find the sender
conveys progressively larger pieces of good news. We discuss applications to
media competition and game shows."
economics,The interest rate for saving as a possibilistic risk,"In the paper there is studied an optimal saving model in which the
interest-rate risk for saving is a fuzzy number. The total utility of
consumption is defined by using a concept of possibilistic expected utility. A
notion of possibilistic precautionary saving is introduced as a measure of the
variation of optimal saving level when moving from a sure saving model to a
possibilistic risk model. A first result establishes a necessary and sufficient
condition that the presence of a possibilistic interest-rate risk generates an
extra-saving. This result can be seen as a possibilistic version of a
Rothschilld and Stiglitz theorem on a probabilistic model of saving. A second
result of the paper studies the variation of the optimal saving level when
moving from a probabilistic model (the interest-rate risk is a random variable)
to a possibilistic model (the interest-rate risk is a fuzzy number)."
economics,Third person enforcement in a prisoner's dilemma game,"We theoretically study the effect of a third person enforcement on a one-shot
prisoner's dilemma game played by two persons, with whom the third person plays
repeated prisoner's dilemma games. We find that the possibility of the third
person's future punishment causes them to cooperate in the one-shot game."
economics,Equilibrium in Production Chains with Multiple Upstream Partners,"In this paper, we extend and improve the production chain model introduced by
Kikuchi et al. (2018). Utilizing the theory of monotone concave operators, we
prove the existence, uniqueness, and global stability of equilibrium price,
hence improving their results on production networks with multiple upstream
partners. We propose an algorithm for computing the equilibrium price function
that is more than ten times faster than successive evaluations of the operator.
The model is then generalized to a stochastic setting that offers richer
implications for the distribution of firms in a production network."
economics,Improving Information from Manipulable Data,"Data-based decisionmaking must account for the manipulation of data by agents
who are aware of how decisions are being made and want to affect their
allocations. We study a framework in which, due to such manipulation, data
becomes less informative when decisions depend more strongly on data. We
formalize why and how a decisionmaker should commit to underutilizing data.
Doing so attenuates information loss and thereby improves allocation accuracy."
economics,A Cardinal Comparison of Experts,"In various situations, decision makers face experts that may provide
conflicting advice. This advice may be in the form of probabilistic forecasts
over critical future events. We consider a setting where the two forecasters
provide their advice repeatedly and ask whether the decision maker can learn to
compare and rank the two forecasters based on past performance. We take an
axiomatic approach and propose three natural axioms that a comparison test
should comply with. We propose a test that complies with our axioms. Perhaps,
not surprisingly, this test is closely related to the likelihood ratio of the
two forecasts over the realized sequence of events. More surprisingly, this
test is essentially unique. Furthermore, using results on the rate of
convergence of supermartingales, we show that whenever the two
experts\textquoteright{} advice are sufficiently distinct, the proposed test
will detect the informed expert in any desired degree of precision in some
fixed finite time."
economics,Rational Inattention and Perceptual Distance,"This paper uses an axiomatic foundation to create a new measure for the cost
of learning that allows for multiple perceptual distances in a single choice
environment so that some events can be harder to differentiate between than
others. The new measure maintains the tractability of Shannon's classic measure
but produces richer choice predictions and identifies a new form of
informational bias significant for welfare and counterfactual analysis."
economics,Scoring Strategic Agents,"I introduce a model of predictive scoring. A receiver wants to predict a
sender's quality. An intermediary observes multiple features of the sender and
aggregates them into a score. Based on the score, the receiver makes a
decision. The sender wants the most favorable decision, and she can distort
each feature at a privately known cost. I characterize the most accurate
scoring rule. This rule underweights some features to deter sender distortion,
and overweights other features so that the score is correct on average. The
receiver prefers this scoring rule to full disclosure because information
aggregation mitigates his commitment problem."
economics,Illiquid Financial Markets and Monetary Policy,"This paper analyzes the role of money in asset markets characterized by
search frictions. We develop a dynamic framework that brings together a model
for illiquid financial assets `a la Duffie, Garleanu, and Pedersen, and a
search-theoretic model of monetary exchange `a la Lagos and Wright. The
presence of decentralized financial markets generates an essential role for
money, which helps investors re-balance their portfolios. We provide conditions
that guarantee the existence of a monetary equilibrium. In this case, asset
prices are always above their fundamental value, and this differential
represents a liquidity premium. We are able to derive an asset pricing theory
that delivers an explicit connection between monetary policy, asset prices, and
welfare. We obtain a negative relationship between inflation and equilibrium
asset prices. This key result stems from the complementarity between money and
assets in our framework."
economics,Constrained Pseudo-market Equilibrium,"We propose a pseudo-market solution to resource allocation problems subject
to constraints. Our treatment of constraints is general: including
bihierarchical constraints due to considerations of diversity in school choice,
or scheduling in course allocation; and other forms of constraints needed to
model, for example, the market for roommates, and combinatorial assignment
problems. Constraints give rise to pecuniary externalities, which are
internalized via prices. Agents pay to the extent that their purchases affect
the value of relevant constraints at equilibrium prices. The result is a
constrained efficient market equilibrium outcome. The outcome is fair whenever
the constraints do not single out individual agents. Our result can be extended
to economies with endowments, and address participation constraints."
economics,Overconfidence and Prejudice,"We explore conclusions a person draws from observing society when he allows
for the possibility that individuals' outcomes are affected by group-level
discrimination. Injecting a single non-classical assumption, that the agent is
overconfident about himself, we explain key observed patterns in social
beliefs, and make a number of additional predictions. First, the agent believes
in discrimination against any group he is in more than an outsider does,
capturing widely observed self-centered views of discrimination. Second, the
more group memberships the agent shares with an individual, the more positively
he evaluates the individual. This explains one of the most basic facts about
social judgments, in-group bias, as well as ""legitimizing myths"" that justify
an arbitrary social hierarchy through the perceived superiority of the
privileged group. Third, biases are sensitive to how the agent divides society
into groups when evaluating outcomes. This provides a reason why some
ethnically charged questions should not be asked, as well as a potential
channel for why nation-building policies might be effective. Fourth, giving the
agent more accurate information about himself increases all his biases. Fifth,
the agent is prone to substitute biases, implying that the introduction of a
new outsider group to focus on creates biases against the new group but lowers
biases vis a vis other groups. Sixth, there is a tendency for the agent to
agree more with those in the same groups. As a microfoundation for our model,
we provide an explanation for why an overconfident agent might allow for
potential discrimination in evaluating outcomes, even when he initially did not
conceive of this possibility."
economics,"Time-consistent decisions and rational expectation equilibrium existence
  in DSGE models","Under some initial conditions, it is shown that time consistency requirements
prevent rational expectation equilibrium (REE) existence for dynamic stochastic
general equilibrium models induced by consumer heterogeneity, in contrast to
static models. However, one can consider REE-prohibiting initial conditions as
limits of other initial conditions. The REE existence issue then is overcome by
using a limit of economies. This shows that significant care must be taken of
when dealing with rational expectation equilibria."
economics,The converse envelope theorem,"I prove an envelope theorem with a converse: the envelope formula is
equivalent to a first-order condition. Like Milgrom and Segal's (2002) envelope
theorem, my result requires no structure on the choice set. I use the converse
envelope theorem to extend to general outcomes and preferences the canonical
result in mechanism design that any increasing allocation is implementable, and
apply this to selling information."
economics,Undiscounted Bandit Games,"We analyze undiscounted continuous-time games of strategic experimentation
with two-armed bandits. The risky arm generates payoffs according to a L\'{e}vy
process with an unknown average payoff per unit of time which nature draws from
an arbitrary finite set. Observing all actions and realized payoffs, plus a
free background signal, players use Markov strategies with the common posterior
belief about the unknown parameter as the state variable. We show that the
unique symmetric Markov perfect equilibrium can be computed in a simple closed
form involving only the payoff of the safe arm, the expected current payoff of
the risky arm, and the expected full-information payoff, given the current
belief. In particular, the equilibrium does not depend on the precise
specification of the payoff-generating processes."
economics,All-Pay Auctions with Different Forfeits,"In an auction each party bids a certain amount and the one which bids the
highest is the winner. Interestingly, auctions can also be used as models for
other real-world systems. In an all pay auction all parties must pay a forfeit
for bidding. In the most commonly studied all pay auction, parties forfeit
their entire bid, and this has been considered as a model for expenditure on
political campaigns. Here we consider a number of alternative forfeits which
might be used as models for different real-world competitions, such as
preparing bids for defense or infrastructure contracts."
economics,All-Pay Auctions as Models for Trade Wars and Military Annexation,"We explore an application of all-pay auctions to model trade wars and
territorial annexation. Specifically, in the model we consider the expected
resource, production, and aggressive (military/tariff) power are public
information, but actual resource levels are private knowledge. We consider the
resource transfer at the end of such a competition which deprives the weaker
country of some fraction of its original resources. In particular, we derive
the quasi-equilibria strategies for two country conflicts under different
scenarios. This work is relevant for the ongoing US-China trade war, and the
recent Russian capture of Crimea, as well as historical and future conflicts."
economics,"The structure of two-valued strategy-proof social choice functions with
  indifference","We give a structure theorem for all coalitionally strategy-proof social
choice functions whose range is a subset of cardinality two of a given larger
set of alternatives.
  We provide this in the case where the voters/agents are allowed to express
indifference and the domain consists of profiles of preferences over a society
of arbitrary cardinality. The theorem, that takes the form of a representation
formula, can be used to construct all functions under consideration."
economics,Convex Combinatorial Auction of Pipeline Network Capacities,"In this paper we propose a mechanism for the allocation of pipeline
capacities, assuming that the participants bidding for capacities do have
subjective evaluation of various network routes. The proposed mechanism is
based on the concept of bidding for route-quantity pairs. Each participant
defines a limited number of routes and places multiple bids, corresponding to
various quantities, on each of these routes. The proposed mechanism assigns a
convex combination of the submitted bids to each participant, thus its called
convex combinatorial auction. The capacity payments in the proposed model are
determined according to the Vickrey-Clarke-Groves principle. We compare the
efficiency of the proposed algorithm with a simplified model of the method
currently used for pipeline capacity allocation in the EU (simultaneous
ascending clock auction of pipeline capacities) via simulation, according to
various measures, such as resulting utility of players, utilization of network
capacities, total income of the auctioneer and fairness."
economics,VAT Compliance Incentives,"In this work I clarify VAT evasion incentives through a game theoretical
approach. Traditionally, evasion has been linked to the decreasing risk
aversion in higher revenues (Allingham and Sandmo (1972), Cowell (1985)
(1990)). I claim tax evasion to be a rational choice when compliance is
stochastically more expensive than evading, even in absence of controls and
sanctions. I create a framework able to measure the incentives for taxpayers to
comply. The incentives here are deductions of specific VAT documented expenses
from the income tax. The issue is very well known and deduction policies at
work in many countries. The aim is to compute the right parameters for each
precise class of taxpayers. VAT evasion is a collusive conduct between the two
counterparts of the transaction. I therefore first explore the convenience for
the two private counterparts to agree on the joint evasion and to form a
coalition. Crucial is that compliance incentives break the agreement among the
transaction participants' coalition about evading. The game solution leads to
boundaries for marginal tax rates or deduction percentages, depending on
parameters, able to create incentives to comply The stylized example presented
here for VAT policies, already in use in many countries, is an attempt to
establish a more general method for tax design, able to make compliance the
""dominant strategy"", satisfying the ""outside option"" constraint represented by
evasion, even in absence of audit and sanctions. The theoretical results
derived here can be easily applied to real data for precise tax design
engineering."
economics,"Lattice structure of the random stable set in many-to-many matching
  market","For a many-to-many matching market, we study the lattice structure of the set
of random stable matchings. We define a partial order on the random stable set
and present two intuitive binary operations to compute the least upper bound
and the greatest lower bound for each side of the matching market. Then, we
prove that with these binary operations the set of random stable matchings
forms two dual lattices."
economics,What are we weighting for? A mechanistic model for probability weighting,"Behavioural economics provides labels for patterns in human economic
behaviour. Probability weighting is one such label. It expresses a mismatch
between probabilities used in a formal model of a decision (i.e. model
parameters) and probabilities inferred from real people's decisions (the same
parameters estimated empirically). The inferred probabilities are called
""decision weights."" It is considered a robust experimental finding that
decision weights are higher than probabilities for rare events, and
(necessarily, through normalisation) lower than probabilities for common
events. Typically this is presented as a cognitive bias, i.e. an error of
judgement by the person. Here we point out that the same observation can be
described differently: broadly speaking, probability weighting means that a
decision maker has greater uncertainty about the world than the observer. We
offer a plausible mechanism whereby such differences in uncertainty arise
naturally: when a decision maker must estimate probabilities as frequencies in
a time series while the observer knows them a priori. This suggests an
alternative presentation of probability weighting as a principled response by a
decision maker to uncertainties unaccounted for in an observer's model."
economics,On the Equivalence of Neural and Production Networks,"This paper identifies the mathematical equivalence between economic networks
of Cobb-Douglas agents and Artificial Neural Networks. It explores two
implications of this equivalence under general conditions. First, a burgeoning
literature has established that network propagation can transform microeconomic
perturbations into large aggregate shocks. Neural network equivalence amplifies
the magnitude and complexity of this phenomenon. Second, if economic agents
adjust their production and utility functions in optimal response to local
conditions, market pricing is a sufficient and robust channel for information
feedback leading to macro learning."
economics,Dynamic Reserves in Matching Markets,"We study a school choice problem under affirmative action policies where
authorities reserve a certain fraction of the slots at each school for specific
student groups, and where students have preferences not only over the schools
they are matched to but also the type of slots they receive. Such reservation
policies might cause waste in instances of low demand from some student groups.
To propose a solution to this issue, we construct a family of choice functions,
dynamic reserves choice functions, for schools that respect within-group
fairness and allow the transfer of otherwise vacant slots from low-demand
groups to high-demand groups. We propose the cumulative offer mechanism (COM)
as an allocation rule where each school uses a dynamic reserves choice function
and show that it is stable with respect to schools' choice functions, is
strategy-proof, and respects improvements. Furthermore, we show that
transferring more of the otherwise vacant slots leads to strategy-proof Pareto
improvement under the COM."
economics,A Theory of the Saving Rate of the Rich,"Empirical evidence suggests that the rich have higher propensity to save than
do the poor. While this observation may appear to contradict the homotheticity
of preferences, we theoretically show that that is not the case. Specifically,
we consider an income fluctuation problem with homothetic preferences and
general shocks and prove that consumption functions are asymptotically linear,
with an exact analytical characterization of asymptotic marginal propensities
to consume (MPC). We provide necessary and sufficient conditions for the
asymptotic MPCs to be zero. We calibrate a model with standard constant
relative risk aversion utility and show that zero asymptotic MPCs are
empirically plausible, implying that our mechanism has the potential to
accommodate a large saving rate of the rich and high wealth inequality (small
Pareto exponent) as observed in the data."
economics,Choice with Endogenous Categorization,"We propose and axiomatize the categorical thinking model (CTM) in which the
framing of the decision problem affects how agents categorize alternatives,
that in turn affects their evaluation of it. Prominent models of salience,
status quo bias, loss-aversion, inequality aversion, and present bias all fit
under the umbrella of CTM. This suggests categorization is an underlying
mechanism of key departures from the neoclassical model of choice. We
specialize CTM to provide a behavioral foundation for the salient thinking
model of Bordalo et al. (2013) that highlights its strong predictions and
distinctions from other models."
economics,"Communication, Renegotiation and Coordination with Private Values","An equilibrium is communication-proof if it is unaffected by new
opportunities to communicate and renegotiate. We characterize the set of
equilibria of coordination games with pre-play communication in which players
have private preferences over the coordinated outcomes. The set of
communication-proof equilibria is a small and relatively homogeneous subset of
the set of qualitatively diverse Bayesian Nash equilibria. Under a
communication-proof equilibrium, players never miscoordinate, play their
jointly preferred outcome whenever there is one, and communicate only the
ordinal part of their preferences. Moreover, such equilibria are robust to
changes in players' beliefs and interim Pareto efficient"
economics,"Information Validates the Prior: A Theorem on Bayesian Updating and
  Applications","We develop a result on expected posteriors for Bayesians with heterogenous
priors, dubbed information validates the prior (IVP). Under familiar ordering
requirements, Anne expects a (Blackwell) more informative experiment to bring
Bob's posterior mean closer to Anne's prior mean. We apply the result in two
contexts of games of asymmetric information: voluntary testing or
certification, and costly signaling or falsification. IVP can be used to
determine how an agent's behavior responds to additional exogenous or
endogenous information. We discuss economic implications."
economics,"Instability of Defection in the Prisoner's Dilemma Under Best
  Experienced Payoff Dynamics","We study population dynamics under which each revising agent tests each
strategy k times, with each trial being against a newly drawn opponent, and
chooses the strategy whose mean payoff was highest. When k = 1, defection is
globally stable in the prisoner`s dilemma. By contrast, when k > 1 we show that
there exists a globally stable state in which agents cooperate with probability
between 28% and 50%. Next, we characterize stability of strict equilibria in
general games. Our results demonstrate that the empirically plausible case of k
> 1 can yield qualitatively different predictions than the case of k = 1 that
is commonly studied in the literature."
economics,Efficient and fair trading algorithms in market design environments,"We propose a new method to define trading algorithms in market design
environments. Dropping the traditional idea of clearing cycles in generated
graphs, we use parameterized linear equations to define trading algorithms. Our
method has two advantages. First, our method avoids discussing the details of
who trades with whom and how, which can be a difficult question in complex
environments. Second, by controlling parameter values in our equations, our
method is flexible and transparent to satisfy various fairness criteria. We
apply our method to several models and obtain new trading algorithms that are
efficient and fair."
economics,Exploring Weak Strategy-Proofness in Voting Theory,"Voting is the aggregation of individual preferences in order to select a
winning alternative. Selection of a winner is accomplished via a voting rule,
e.g., rank-order voting, majority rule, plurality rule, approval voting. Which
voting rule should be used? In social choice theory, desirable properties of
voting rules are expressed as axioms to be satisfied. This thesis focuses on
axioms concerning strategic manipulation by voters. Sometimes, voters may
intentionally misstate their true preferences in order to alter the outcome for
their own advantage. For example, in plurality rule, if a voter knows that
their top-choice candidate will lose, then they might instead vote for their
second-choice candidate just to avoid an even less desirable result. When no
coalition of voters can strategically manipulate, then the voting rule is said
to satisfy the axiom of Strategy-Proofness. A less restrictive axiom is Weak
Strategy-Proofness (as defined by Dasgupta and Maskin (2019)), which allows for
strategic manipulation by all but the smallest coalitions. Under certain
intuitive conditions, Dasgupta and Maskin (2019) proved that the only voting
rules satisfying Strategy-Proofness are rank-order voting and majority rule. In
my thesis, I generalize their result, by proving that rank-order voting and
majority rule are surprisingly still the only voting rules satisfying Weak
Strategy-Proofness."
economics,"Optimal Trade-Off Between Economic Activity and Health During an
  Epidemic","This paper considers a simple model where a social planner can influence the
spread-intensity of an infection wave, and, consequently, also the economic
activity and population health, through a single parameter. Population health
is assumed to only be negatively affected when the number of simultaneously
infected exceeds health care capacity. The main finding is that if (i) the
planner attaches a positive weight on economic activity and (ii) it is more
harmful for the economy to be locked down for longer than shorter time periods,
then the optimal policy is to (weakly) exceed health care capacity at some
time."